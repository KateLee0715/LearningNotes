{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from pyvirtualdisplay import Display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from IPython import display\n",
    "from torch.distributions import Categorical\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 543\n",
    "def fix(env, seed):\n",
    "    env.seed(seed)\n",
    "    env.action_space.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "env = gym.make('LunarLander-v2')\n",
    "fix(env, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box([-inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf], (8,), float32)\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(4)\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00396109  1.4083536   0.40119505 -0.11407257 -0.00458307 -0.09087662\n",
      "  0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "initial_state = env.reset()\n",
    "print(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "random_action = env.action_space.sample()\n",
    "print(random_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation, reward, done, info = env.step(random_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8588900517154912\n"
     ]
    }
   ],
   "source": [
    "print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "\n",
    "img = plt.imshow(env.render(mode = 'rgb_array'))\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, _ = env.step(action)\n",
    "    img.set_data(env.render(mode = 'rgb_array'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    \"\"\"Actor (Policy) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size=8, action_size=4, fc1_units=64, fc2_units=64):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fc1_units (int): Number of nodes in first hidden layer\n",
    "            fc2_units (int): Number of nodes in second hidden layer\n",
    "        \"\"\"\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build a network that maps state -> action values.\"\"\"\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyGradientNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PolicyGradientNetwork, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(8, 16),\n",
    "            nn.Tanh(),\n",
    "            \n",
    "            nn.Linear(16, 16),\n",
    "            nn.Tanh(),\n",
    "            \n",
    "            nn.Linear(16, 4),\n",
    "            nn.Softmax(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "class ReplayMemory:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "    def __init__(self, CAPACITY):\n",
    "        self.capacity = CAPACITY  \n",
    "        self.memory = []  \n",
    "        self.index = 0  \n",
    "        self.transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "        \n",
    "    def push(self, state, action, state_next, reward):\n",
    "        \"\"\"Push a new experience to memory.\"\"\"\n",
    "        if len(self.memory) < self.capacity: # if still has capacity, initialize memory[index] to None\n",
    "            self.memory.append(None)\n",
    "\n",
    "        self.memory[self.index] = self.transition(state, action, state_next, reward)\n",
    "\n",
    "        self.index = (self.index + 1) % self.capacity  # circular index\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent():\n",
    "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
    "    def __init__(self, num_states, num_actions):\n",
    "        \"\"\"Initialize an Agent object.\"\"\"\n",
    "        \n",
    "        self.num_states = num_states\n",
    "        self.num_actions = num_actions\n",
    "        \n",
    "        # Replay memory\n",
    "        self.memory_capacity = 10000\n",
    "        self.memory = ReplayMemory(self.memory_capacity)\n",
    "        \n",
    "        # Q-Network\n",
    "        self.main_q_network = DQN() \n",
    "        self.target_q_network = DQN()\n",
    "        \n",
    "        # optimizer\n",
    "        self.optimizer = optim.RMSprop(self.main_q_network.parameters(), lr=1e-4)\n",
    "    \n",
    "    def update_q_function(self):\n",
    "        '''update q function'''\n",
    "        \n",
    "        # no enough samples, just return\n",
    "        if len(self.memory) < BATCH_SIZE:\n",
    "            return\n",
    "        # If enough samples are available in memory, get random subset and learn\n",
    "        self.batch, self.state_batch, self.action_batch, self.reward_batch, self.non_final_next_states = self.make_minibatch()\n",
    "        \n",
    "        self.expected_state_action_values = self.get_expected_state_action_values()\n",
    "\n",
    "        self.update_main_q_network()\n",
    "\n",
    "    def make_minibatch(self):\n",
    "        '''Creating a mini-batch'''\n",
    "\n",
    "        transitions = self.memory.sample(BATCH_SIZE)\n",
    "\n",
    "        Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "        batch = Transition(*zip(*transitions))\n",
    "\n",
    "\n",
    "        state_batch = torch.cat(batch.state)\n",
    "        action_batch = torch.cat(batch.action)\n",
    "        reward_batch = torch.cat(batch.reward)\n",
    "        non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                           if s is not None])\n",
    "\n",
    "        return batch, state_batch, action_batch, reward_batch, non_final_next_states\n",
    "\n",
    "    def get_expected_state_action_values(self):\n",
    "        '''calculate Q（St,at）'''\n",
    "\n",
    "        self.main_q_network.eval()\n",
    "        self.target_q_network.eval()\n",
    "\n",
    "        self.state_action_values = self.main_q_network(\n",
    "            self.state_batch).gather(1, self.action_batch)\n",
    "\n",
    "        non_final_mask = torch.BoolTensor(tuple(map(lambda s: s is not None,\n",
    "                                                    self.batch.next_state)))\n",
    "        # set all state to 0\n",
    "        next_state_values = torch.zeros(BATCH_SIZE)\n",
    "\n",
    "        next_state_values[non_final_mask] = self.target_q_network(\n",
    "            self.non_final_next_states).max(1)[0].detach()\n",
    "        # DQN formula\n",
    "        expected_state_action_values = self.reward_batch + GAMMA * next_state_values\n",
    "        \n",
    "        return expected_state_action_values \n",
    "        \n",
    "    def get_action(self, state, episode, test=False):\n",
    "        \"\"\"Returns actions for given state as per current policy.\"\"\"\n",
    "        if test:\n",
    "            self.main_q_network.eval()\n",
    "            with torch.no_grad():\n",
    "                # t.max(1) will return largest column value of each row.\n",
    "                # second column on max result is index of where max element was\n",
    "                # found, so we pick action with the larger expected reward.\n",
    "                action = self.main_q_network(torch.from_numpy(state).unsqueeze(0)).max(1)[1].view(1, 1)\n",
    "            return action.item()\n",
    "        \n",
    "        global steps_done\n",
    "        # Epsilon-greedy policy\n",
    "        #epsilon = episode\n",
    "        #epsilon = 0.5 * (1 / (episode + 1))\n",
    "        epsilon = EPS_END + (EPS_START - EPS_END) * \\\n",
    "                np.exp(-1. * steps_done / EPS_DECAY)\n",
    "        #print('epsilon', epsilon)\n",
    "        \n",
    "        steps_done += 1\n",
    "        \n",
    "        if epsilon <= np.random.uniform(0, 1):\n",
    "            #print('use max')\n",
    "            self.main_q_network.eval()\n",
    "            with torch.no_grad():\n",
    "                # t.max(1) will return largest column value of each row.\n",
    "                # second column on max result is index of where max element was\n",
    "                # found, so we pick action with the larger expected reward.\n",
    "                action = self.main_q_network(state).max(1)[1].view(1, 1)\n",
    "        else:\n",
    "            #print('random')\n",
    "            action = torch.LongTensor(\n",
    "                [[random.randrange(self.num_actions)]])  \n",
    "            \n",
    "        return action\n",
    "\n",
    "    def update_main_q_network(self):\n",
    "        \n",
    "        '''update main q net'''\n",
    "\n",
    "        # set train mode\n",
    "        self.main_q_network.train()\n",
    "        # Hurberloss function\n",
    "        # expected_state_action_values (minbatch,)->(minbatchx1)\n",
    "\n",
    "        loss = F.smooth_l1_loss(self.state_action_values,\n",
    "                                self.expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "        # update\n",
    "        self.optimizer.zero_grad()  # reset gradient\n",
    "        loss.backward()  # backpropagation\n",
    "        for param in self.main_q_network.parameters():\n",
    "            param.grad.data.clamp_(-1, 1)\n",
    "        self.optimizer.step()  # update network\n",
    "\n",
    "\n",
    "    def memorize(self, state, action, state_next, reward):\n",
    "        '''save state, action, state_next, reward into replay memory'''\n",
    "        self.memory.push(state, action, state_next, reward)\n",
    "\n",
    "    def update_target_q_function(self):\n",
    "        \n",
    "        '''synchronize Target Q-Network to Main Q-Network'''\n",
    "        self.target_q_network.load_state_dict(self.main_q_network.state_dict()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyGradientAgent():\n",
    "    def __init__(self, network):\n",
    "        self.network = network\n",
    "        self.optimizer = optim.SGD(self.network.parameters(), lr=0.001)\n",
    "    \n",
    "    def learn(self, log_prob, reward):\n",
    "        loss = (-log_prob * reward).sum()\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def sample(self, state):\n",
    "        action_prob = self.network(torch.FloatTensor(state))\n",
    "        action_dist = Categorical(action_prob)\n",
    "        action = action_dist.sample()\n",
    "        log_prob = action_dist.log_prob(action)\n",
    "        return action.item(), log_prob\n",
    "    \n",
    "    def save(self, PATH):\n",
    "        Agent_Dist = {\n",
    "            'network': self.network.state_dict(),\n",
    "            'optimizer': self.optimizer.state_dict()\n",
    "        }\n",
    "        \n",
    "        torch.save(Agent_Dist, PATH)\n",
    "    \n",
    "    def load(self, PATH):\n",
    "        checkpoints = torch.load(PATH)\n",
    "        self.network.load_state_dict(checkpoints['network'])\n",
    "        self.optimizer.load_state_dict(checkpoints['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = DQN()\n",
    "agent = DQNAgent(env.observation_space.shape[0], env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = PolicyGradientNetwork()\n",
    "agent = PolicyGradientAgent(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "934c7581d3f141c19a05258ced95acd2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.from_numpy(rewards) looks like  torch.Size([2557])\n",
      "-128.30740249705312\n",
      "length of actions is  1000\n",
      "-81.91184395357213\n",
      "length of actions is  1000\n",
      "-104.7819205246249\n",
      "length of actions is  1000\n",
      "-116.07362112610487\n",
      "length of actions is  1000\n",
      "-156.44286048358157\n",
      "length of actions is  1000\n",
      "Your final reward is : -117.50\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3552])\n",
      "-117.0591967629623\n",
      "length of actions is  1000\n",
      "-73.75954867452928\n",
      "length of actions is  1000\n",
      "-90.86768118075335\n",
      "length of actions is  1000\n",
      "-106.80543927299351\n",
      "length of actions is  1000\n",
      "-147.87788089736046\n",
      "length of actions is  1000\n",
      "Your final reward is : -107.27\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4298])\n",
      "-123.12194015583322\n",
      "length of actions is  1000\n",
      "-84.1392074053583\n",
      "length of actions is  1000\n",
      "-110.43401059943893\n",
      "length of actions is  1000\n",
      "-112.77240136106295\n",
      "length of actions is  1000\n",
      "-153.16703731009363\n",
      "length of actions is  1000\n",
      "Your final reward is : -116.73\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3543])\n",
      "-118.58636930561008\n",
      "length of actions is  1000\n",
      "-68.65656270735374\n",
      "length of actions is  1000\n",
      "-83.06119443551637\n",
      "length of actions is  1000\n",
      "-114.2313119633492\n",
      "length of actions is  1000\n",
      "-143.28226544757743\n",
      "length of actions is  1000\n",
      "Your final reward is : -105.56\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4355])\n",
      "-129.91740868083855\n",
      "length of actions is  1000\n",
      "-78.76725621624836\n",
      "length of actions is  1000\n",
      "-94.0666208207197\n",
      "length of actions is  1000\n",
      "-122.90301100798546\n",
      "length of actions is  1000\n",
      "-158.5219414726379\n",
      "length of actions is  1000\n",
      "Your final reward is : -116.84\n",
      "torch.from_numpy(rewards) looks like  torch.Size([5000])\n",
      "-116.44257246505217\n",
      "length of actions is  1000\n",
      "-72.58766804829935\n",
      "length of actions is  1000\n",
      "-89.805841703454\n",
      "length of actions is  1000\n",
      "-111.1719323456157\n",
      "length of actions is  1000\n",
      "-153.5624906109638\n",
      "length of actions is  1000\n",
      "Your final reward is : -108.71\n",
      "torch.from_numpy(rewards) looks like  torch.Size([5000])\n",
      "-120.22049200355515\n",
      "length of actions is  1000\n",
      "-22.307866773209057\n",
      "length of actions is  1000\n",
      "-81.42097820026551\n",
      "length of actions is  1000\n",
      "-111.92066585560329\n",
      "length of actions is  1000\n",
      "-155.87653533794412\n",
      "length of actions is  1000\n",
      "Your final reward is : -98.35\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3929])\n",
      "-104.6912816088977\n",
      "length of actions is  1000\n",
      "-52.696230990241325\n",
      "length of actions is  1000\n",
      "-63.797672017702666\n",
      "length of actions is  1000\n",
      "-103.71515106394847\n",
      "length of actions is  1000\n",
      "-136.50457574060334\n",
      "length of actions is  1000\n",
      "Your final reward is : -92.28\n",
      "torch.from_numpy(rewards) looks like  torch.Size([5000])\n",
      "-105.03210337891475\n",
      "length of actions is  1000\n",
      "-53.74859705499379\n",
      "length of actions is  1000\n",
      "-74.6343941771592\n",
      "length of actions is  1000\n",
      "-102.72722538442108\n",
      "length of actions is  1000\n",
      "-150.06408991456524\n",
      "length of actions is  1000\n",
      "Your final reward is : -97.24\n",
      "torch.from_numpy(rewards) looks like  torch.Size([5000])\n",
      "-107.2255828583333\n",
      "length of actions is  1000\n",
      "-40.47230652943364\n",
      "length of actions is  1000\n",
      "-57.68392296199839\n",
      "length of actions is  1000\n",
      "-100.87319784065934\n",
      "length of actions is  1000\n",
      "-142.56084530183574\n",
      "length of actions is  1000\n",
      "Your final reward is : -89.76\n",
      "torch.from_numpy(rewards) looks like  torch.Size([5000])\n",
      "-97.339556446995\n",
      "length of actions is  1000\n",
      "34.16164434780957\n",
      "length of actions is  1000\n",
      "19.865744526018638\n",
      "length of actions is  1000\n",
      "-100.0576315196355\n",
      "length of actions is  1000\n",
      "-125.65398288590575\n",
      "length of actions is  1000\n",
      "Your final reward is : -53.80\n",
      "torch.from_numpy(rewards) looks like  torch.Size([5000])\n",
      "-79.96843595347327\n",
      "length of actions is  1000\n",
      "31.238773244439205\n",
      "length of actions is  1000\n",
      "5.108810194362734\n",
      "length of actions is  1000\n",
      "-98.00067160526113\n",
      "length of actions is  1000\n",
      "-127.96227128793058\n",
      "length of actions is  1000\n",
      "Your final reward is : -53.92\n",
      "torch.from_numpy(rewards) looks like  torch.Size([5000])\n",
      "-72.99480516182415\n",
      "length of actions is  1000\n",
      "29.321304896826604\n",
      "length of actions is  1000\n",
      "23.361492618288565\n",
      "length of actions is  1000\n",
      "-82.46482371366942\n",
      "length of actions is  1000\n",
      "-120.08227616804825\n",
      "length of actions is  1000\n",
      "Your final reward is : -44.57\n",
      "torch.from_numpy(rewards) looks like  torch.Size([5000])\n",
      "-78.00267663107407\n",
      "length of actions is  1000\n",
      "-20.447248717094837\n",
      "length of actions is  703\n",
      "4.022554263771078\n",
      "length of actions is  1000\n",
      "17.15425459463832\n",
      "length of actions is  1000\n",
      "64.75420095060359\n",
      "length of actions is  1000\n",
      "Your final reward is : -2.50\n",
      "torch.from_numpy(rewards) looks like  torch.Size([5000])\n",
      "-65.44039004841076\n",
      "length of actions is  1000\n",
      "-55.63631038474274\n",
      "length of actions is  1000\n",
      "-56.15398987650959\n",
      "length of actions is  1000\n",
      "-57.64877053037425\n",
      "length of actions is  1000\n",
      "-109.95271303721474\n",
      "length of actions is  1000\n",
      "Your final reward is : -68.97\n",
      "torch.from_numpy(rewards) looks like  torch.Size([5000])\n",
      "-65.03405434121593\n",
      "length of actions is  1000\n",
      "-31.89618899150499\n",
      "length of actions is  1000\n",
      "-63.1055760465709\n",
      "length of actions is  1000\n",
      "-59.79772397531836\n",
      "length of actions is  1000\n",
      "-92.15245210153543\n",
      "length of actions is  1000\n",
      "Your final reward is : -62.40\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4319])\n",
      "-53.561259616735576\n",
      "length of actions is  1000\n",
      "-26.150811003762975\n",
      "length of actions is  1000\n",
      "-70.18629763276442\n",
      "length of actions is  661\n",
      "-6.25288596680294\n",
      "length of actions is  1000\n",
      "-87.70293101062254\n",
      "length of actions is  1000\n",
      "Your final reward is : -48.77\n",
      "torch.from_numpy(rewards) looks like  torch.Size([5000])\n",
      "-52.89007221575466\n",
      "length of actions is  1000\n",
      "-62.62577531478631\n",
      "length of actions is  1000\n",
      "50.11860706988065\n",
      "length of actions is  1000\n",
      "-21.020197070461833\n",
      "length of actions is  1000\n",
      "-85.30135354570963\n",
      "length of actions is  1000\n",
      "Your final reward is : -34.34\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4300])\n",
      "-153.26241296313626\n",
      "length of actions is  852\n",
      "-20.46882131339055\n",
      "length of actions is  1000\n",
      "-31.860302161426446\n",
      "length of actions is  1000\n",
      "-71.99241906269998\n",
      "length of actions is  388\n",
      "-58.674020221990155\n",
      "length of actions is  1000\n",
      "Your final reward is : -67.25\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3656])\n",
      "-0.22789795669968302\n",
      "length of actions is  1000\n",
      "110.11974161671394\n",
      "length of actions is  707\n",
      "-97.22253242613621\n",
      "length of actions is  536\n",
      "-50.353191307096864\n",
      "length of actions is  420\n",
      "-8.06054535677407\n",
      "length of actions is  1000\n",
      "Your final reward is : -9.15\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4046])\n",
      "-122.27740286738934\n",
      "length of actions is  542\n",
      "147.42012568978754\n",
      "length of actions is  572\n",
      "156.60648183726346\n",
      "length of actions is  564\n",
      "-56.987923077570024\n",
      "length of actions is  123\n",
      "118.25167454609466\n",
      "length of actions is  919\n",
      "Your final reward is : 48.60\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3069])\n",
      "48.329921903571375\n",
      "length of actions is  900\n",
      "133.02888140231684\n",
      "length of actions is  707\n",
      "137.85583382401182\n",
      "length of actions is  645\n",
      "-56.88379805924163\n",
      "length of actions is  342\n",
      "-60.56981776815034\n",
      "length of actions is  171\n",
      "Your final reward is : 40.35\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2558])\n",
      "-169.23787672788274\n",
      "length of actions is  850\n",
      "-63.265521765704484\n",
      "length of actions is  234\n",
      "119.6401448087372\n",
      "length of actions is  918\n",
      "-66.24621209562869\n",
      "length of actions is  164\n",
      "91.13549439783739\n",
      "length of actions is  952\n",
      "Your final reward is : -17.59\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3129])\n",
      "92.76978749858065\n",
      "length of actions is  662\n",
      "158.34565772079281\n",
      "length of actions is  514\n",
      "-38.01006443078465\n",
      "length of actions is  211\n",
      "-79.60518979359061\n",
      "length of actions is  245\n",
      "-30.606613344309913\n",
      "length of actions is  1000\n",
      "Your final reward is : 20.58\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2494])\n",
      "84.55098619565642\n",
      "length of actions is  691\n",
      "106.76114540473345\n",
      "length of actions is  702\n",
      "-62.25934590015226\n",
      "length of actions is  191\n",
      "112.29316378236575\n",
      "length of actions is  742\n",
      "-58.94460377414882\n",
      "length of actions is  245\n",
      "Your final reward is : 36.48\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3557])\n",
      "-73.81743750173442\n",
      "length of actions is  1000\n",
      "142.18495477814633\n",
      "length of actions is  511\n",
      "-80.07484074446768\n",
      "length of actions is  223\n",
      "173.80893263466152\n",
      "length of actions is  514\n",
      "204.49478769064396\n",
      "length of actions is  368\n",
      "Your final reward is : 73.32\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2549])\n",
      "-122.04006974718219\n",
      "length of actions is  498\n",
      "106.18710638014744\n",
      "length of actions is  983\n",
      "137.3505030375866\n",
      "length of actions is  443\n",
      "151.03974395204597\n",
      "length of actions is  493\n",
      "6.78530598725691\n",
      "length of actions is  1000\n",
      "Your final reward is : 55.86\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2786])\n",
      "-78.53870588271522\n",
      "length of actions is  1000\n",
      "123.33267595313471\n",
      "length of actions is  1000\n",
      "177.53653280191043\n",
      "length of actions is  448\n",
      "62.05111095932493\n",
      "length of actions is  819\n",
      "118.55173888505828\n",
      "length of actions is  984\n",
      "Your final reward is : 80.59\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2430])\n",
      "85.89811971166255\n",
      "length of actions is  814\n",
      "112.97476570051712\n",
      "length of actions is  658\n",
      "120.74321525056402\n",
      "length of actions is  741\n",
      "210.71864170195678\n",
      "length of actions is  505\n",
      "-38.4730790327212\n",
      "length of actions is  188\n",
      "Your final reward is : 98.37\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2638])\n",
      "-131.55430705971781\n",
      "length of actions is  552\n",
      "194.57705492712012\n",
      "length of actions is  456\n",
      "139.34595566512846\n",
      "length of actions is  486\n",
      "162.0471976746633\n",
      "length of actions is  664\n",
      "58.30344449185212\n",
      "length of actions is  1000\n",
      "Your final reward is : 84.54\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2513])\n",
      "67.3855605639276\n",
      "length of actions is  842\n",
      "-55.76654130649956\n",
      "length of actions is  154\n",
      "-51.009021501830034\n",
      "length of actions is  260\n",
      "116.90790378704902\n",
      "length of actions is  576\n",
      "-34.40945324874011\n",
      "length of actions is  178\n",
      "Your final reward is : 8.62\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4180])\n",
      "95.81637107191797\n",
      "length of actions is  827\n",
      "121.03164987047647\n",
      "length of actions is  503\n",
      "116.0531841127923\n",
      "length of actions is  803\n",
      "-28.24029516969118\n",
      "length of actions is  371\n",
      "-10.471780367702713\n",
      "length of actions is  1000\n",
      "Your final reward is : 58.84\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3006])\n",
      "-75.37258528568688\n",
      "length of actions is  1000\n",
      "249.50028775299373\n",
      "length of actions is  378\n",
      "38.05419190983062\n",
      "length of actions is  1000\n",
      "-72.7901170128568\n",
      "length of actions is  309\n",
      "133.5330793833232\n",
      "length of actions is  1000\n",
      "Your final reward is : 54.58\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4030])\n",
      "81.59182740357186\n",
      "length of actions is  823\n",
      "-2.8297758269584996\n",
      "length of actions is  1000\n",
      "218.0893411855092\n",
      "length of actions is  889\n",
      "96.45423310125051\n",
      "length of actions is  749\n",
      "224.52524549787805\n",
      "length of actions is  412\n",
      "Your final reward is : 123.57\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2976])\n",
      "62.95316098624471\n",
      "length of actions is  953\n",
      "119.73230421524579\n",
      "length of actions is  638\n",
      "201.72713909645165\n",
      "length of actions is  487\n",
      "227.98317614700605\n",
      "length of actions is  532\n",
      "243.73415824502496\n",
      "length of actions is  547\n",
      "Your final reward is : 171.23\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2316])\n",
      "96.86155749218047\n",
      "length of actions is  775\n",
      "246.46066477638158\n",
      "length of actions is  435\n",
      "162.41986509336627\n",
      "length of actions is  644\n",
      "-61.58599388019814\n",
      "length of actions is  1000\n",
      "46.809093722732385\n",
      "length of actions is  1000\n",
      "Your final reward is : 98.19\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1773])\n",
      "-114.74670736716955\n",
      "length of actions is  644\n",
      "-39.58259749763124\n",
      "length of actions is  204\n",
      "-81.18036618504439\n",
      "length of actions is  442\n",
      "194.25982940925923\n",
      "length of actions is  482\n",
      "142.7110361361101\n",
      "length of actions is  1000\n",
      "Your final reward is : 20.29\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2974])\n",
      "81.5189197254051\n",
      "length of actions is  830\n",
      "128.53505158092221\n",
      "length of actions is  523\n",
      "106.83378390581237\n",
      "length of actions is  879\n",
      "207.20611750607367\n",
      "length of actions is  424\n",
      "-78.70086701396734\n",
      "length of actions is  1000\n",
      "Your final reward is : 89.08\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2600])\n",
      "-77.78873641555236\n",
      "length of actions is  1000\n",
      "238.2919147894468\n",
      "length of actions is  419\n",
      "141.2312365103398\n",
      "length of actions is  575\n",
      "220.5553462540698\n",
      "length of actions is  554\n",
      "176.48754678890162\n",
      "length of actions is  389\n",
      "Your final reward is : 139.76\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3857])\n",
      "-80.04222007748304\n",
      "length of actions is  1000\n",
      "231.89688614159653\n",
      "length of actions is  417\n",
      "210.4273519193976\n",
      "length of actions is  480\n",
      "99.49187385421445\n",
      "length of actions is  1000\n",
      "91.55696828687368\n",
      "length of actions is  1000\n",
      "Your final reward is : 110.67\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4888])\n",
      "77.26261890820027\n",
      "length of actions is  900\n",
      "133.70332729643167\n",
      "length of actions is  833\n",
      "-53.640700211205896\n",
      "length of actions is  1000\n",
      "148.89286098275699\n",
      "length of actions is  717\n",
      "141.1034242102241\n",
      "length of actions is  898\n",
      "Your final reward is : 89.46\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2978])\n",
      "45.417379561302326\n",
      "length of actions is  990\n",
      "225.60618609580612\n",
      "length of actions is  522\n",
      "63.490875088031665\n",
      "length of actions is  1000\n",
      "130.12093386194655\n",
      "length of actions is  818\n",
      "226.22506527711786\n",
      "length of actions is  448\n",
      "Your final reward is : 138.17\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2464])\n",
      "-86.11314566708666\n",
      "length of actions is  1000\n",
      "263.6858921752457\n",
      "length of actions is  374\n",
      "193.99852269815307\n",
      "length of actions is  242\n",
      "175.9650300820658\n",
      "length of actions is  358\n",
      "127.32261955121527\n",
      "length of actions is  905\n",
      "Your final reward is : 134.97\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1963])\n",
      "-88.47916839843188\n",
      "length of actions is  1000\n",
      "278.39560289265347\n",
      "length of actions is  333\n",
      "146.01395995678843\n",
      "length of actions is  625\n",
      "127.19414014704594\n",
      "length of actions is  419\n",
      "28.053824736845094\n",
      "length of actions is  1000\n",
      "Your final reward is : 98.24\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3275])\n",
      "86.16511223488658\n",
      "length of actions is  873\n",
      "-4.645662847394025\n",
      "length of actions is  1000\n",
      "118.22952147826564\n",
      "length of actions is  688\n",
      "237.03646998246393\n",
      "length of actions is  440\n",
      "189.774143958482\n",
      "length of actions is  447\n",
      "Your final reward is : 125.31\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2837])\n",
      "86.20162669285351\n",
      "length of actions is  848\n",
      "188.96878575750569\n",
      "length of actions is  302\n",
      "22.91112036234105\n",
      "length of actions is  1000\n",
      "51.23082916554175\n",
      "length of actions is  955\n",
      "216.042522897609\n",
      "length of actions is  335\n",
      "Your final reward is : 113.07\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2834])\n",
      "85.47927177728978\n",
      "length of actions is  958\n",
      "250.01517035680172\n",
      "length of actions is  415\n",
      "176.37379291178274\n",
      "length of actions is  322\n",
      "229.41607548488204\n",
      "length of actions is  366\n",
      "-43.54528490745931\n",
      "length of actions is  1000\n",
      "Your final reward is : 139.55\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2316])\n",
      "-46.65258598327624\n",
      "length of actions is  1000\n",
      "250.92147535779728\n",
      "length of actions is  377\n",
      "183.69681736707594\n",
      "length of actions is  281\n",
      "205.48347388269025\n",
      "length of actions is  598\n",
      "155.04503100260212\n",
      "length of actions is  1000\n",
      "Your final reward is : 149.70\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1734])\n",
      "-117.43125209972324\n",
      "length of actions is  513\n",
      "-53.2081423752158\n",
      "length of actions is  233\n",
      "230.3509215678259\n",
      "length of actions is  378\n",
      "118.89468810586716\n",
      "length of actions is  664\n",
      "240.24937525878892\n",
      "length of actions is  405\n",
      "Your final reward is : 83.77\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2991])\n",
      "-27.000395591940645\n",
      "length of actions is  1000\n",
      "141.2834758487442\n",
      "length of actions is  1000\n",
      "125.39925267175227\n",
      "length of actions is  1000\n",
      "136.42211134634618\n",
      "length of actions is  546\n",
      "119.65887779182435\n",
      "length of actions is  1000\n",
      "Your final reward is : 99.15\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1605])\n",
      "-89.19809877215067\n",
      "length of actions is  270\n",
      "-85.91848301314212\n",
      "length of actions is  272\n",
      "73.61057527279766\n",
      "length of actions is  788\n",
      "191.3799851539884\n",
      "length of actions is  390\n",
      "-23.401771402125064\n",
      "length of actions is  407\n",
      "Your final reward is : 13.29\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3098])\n",
      "-119.2319397256496\n",
      "length of actions is  649\n",
      "224.5453838616933\n",
      "length of actions is  403\n",
      "-51.59117671547408\n",
      "length of actions is  173\n",
      "-24.936391098554253\n",
      "length of actions is  266\n",
      "-42.59140614947637\n",
      "length of actions is  1000\n",
      "Your final reward is : -2.76\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1734])\n",
      "-109.04264922447251\n",
      "length of actions is  450\n",
      "261.9157373697817\n",
      "length of actions is  382\n",
      "68.93635105581363\n",
      "length of actions is  867\n",
      "253.18860678091465\n",
      "length of actions is  390\n",
      "142.41333161861394\n",
      "length of actions is  677\n",
      "Your final reward is : 123.48\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2421])\n",
      "156.84632863299137\n",
      "length of actions is  710\n",
      "-26.059511928163573\n",
      "length of actions is  278\n",
      "-49.89503316966908\n",
      "length of actions is  280\n",
      "-17.214280180953338\n",
      "length of actions is  280\n",
      "237.09144710208486\n",
      "length of actions is  426\n",
      "Your final reward is : 60.15\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3797])\n",
      "-106.03281400755772\n",
      "length of actions is  394\n",
      "246.6564128399513\n",
      "length of actions is  356\n",
      "107.94024577477316\n",
      "length of actions is  763\n",
      "231.7453626222832\n",
      "length of actions is  466\n",
      "209.42609162634312\n",
      "length of actions is  447\n",
      "Your final reward is : 137.95\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2147])\n",
      "-117.05560018322524\n",
      "length of actions is  494\n",
      "246.55661592879537\n",
      "length of actions is  381\n",
      "61.74886676661163\n",
      "length of actions is  1000\n",
      "-44.31524086921062\n",
      "length of actions is  202\n",
      "-82.6785835147706\n",
      "length of actions is  1000\n",
      "Your final reward is : 12.85\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1851])\n",
      "-93.60626471885065\n",
      "length of actions is  361\n",
      "219.72723315155895\n",
      "length of actions is  384\n",
      "-54.784650362992146\n",
      "length of actions is  168\n",
      "257.7454792599592\n",
      "length of actions is  358\n",
      "122.61210778079312\n",
      "length of actions is  1000\n",
      "Your final reward is : 90.34\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3177])\n",
      "-109.72489827917497\n",
      "length of actions is  468\n",
      "78.47401741753661\n",
      "length of actions is  1000\n",
      "69.0270015696347\n",
      "length of actions is  781\n",
      "263.2592354629302\n",
      "length of actions is  335\n",
      "-97.93864417533472\n",
      "length of actions is  1000\n",
      "Your final reward is : 40.62\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2462])\n",
      "-91.86578507900259\n",
      "length of actions is  1000\n",
      "148.9565050486813\n",
      "length of actions is  1000\n",
      "121.61650109860828\n",
      "length of actions is  1000\n",
      "12.83991794490937\n",
      "length of actions is  1000\n",
      "46.71143910543176\n",
      "length of actions is  1000\n",
      "Your final reward is : 47.65\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2807])\n",
      "-99.17118287023426\n",
      "length of actions is  389\n",
      "-81.72752599406796\n",
      "length of actions is  1000\n",
      "-49.48097639246298\n",
      "length of actions is  1000\n",
      "251.31690704715868\n",
      "length of actions is  307\n",
      "179.9515243714131\n",
      "length of actions is  571\n",
      "Your final reward is : 40.18\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1996])\n",
      "-126.21895507207687\n",
      "length of actions is  538\n",
      "196.51851404886156\n",
      "length of actions is  271\n",
      "265.0684532477193\n",
      "length of actions is  341\n",
      "200.12504904130998\n",
      "length of actions is  809\n",
      "-38.37686431606129\n",
      "length of actions is  268\n",
      "Your final reward is : 99.42\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2156])\n",
      "-68.25650030434812\n",
      "length of actions is  1000\n",
      "178.72169685732163\n",
      "length of actions is  1000\n",
      "250.98495785529295\n",
      "length of actions is  433\n",
      "146.40978252619348\n",
      "length of actions is  1000\n",
      "110.12727447034176\n",
      "length of actions is  1000\n",
      "Your final reward is : 123.60\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2315])\n",
      "-64.53635176662826\n",
      "length of actions is  1000\n",
      "267.74711986628586\n",
      "length of actions is  321\n",
      "227.77822593958555\n",
      "length of actions is  786\n",
      "133.05874143573797\n",
      "length of actions is  1000\n",
      "110.87910756188298\n",
      "length of actions is  616\n",
      "Your final reward is : 134.99\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2126])\n",
      "-66.75955832511472\n",
      "length of actions is  1000\n",
      "286.1090532321906\n",
      "length of actions is  318\n",
      "215.69191732179002\n",
      "length of actions is  241\n",
      "294.68250188864886\n",
      "length of actions is  301\n",
      "221.16974364351086\n",
      "length of actions is  205\n",
      "Your final reward is : 190.18\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1505])\n",
      "43.04163485306256\n",
      "length of actions is  921\n",
      "-28.515785354726148\n",
      "length of actions is  217\n",
      "227.53935660112435\n",
      "length of actions is  275\n",
      "194.862197159741\n",
      "length of actions is  335\n",
      "-77.3026610990767\n",
      "length of actions is  1000\n",
      "Your final reward is : 71.92\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1577])\n",
      "-61.49172652507215\n",
      "length of actions is  1000\n",
      "283.0109345676575\n",
      "length of actions is  309\n",
      "229.06058795014155\n",
      "length of actions is  376\n",
      "238.34434745313928\n",
      "length of actions is  301\n",
      "276.16018292554844\n",
      "length of actions is  292\n",
      "Your final reward is : 193.02\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3197])\n",
      "-84.21476154971997\n",
      "length of actions is  1000\n",
      "282.0403145753586\n",
      "length of actions is  289\n",
      "74.03308081024542\n",
      "length of actions is  1000\n",
      "100.53371650147669\n",
      "length of actions is  1000\n",
      "193.0063129660785\n",
      "length of actions is  372\n",
      "Your final reward is : 113.08\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3176])\n",
      "93.64748049426801\n",
      "length of actions is  808\n",
      "209.05154652111455\n",
      "length of actions is  271\n",
      "138.28583232331283\n",
      "length of actions is  811\n",
      "249.5504119132386\n",
      "length of actions is  659\n",
      "-53.32549803445896\n",
      "length of actions is  179\n",
      "Your final reward is : 127.44\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3117])\n",
      "-56.22376491271304\n",
      "length of actions is  1000\n",
      "286.93089943874963\n",
      "length of actions is  285\n",
      "186.00206726467846\n",
      "length of actions is  563\n",
      "244.59708217201106\n",
      "length of actions is  413\n",
      "48.05113845319241\n",
      "length of actions is  1000\n",
      "Your final reward is : 141.87\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3138])\n",
      "-62.031168919379645\n",
      "length of actions is  1000\n",
      "38.07226098170173\n",
      "length of actions is  211\n",
      "234.52942306725433\n",
      "length of actions is  365\n",
      "268.2642051141639\n",
      "length of actions is  295\n",
      "-27.79451981502587\n",
      "length of actions is  1000\n",
      "Your final reward is : 90.21\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2491])\n",
      "-69.9709129735845\n",
      "length of actions is  1000\n",
      "168.81837484080864\n",
      "length of actions is  1000\n",
      "260.5229983949871\n",
      "length of actions is  323\n",
      "165.79117401509055\n",
      "length of actions is  307\n",
      "-65.39772074180033\n",
      "length of actions is  1000\n",
      "Your final reward is : 91.95\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2084])\n",
      "-53.09179668703109\n",
      "length of actions is  1000\n",
      "285.2592398690026\n",
      "length of actions is  302\n",
      "248.00657085481163\n",
      "length of actions is  359\n",
      "143.2027861269878\n",
      "length of actions is  875\n",
      "278.2192864312803\n",
      "length of actions is  291\n",
      "Your final reward is : 180.32\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2744])\n",
      "-60.02200072373486\n",
      "length of actions is  1000\n",
      "250.95044209073018\n",
      "length of actions is  276\n",
      "290.78177820501935\n",
      "length of actions is  276\n",
      "163.93275422432163\n",
      "length of actions is  647\n",
      "34.05504965046258\n",
      "length of actions is  1000\n",
      "Your final reward is : 135.94\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3785])\n",
      "-64.85883352009007\n",
      "length of actions is  1000\n",
      "124.5984291018872\n",
      "length of actions is  1000\n",
      "143.43209879090955\n",
      "length of actions is  1000\n",
      "-54.39407686736558\n",
      "length of actions is  1000\n",
      "6.509756965732487\n",
      "length of actions is  1000\n",
      "Your final reward is : 31.06\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3898])\n",
      "-71.49384636057587\n",
      "length of actions is  1000\n",
      "18.984525073260173\n",
      "length of actions is  199\n",
      "11.739077134674964\n",
      "length of actions is  1000\n",
      "168.9396646096416\n",
      "length of actions is  1000\n",
      "-55.740737020162996\n",
      "length of actions is  1000\n",
      "Your final reward is : 14.49\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2838])\n",
      "-58.53466961174473\n",
      "length of actions is  1000\n",
      "24.889821300005806\n",
      "length of actions is  190\n",
      "-40.88408701332163\n",
      "length of actions is  1000\n",
      "259.66402616863263\n",
      "length of actions is  341\n",
      "276.92173556343414\n",
      "length of actions is  305\n",
      "Your final reward is : 92.41\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4152])\n",
      "-44.32634336528126\n",
      "length of actions is  1000\n",
      "13.337258751743732\n",
      "length of actions is  177\n",
      "51.2377090350015\n",
      "length of actions is  179\n",
      "-24.36129854734637\n",
      "length of actions is  1000\n",
      "-30.463064664241074\n",
      "length of actions is  1000\n",
      "Your final reward is : -6.92\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2971])\n",
      "-72.80379186179057\n",
      "length of actions is  1000\n",
      "32.145879807113346\n",
      "length of actions is  193\n",
      "-40.8110720407445\n",
      "length of actions is  1000\n",
      "199.34146919078546\n",
      "length of actions is  263\n",
      "190.76716312706867\n",
      "length of actions is  269\n",
      "Your final reward is : 61.73\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2515])\n",
      "-54.966564902907976\n",
      "length of actions is  1000\n",
      "26.79089086462031\n",
      "length of actions is  185\n",
      "38.92095301624073\n",
      "length of actions is  201\n",
      "165.74685114130196\n",
      "length of actions is  670\n",
      "187.40175716460487\n",
      "length of actions is  489\n",
      "Your final reward is : 72.78\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2139])\n",
      "71.04501528741027\n",
      "length of actions is  896\n",
      "-33.740617295500776\n",
      "length of actions is  1000\n",
      "135.89495587979778\n",
      "length of actions is  501\n",
      "107.91159453374868\n",
      "length of actions is  733\n",
      "227.1456416578977\n",
      "length of actions is  278\n",
      "Your final reward is : 101.65\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2216])\n",
      "-51.6688009804119\n",
      "length of actions is  1000\n",
      "21.998170036596562\n",
      "length of actions is  184\n",
      "261.94284316718966\n",
      "length of actions is  294\n",
      "119.15599247503047\n",
      "length of actions is  860\n",
      "-29.44236345530466\n",
      "length of actions is  208\n",
      "Your final reward is : 64.40\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2980])\n",
      "-38.9642907823213\n",
      "length of actions is  1000\n",
      "37.54467340928727\n",
      "length of actions is  195\n",
      "209.49022316328967\n",
      "length of actions is  632\n",
      "-36.68165580571424\n",
      "length of actions is  1000\n",
      "199.2307324204549\n",
      "length of actions is  266\n",
      "Your final reward is : 74.12\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2098])\n",
      "-61.943638643838725\n",
      "length of actions is  1000\n",
      "55.62783066813168\n",
      "length of actions is  200\n",
      "40.174068331899996\n",
      "length of actions is  1000\n",
      "-32.504481546538564\n",
      "length of actions is  1000\n",
      "151.1665847550551\n",
      "length of actions is  550\n",
      "Your final reward is : 30.50\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3248])\n",
      "-46.68415750504491\n",
      "length of actions is  1000\n",
      "46.521095382515995\n",
      "length of actions is  193\n",
      "-5.126092963155511\n",
      "length of actions is  1000\n",
      "-43.27467736758255\n",
      "length of actions is  1000\n",
      "160.28706241919272\n",
      "length of actions is  1000\n",
      "Your final reward is : 22.34\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2974])\n",
      "-35.882259865492536\n",
      "length of actions is  1000\n",
      "282.8765611907765\n",
      "length of actions is  316\n",
      "136.10178397566014\n",
      "length of actions is  850\n",
      "169.91807348717447\n",
      "length of actions is  631\n",
      "232.75328300859243\n",
      "length of actions is  423\n",
      "Your final reward is : 157.15\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3347])\n",
      "-71.453747637862\n",
      "length of actions is  1000\n",
      "256.7481618791753\n",
      "length of actions is  430\n",
      "247.2901695730655\n",
      "length of actions is  522\n",
      "81.5780694727097\n",
      "length of actions is  1000\n",
      "207.95813623939023\n",
      "length of actions is  749\n",
      "Your final reward is : 144.42\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2974])\n",
      "-33.31801881261233\n",
      "length of actions is  1000\n",
      "274.28164754723457\n",
      "length of actions is  342\n",
      "209.3769554840366\n",
      "length of actions is  395\n",
      "154.7067829923013\n",
      "length of actions is  758\n",
      "-46.4277522779514\n",
      "length of actions is  1000\n",
      "Your final reward is : 111.72\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3481])\n",
      "-39.76902811318006\n",
      "length of actions is  1000\n",
      "147.96062004673118\n",
      "length of actions is  1000\n",
      "223.9248587385357\n",
      "length of actions is  474\n",
      "224.8456844991129\n",
      "length of actions is  481\n",
      "191.97365237039926\n",
      "length of actions is  554\n",
      "Your final reward is : 149.79\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3281])\n",
      "-41.35500705392067\n",
      "length of actions is  1000\n",
      "270.47166025435706\n",
      "length of actions is  328\n",
      "138.42234074099326\n",
      "length of actions is  1000\n",
      "-24.855075873666983\n",
      "length of actions is  1000\n",
      "135.50357081816594\n",
      "length of actions is  1000\n",
      "Your final reward is : 95.64\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3714])\n",
      "-32.65365455252023\n",
      "length of actions is  1000\n",
      "30.12328778210403\n",
      "length of actions is  188\n",
      "289.18390469131504\n",
      "length of actions is  274\n",
      "279.3518324478829\n",
      "length of actions is  420\n",
      "267.14539051478675\n",
      "length of actions is  306\n",
      "Your final reward is : 166.63\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2657])\n",
      "-31.604124310241858\n",
      "length of actions is  1000\n",
      "290.7641496907302\n",
      "length of actions is  250\n",
      "242.5294655485873\n",
      "length of actions is  407\n",
      "-6.847705952422574\n",
      "length of actions is  1000\n",
      "232.19440082304612\n",
      "length of actions is  453\n",
      "Your final reward is : 145.41\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2871])\n",
      "-16.019677097924337\n",
      "length of actions is  1000\n",
      "285.52060982391674\n",
      "length of actions is  300\n",
      "73.15481840481692\n",
      "length of actions is  1000\n",
      "190.6122117852526\n",
      "length of actions is  441\n",
      "217.1534918807411\n",
      "length of actions is  393\n",
      "Your final reward is : 150.08\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3157])\n",
      "-23.789664556495563\n",
      "length of actions is  1000\n",
      "242.98631564810069\n",
      "length of actions is  363\n",
      "38.987823292298124\n",
      "length of actions is  1000\n",
      "187.735550899877\n",
      "length of actions is  560\n",
      "150.71569548686705\n",
      "length of actions is  686\n",
      "Your final reward is : 119.33\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3146])\n",
      "-25.780159763938702\n",
      "length of actions is  1000\n",
      "29.322933114660202\n",
      "length of actions is  188\n",
      "294.6866524801467\n",
      "length of actions is  260\n",
      "45.32856403552517\n",
      "length of actions is  1000\n",
      "277.2467298274323\n",
      "length of actions is  237\n",
      "Your final reward is : 124.16\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2600])\n",
      "141.9003460930159\n",
      "length of actions is  826\n",
      "277.0198068991372\n",
      "length of actions is  291\n",
      "241.2419015302415\n",
      "length of actions is  281\n",
      "259.3122265072144\n",
      "length of actions is  279\n",
      "256.5846772309487\n",
      "length of actions is  284\n",
      "Your final reward is : 235.21\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2605])\n",
      "151.34407587892838\n",
      "length of actions is  640\n",
      "247.85896603553522\n",
      "length of actions is  289\n",
      "198.82414912619043\n",
      "length of actions is  755\n",
      "72.47057189130047\n",
      "length of actions is  208\n",
      "143.3736411429683\n",
      "length of actions is  997\n",
      "Your final reward is : 162.77\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1963])\n",
      "183.26724050704397\n",
      "length of actions is  607\n",
      "263.57866333957463\n",
      "length of actions is  247\n",
      "168.96256546378805\n",
      "length of actions is  285\n",
      "214.2419100782424\n",
      "length of actions is  794\n",
      "239.7282852085721\n",
      "length of actions is  367\n",
      "Your final reward is : 213.96\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3480])\n",
      "185.12942504494967\n",
      "length of actions is  262\n",
      "58.87314573664867\n",
      "length of actions is  185\n",
      "261.1598007304607\n",
      "length of actions is  249\n",
      "257.3134352059585\n",
      "length of actions is  266\n",
      "44.07642833554897\n",
      "length of actions is  209\n",
      "Your final reward is : 161.31\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2161])\n",
      "182.95038554252307\n",
      "length of actions is  280\n",
      "227.63178813573722\n",
      "length of actions is  292\n",
      "257.87501446268857\n",
      "length of actions is  257\n",
      "231.27697156291\n",
      "length of actions is  259\n",
      "206.32033854478573\n",
      "length of actions is  360\n",
      "Your final reward is : 221.21\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1534])\n",
      "79.06569296527186\n",
      "length of actions is  1000\n",
      "285.191787421133\n",
      "length of actions is  286\n",
      "231.00516898788152\n",
      "length of actions is  339\n",
      "275.6329971025936\n",
      "length of actions is  308\n",
      "238.09743167475025\n",
      "length of actions is  382\n",
      "Your final reward is : 221.80\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1429])\n",
      "79.25551913042086\n",
      "length of actions is  1000\n",
      "278.5281295773261\n",
      "length of actions is  276\n",
      "292.88094775658266\n",
      "length of actions is  372\n",
      "272.8736367518783\n",
      "length of actions is  239\n",
      "227.71737154257931\n",
      "length of actions is  277\n",
      "Your final reward is : 230.25\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1497])\n",
      "210.50625858832288\n",
      "length of actions is  338\n",
      "217.86073025554015\n",
      "length of actions is  320\n",
      "156.84658551677836\n",
      "length of actions is  806\n",
      "92.52618121513359\n",
      "length of actions is  1000\n",
      "267.729852523942\n",
      "length of actions is  234\n",
      "Your final reward is : 189.09\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1734])\n",
      "188.45409821007019\n",
      "length of actions is  262\n",
      "45.44731128545749\n",
      "length of actions is  182\n",
      "59.398412848787785\n",
      "length of actions is  233\n",
      "62.3129152365818\n",
      "length of actions is  237\n",
      "287.9886732688295\n",
      "length of actions is  305\n",
      "Your final reward is : 128.72\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2014])\n",
      "147.63700002967022\n",
      "length of actions is  650\n",
      "219.00636844084394\n",
      "length of actions is  331\n",
      "223.62093701977713\n",
      "length of actions is  526\n",
      "115.4323096327466\n",
      "length of actions is  1000\n",
      "93.97419791112668\n",
      "length of actions is  1000\n",
      "Your final reward is : 159.93\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2340])\n",
      "124.23247534718077\n",
      "length of actions is  872\n",
      "256.60211441200045\n",
      "length of actions is  241\n",
      "248.34126013279484\n",
      "length of actions is  278\n",
      "208.7818913595666\n",
      "length of actions is  454\n",
      "281.0663587158749\n",
      "length of actions is  253\n",
      "Your final reward is : 223.80\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1734])\n",
      "-17.564649718799526\n",
      "length of actions is  1000\n",
      "60.548241823503986\n",
      "length of actions is  215\n",
      "78.35114259087857\n",
      "length of actions is  204\n",
      "229.8401430519676\n",
      "length of actions is  249\n",
      "285.26290361470694\n",
      "length of actions is  287\n",
      "Your final reward is : 127.29\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2818])\n",
      "153.15421767392638\n",
      "length of actions is  720\n",
      "246.80288062060683\n",
      "length of actions is  239\n",
      "259.3142717739172\n",
      "length of actions is  256\n",
      "31.374142254673842\n",
      "length of actions is  225\n",
      "72.27499337126659\n",
      "length of actions is  1000\n",
      "Your final reward is : 152.58\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2082])\n",
      "-16.001670686633613\n",
      "length of actions is  1000\n",
      "283.3517975766482\n",
      "length of actions is  274\n",
      "247.04170368298907\n",
      "length of actions is  252\n",
      "47.769882243415196\n",
      "length of actions is  214\n",
      "211.10866418349266\n",
      "length of actions is  493\n",
      "Your final reward is : 154.65\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3655])\n",
      "151.83709980273713\n",
      "length of actions is  674\n",
      "151.6794273177435\n",
      "length of actions is  826\n",
      "228.00774013356965\n",
      "length of actions is  755\n",
      "156.96046787202823\n",
      "length of actions is  1000\n",
      "101.61264873704668\n",
      "length of actions is  1000\n",
      "Your final reward is : 158.02\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2414])\n",
      "165.69813191466886\n",
      "length of actions is  692\n",
      "171.94251795424134\n",
      "length of actions is  768\n",
      "167.66186490348582\n",
      "length of actions is  377\n",
      "120.61526391953751\n",
      "length of actions is  1000\n",
      "148.8356426982381\n",
      "length of actions is  1000\n",
      "Your final reward is : 154.95\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1595])\n",
      "-21.42342296595829\n",
      "length of actions is  1000\n",
      "275.8075297085648\n",
      "length of actions is  319\n",
      "182.2538504852396\n",
      "length of actions is  664\n",
      "253.20561586324922\n",
      "length of actions is  228\n",
      "264.0924798891526\n",
      "length of actions is  260\n",
      "Your final reward is : 190.79\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2082])\n",
      "170.8186347134847\n",
      "length of actions is  690\n",
      "276.43634468949153\n",
      "length of actions is  283\n",
      "202.1212038680476\n",
      "length of actions is  409\n",
      "235.4336088542003\n",
      "length of actions is  557\n",
      "243.1170662899565\n",
      "length of actions is  262\n",
      "Your final reward is : 225.59\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2412])\n",
      "172.93955985546694\n",
      "length of actions is  706\n",
      "290.892693307414\n",
      "length of actions is  274\n",
      "270.6787265799338\n",
      "length of actions is  237\n",
      "236.3810046478772\n",
      "length of actions is  311\n",
      "58.96636031945201\n",
      "length of actions is  195\n",
      "Your final reward is : 205.97\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2867])\n",
      "164.88592819644327\n",
      "length of actions is  710\n",
      "257.3323960293743\n",
      "length of actions is  517\n",
      "8.341497230006729\n",
      "length of actions is  1000\n",
      "143.50637513958344\n",
      "length of actions is  1000\n",
      "298.29644482963766\n",
      "length of actions is  279\n",
      "Your final reward is : 174.47\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2525])\n",
      "213.69671638146866\n",
      "length of actions is  414\n",
      "178.43432386567446\n",
      "length of actions is  698\n",
      "257.37303463437206\n",
      "length of actions is  251\n",
      "232.58676920696223\n",
      "length of actions is  244\n",
      "259.89026759131787\n",
      "length of actions is  285\n",
      "Your final reward is : 228.40\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2660])\n",
      "206.6596665398166\n",
      "length of actions is  575\n",
      "211.67026289474197\n",
      "length of actions is  396\n",
      "95.12928958020082\n",
      "length of actions is  1000\n",
      "224.9489814884039\n",
      "length of actions is  264\n",
      "288.97248709941624\n",
      "length of actions is  243\n",
      "Your final reward is : 205.48\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2454])\n",
      "154.04505301411356\n",
      "length of actions is  691\n",
      "242.03020751679108\n",
      "length of actions is  253\n",
      "259.4405095744446\n",
      "length of actions is  300\n",
      "269.1314858497875\n",
      "length of actions is  264\n",
      "256.7111434924425\n",
      "length of actions is  291\n",
      "Your final reward is : 236.27\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2241])\n",
      "174.96848718503816\n",
      "length of actions is  627\n",
      "234.58562238729124\n",
      "length of actions is  341\n",
      "244.57163347411677\n",
      "length of actions is  324\n",
      "217.65318916801755\n",
      "length of actions is  407\n",
      "207.21201969747955\n",
      "length of actions is  545\n",
      "Your final reward is : 215.80\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1587])\n",
      "171.32516320866793\n",
      "length of actions is  843\n",
      "273.86177350629976\n",
      "length of actions is  268\n",
      "151.02934855665148\n",
      "length of actions is  1000\n",
      "221.01372512143627\n",
      "length of actions is  308\n",
      "226.54902022899338\n",
      "length of actions is  307\n",
      "Your final reward is : 208.76\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1970])\n",
      "185.33444646578965\n",
      "length of actions is  626\n",
      "223.68700761739873\n",
      "length of actions is  589\n",
      "260.204647817083\n",
      "length of actions is  308\n",
      "234.1768842894232\n",
      "length of actions is  283\n",
      "277.2276627288111\n",
      "length of actions is  270\n",
      "Your final reward is : 236.13\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3098])\n",
      "177.6038476872253\n",
      "length of actions is  682\n",
      "170.27678702175942\n",
      "length of actions is  1000\n",
      "226.06431687519841\n",
      "length of actions is  425\n",
      "127.62323639051897\n",
      "length of actions is  1000\n",
      "184.98737359402844\n",
      "length of actions is  669\n",
      "Your final reward is : 177.31\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2303])\n",
      "168.81417633424402\n",
      "length of actions is  713\n",
      "227.4039932845055\n",
      "length of actions is  262\n",
      "235.66956305886367\n",
      "length of actions is  235\n",
      "259.9136929145842\n",
      "length of actions is  276\n",
      "246.0060197802583\n",
      "length of actions is  232\n",
      "Your final reward is : 227.56\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2275])\n",
      "16.234677975936624\n",
      "length of actions is  1000\n",
      "294.121569228604\n",
      "length of actions is  252\n",
      "224.83927052569115\n",
      "length of actions is  297\n",
      "227.46529175241773\n",
      "length of actions is  667\n",
      "306.8051210366119\n",
      "length of actions is  261\n",
      "Your final reward is : 213.89\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2502])\n",
      "173.2341602937941\n",
      "length of actions is  631\n",
      "134.00462029854083\n",
      "length of actions is  771\n",
      "255.07305183684133\n",
      "length of actions is  290\n",
      "309.8493627822224\n",
      "length of actions is  279\n",
      "233.26461348218166\n",
      "length of actions is  230\n",
      "Your final reward is : 221.09\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2835])\n",
      "-10.074103158009411\n",
      "length of actions is  1000\n",
      "272.96824108611463\n",
      "length of actions is  267\n",
      "232.71789617865667\n",
      "length of actions is  257\n",
      "280.156008166596\n",
      "length of actions is  284\n",
      "226.2652593217037\n",
      "length of actions is  264\n",
      "Your final reward is : 200.41\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2018])\n",
      "-14.838950796435919\n",
      "length of actions is  1000\n",
      "286.92624377811103\n",
      "length of actions is  278\n",
      "-7.3630468963345805\n",
      "length of actions is  209\n",
      "173.9055678512485\n",
      "length of actions is  321\n",
      "215.58816490010867\n",
      "length of actions is  257\n",
      "Your final reward is : 130.84\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1707])\n",
      "220.34509512123577\n",
      "length of actions is  361\n",
      "141.1130502176817\n",
      "length of actions is  1000\n",
      "164.41112004488213\n",
      "length of actions is  728\n",
      "90.4300808747023\n",
      "length of actions is  1000\n",
      "33.016345256970624\n",
      "length of actions is  217\n",
      "Your final reward is : 129.86\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2490])\n",
      "64.64700933257029\n",
      "length of actions is  1000\n",
      "156.55147987272912\n",
      "length of actions is  1000\n",
      "150.84268249260228\n",
      "length of actions is  1000\n",
      "133.78747129090402\n",
      "length of actions is  874\n",
      "186.29871579134675\n",
      "length of actions is  294\n",
      "Your final reward is : 138.43\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2281])\n",
      "-23.572016894114636\n",
      "length of actions is  1000\n",
      "268.42028798778153\n",
      "length of actions is  350\n",
      "270.25632733940733\n",
      "length of actions is  281\n",
      "192.28814649501993\n",
      "length of actions is  506\n",
      "-54.35693204789601\n",
      "length of actions is  417\n",
      "Your final reward is : 130.61\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2867])\n",
      "-30.060750649633444\n",
      "length of actions is  1000\n",
      "267.3796181937923\n",
      "length of actions is  337\n",
      "248.20381282961785\n",
      "length of actions is  324\n",
      "207.77494797843372\n",
      "length of actions is  307\n",
      "250.12619527369054\n",
      "length of actions is  458\n",
      "Your final reward is : 188.68\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2186])\n",
      "-20.96609249172725\n",
      "length of actions is  1000\n",
      "265.4621569719952\n",
      "length of actions is  361\n",
      "225.51459833750158\n",
      "length of actions is  434\n",
      "163.41655738841206\n",
      "length of actions is  939\n",
      "156.69247221335607\n",
      "length of actions is  1000\n",
      "Your final reward is : 158.02\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3828])\n",
      "-16.437122794857533\n",
      "length of actions is  1000\n",
      "253.59626797000706\n",
      "length of actions is  426\n",
      "213.05638766315496\n",
      "length of actions is  355\n",
      "224.6827624485612\n",
      "length of actions is  367\n",
      "228.64094033375454\n",
      "length of actions is  319\n",
      "Your final reward is : 180.71\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3249])\n",
      "130.65419999639948\n",
      "length of actions is  830\n",
      "170.4658706318404\n",
      "length of actions is  730\n",
      "216.73391488985197\n",
      "length of actions is  406\n",
      "189.24250155077505\n",
      "length of actions is  496\n",
      "247.64143962119158\n",
      "length of actions is  410\n",
      "Your final reward is : 190.95\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3402])\n",
      "180.38456625282265\n",
      "length of actions is  695\n",
      "195.55055700897873\n",
      "length of actions is  701\n",
      "205.769419416306\n",
      "length of actions is  697\n",
      "252.3937185767109\n",
      "length of actions is  342\n",
      "191.82636965248452\n",
      "length of actions is  775\n",
      "Your final reward is : 205.18\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2744])\n",
      "175.35664382203356\n",
      "length of actions is  704\n",
      "112.04722205849498\n",
      "length of actions is  1000\n",
      "203.74812371863555\n",
      "length of actions is  440\n",
      "201.82907305425783\n",
      "length of actions is  671\n",
      "182.09276779103084\n",
      "length of actions is  843\n",
      "Your final reward is : 175.01\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3289])\n",
      "150.20985565906733\n",
      "length of actions is  861\n",
      "208.601397181785\n",
      "length of actions is  633\n",
      "245.40532658716205\n",
      "length of actions is  395\n",
      "16.640081033590192\n",
      "length of actions is  253\n",
      "150.40880439431243\n",
      "length of actions is  862\n",
      "Your final reward is : 154.25\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3772])\n",
      "147.55007694189678\n",
      "length of actions is  851\n",
      "205.11364393279104\n",
      "length of actions is  868\n",
      "223.67551800171145\n",
      "length of actions is  364\n",
      "150.15420019046854\n",
      "length of actions is  1000\n",
      "268.1401683317074\n",
      "length of actions is  381\n",
      "Your final reward is : 198.93\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3605])\n",
      "138.22537303982222\n",
      "length of actions is  791\n",
      "202.07951819879807\n",
      "length of actions is  543\n",
      "43.41546160334093\n",
      "length of actions is  1000\n",
      "155.19626728321268\n",
      "length of actions is  672\n",
      "186.28535287531867\n",
      "length of actions is  555\n",
      "Your final reward is : 145.04\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2224])\n",
      "-11.416488747648462\n",
      "length of actions is  1000\n",
      "260.44804702697917\n",
      "length of actions is  347\n",
      "223.15948963142438\n",
      "length of actions is  414\n",
      "241.42290696721233\n",
      "length of actions is  276\n",
      "161.52470089243732\n",
      "length of actions is  785\n",
      "Your final reward is : 175.03\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2142])\n",
      "127.46269449627643\n",
      "length of actions is  785\n",
      "220.97284194283213\n",
      "length of actions is  386\n",
      "93.72557766475225\n",
      "length of actions is  1000\n",
      "263.5285121148455\n",
      "length of actions is  266\n",
      "265.3761118466362\n",
      "length of actions is  363\n",
      "Your final reward is : 194.21\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2411])\n",
      "-14.066684943307006\n",
      "length of actions is  1000\n",
      "242.8628619421273\n",
      "length of actions is  336\n",
      "221.45990848554732\n",
      "length of actions is  429\n",
      "193.0570622996823\n",
      "length of actions is  526\n",
      "174.79182063734345\n",
      "length of actions is  954\n",
      "Your final reward is : 163.62\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2496])\n",
      "-28.11823281836163\n",
      "length of actions is  1000\n",
      "249.38182928134543\n",
      "length of actions is  321\n",
      "3.3277372453587644\n",
      "length of actions is  1000\n",
      "231.2067397233761\n",
      "length of actions is  502\n",
      "231.191362343599\n",
      "length of actions is  425\n",
      "Your final reward is : 137.40\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3751])\n",
      "-20.54996508531009\n",
      "length of actions is  1000\n",
      "259.6139864555019\n",
      "length of actions is  390\n",
      "189.7927482305339\n",
      "length of actions is  810\n",
      "34.111118871281626\n",
      "length of actions is  1000\n",
      "12.284852164825555\n",
      "length of actions is  1000\n",
      "Your final reward is : 95.05\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4088])\n",
      "-21.476883670883844\n",
      "length of actions is  1000\n",
      "259.96021732946997\n",
      "length of actions is  352\n",
      "41.56676556563872\n",
      "length of actions is  1000\n",
      "-53.478201268831555\n",
      "length of actions is  247\n",
      "-5.075503933348429\n",
      "length of actions is  227\n",
      "Your final reward is : 44.30\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3917])\n",
      "-47.70141085996495\n",
      "length of actions is  1000\n",
      "237.25638278146076\n",
      "length of actions is  411\n",
      "172.8457235948725\n",
      "length of actions is  791\n",
      "119.2956858580655\n",
      "length of actions is  948\n",
      "46.061158333202314\n",
      "length of actions is  1000\n",
      "Your final reward is : 105.55\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4038])\n",
      "-20.06305407478032\n",
      "length of actions is  1000\n",
      "253.4648812592486\n",
      "length of actions is  358\n",
      "52.01772040035005\n",
      "length of actions is  1000\n",
      "123.77332512024665\n",
      "length of actions is  894\n",
      "118.24050362959667\n",
      "length of actions is  1000\n",
      "Your final reward is : 105.49\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3833])\n",
      "-14.646667159489766\n",
      "length of actions is  1000\n",
      "258.9742037054956\n",
      "length of actions is  335\n",
      "60.943203689146785\n",
      "length of actions is  1000\n",
      "135.18329362871145\n",
      "length of actions is  889\n",
      "113.96581341099642\n",
      "length of actions is  900\n",
      "Your final reward is : 110.88\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3465])\n",
      "160.82092186300767\n",
      "length of actions is  699\n",
      "151.414237983489\n",
      "length of actions is  713\n",
      "209.73672752647076\n",
      "length of actions is  349\n",
      "39.04537523585779\n",
      "length of actions is  245\n",
      "3.282356628953476\n",
      "length of actions is  1000\n",
      "Your final reward is : 112.86\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3136])\n",
      "138.49427548189402\n",
      "length of actions is  882\n",
      "136.88784110181706\n",
      "length of actions is  663\n",
      "253.6447478134867\n",
      "length of actions is  271\n",
      "43.61189059045779\n",
      "length of actions is  255\n",
      "63.84531020215304\n",
      "length of actions is  1000\n",
      "Your final reward is : 127.30\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3964])\n",
      "115.70888778740078\n",
      "length of actions is  966\n",
      "214.4089298792358\n",
      "length of actions is  412\n",
      "178.0491676623903\n",
      "length of actions is  796\n",
      "39.13969409426614\n",
      "length of actions is  1000\n",
      "159.2067540387883\n",
      "length of actions is  633\n",
      "Your final reward is : 141.30\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3656])\n",
      "137.33961256569592\n",
      "length of actions is  730\n",
      "52.403778605955345\n",
      "length of actions is  1000\n",
      "86.94857413787607\n",
      "length of actions is  1000\n",
      "133.5152904336787\n",
      "length of actions is  801\n",
      "193.4866356988569\n",
      "length of actions is  416\n",
      "Your final reward is : 120.74\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3082])\n",
      "-22.571372116407204\n",
      "length of actions is  1000\n",
      "35.09794367238797\n",
      "length of actions is  240\n",
      "257.9415730332918\n",
      "length of actions is  379\n",
      "263.14212325211633\n",
      "length of actions is  364\n",
      "130.7753694514725\n",
      "length of actions is  950\n",
      "Your final reward is : 132.88\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3344])\n",
      "-9.80338240518791\n",
      "length of actions is  1000\n",
      "269.3110669032354\n",
      "length of actions is  354\n",
      "238.4476070444517\n",
      "length of actions is  356\n",
      "46.96199135044541\n",
      "length of actions is  1000\n",
      "93.92441627606703\n",
      "length of actions is  1000\n",
      "Your final reward is : 127.77\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3932])\n",
      "91.25459690751708\n",
      "length of actions is  921\n",
      "173.56963773338103\n",
      "length of actions is  558\n",
      "193.50054592375622\n",
      "length of actions is  603\n",
      "139.99092200817077\n",
      "length of actions is  851\n",
      "216.75661292353652\n",
      "length of actions is  688\n",
      "Your final reward is : 163.01\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2088])\n",
      "139.35768429726613\n",
      "length of actions is  707\n",
      "162.16120253142216\n",
      "length of actions is  728\n",
      "183.20897085783227\n",
      "length of actions is  541\n",
      "177.44444031728966\n",
      "length of actions is  609\n",
      "-18.0183732789546\n",
      "length of actions is  1000\n",
      "Your final reward is : 128.83\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3402])\n",
      "113.93693451594564\n",
      "length of actions is  793\n",
      "152.68310226048703\n",
      "length of actions is  651\n",
      "206.35583094347942\n",
      "length of actions is  454\n",
      "211.24220051453437\n",
      "length of actions is  475\n",
      "43.534008544725445\n",
      "length of actions is  1000\n",
      "Your final reward is : 145.55\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1705])\n",
      "-19.36760099770593\n",
      "length of actions is  1000\n",
      "256.17764420686046\n",
      "length of actions is  315\n",
      "230.5314634324411\n",
      "length of actions is  354\n",
      "-2.6352207882325445\n",
      "length of actions is  293\n",
      "56.2326830732291\n",
      "length of actions is  1000\n",
      "Your final reward is : 104.19\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2551])\n",
      "-4.605669487649049\n",
      "length of actions is  1000\n",
      "255.67783763704045\n",
      "length of actions is  290\n",
      "223.12630613675032\n",
      "length of actions is  421\n",
      "205.60904815456072\n",
      "length of actions is  460\n",
      "178.62417425170736\n",
      "length of actions is  637\n",
      "Your final reward is : 171.69\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2345])\n",
      "125.75420467580463\n",
      "length of actions is  753\n",
      "86.91085974227471\n",
      "length of actions is  1000\n",
      "7.8611901880268675\n",
      "length of actions is  233\n",
      "225.033210199803\n",
      "length of actions is  447\n",
      "221.71430081706717\n",
      "length of actions is  356\n",
      "Your final reward is : 133.45\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3326])\n",
      "128.1696166023673\n",
      "length of actions is  749\n",
      "-51.61310120201587\n",
      "length of actions is  211\n",
      "185.93511813848446\n",
      "length of actions is  517\n",
      "6.346139573275366\n",
      "length of actions is  169\n",
      "258.0097322045099\n",
      "length of actions is  307\n",
      "Your final reward is : 105.37\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3224])\n",
      "-22.532464799155232\n",
      "length of actions is  1000\n",
      "243.02071455537848\n",
      "length of actions is  341\n",
      "187.39329992666455\n",
      "length of actions is  859\n",
      "60.68038223198643\n",
      "length of actions is  1000\n",
      "173.61584335398211\n",
      "length of actions is  534\n",
      "Your final reward is : 128.44\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3318])\n",
      "-26.948770216386382\n",
      "length of actions is  1000\n",
      "250.8864017816706\n",
      "length of actions is  358\n",
      "136.0713439380156\n",
      "length of actions is  809\n",
      "246.87967879790915\n",
      "length of actions is  372\n",
      "-5.705354299849774\n",
      "length of actions is  1000\n",
      "Your final reward is : 120.24\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2502])\n",
      "145.6738803415755\n",
      "length of actions is  755\n",
      "163.89056687528645\n",
      "length of actions is  593\n",
      "224.25236907511288\n",
      "length of actions is  602\n",
      "31.439704988211687\n",
      "length of actions is  1000\n",
      "190.96257574114176\n",
      "length of actions is  573\n",
      "Your final reward is : 151.24\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3054])\n",
      "148.57756422712478\n",
      "length of actions is  851\n",
      "193.8630866996378\n",
      "length of actions is  561\n",
      "204.25462086009833\n",
      "length of actions is  438\n",
      "148.38317139082795\n",
      "length of actions is  945\n",
      "219.35021513984498\n",
      "length of actions is  388\n",
      "Your final reward is : 182.89\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3763])\n",
      "153.295890217946\n",
      "length of actions is  766\n",
      "242.4527153030302\n",
      "length of actions is  401\n",
      "251.03912878512187\n",
      "length of actions is  375\n",
      "223.5166707244343\n",
      "length of actions is  980\n",
      "76.07626039760639\n",
      "length of actions is  1000\n",
      "Your final reward is : 189.28\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2831])\n",
      "-1.9042244189758506\n",
      "length of actions is  1000\n",
      "252.85350511421854\n",
      "length of actions is  358\n",
      "183.6434564867447\n",
      "length of actions is  612\n",
      "47.579105640125704\n",
      "length of actions is  1000\n",
      "153.50908330371928\n",
      "length of actions is  697\n",
      "Your final reward is : 127.14\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3369])\n",
      "163.76959558413927\n",
      "length of actions is  738\n",
      "259.81756693787935\n",
      "length of actions is  340\n",
      "257.2066167738392\n",
      "length of actions is  309\n",
      "247.68889200988585\n",
      "length of actions is  272\n",
      "247.729098333842\n",
      "length of actions is  436\n",
      "Your final reward is : 235.24\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2412])\n",
      "132.96671229033112\n",
      "length of actions is  930\n",
      "220.81138337455013\n",
      "length of actions is  515\n",
      "239.75966346440165\n",
      "length of actions is  380\n",
      "262.2091134167683\n",
      "length of actions is  322\n",
      "151.40396890375203\n",
      "length of actions is  901\n",
      "Your final reward is : 201.43\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3224])\n",
      "140.255726451405\n",
      "length of actions is  862\n",
      "84.99151730968707\n",
      "length of actions is  1000\n",
      "58.306106580482876\n",
      "length of actions is  1000\n",
      "64.24615874800446\n",
      "length of actions is  1000\n",
      "129.39009015639257\n",
      "length of actions is  1000\n",
      "Your final reward is : 95.44\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4093])\n",
      "132.97345241328958\n",
      "length of actions is  923\n",
      "194.41746286668206\n",
      "length of actions is  632\n",
      "207.00450697628654\n",
      "length of actions is  460\n",
      "25.84025459604105\n",
      "length of actions is  1000\n",
      "254.411959596339\n",
      "length of actions is  334\n",
      "Your final reward is : 162.93\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3727])\n",
      "183.75324782582476\n",
      "length of actions is  646\n",
      "10.632154568754988\n",
      "length of actions is  1000\n",
      "246.16462369943235\n",
      "length of actions is  303\n",
      "190.36955877999387\n",
      "length of actions is  857\n",
      "213.03484589419958\n",
      "length of actions is  374\n",
      "Your final reward is : 168.79\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2729])\n",
      "151.23130169886966\n",
      "length of actions is  824\n",
      "185.09205331295982\n",
      "length of actions is  587\n",
      "128.32329935391385\n",
      "length of actions is  1000\n",
      "175.96289237201722\n",
      "length of actions is  602\n",
      "160.40103269407177\n",
      "length of actions is  966\n",
      "Your final reward is : 160.20\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3140])\n",
      "166.7369286069308\n",
      "length of actions is  729\n",
      "264.77416087347893\n",
      "length of actions is  299\n",
      "211.65936271586605\n",
      "length of actions is  461\n",
      "229.5172493449106\n",
      "length of actions is  350\n",
      "193.2893410359714\n",
      "length of actions is  394\n",
      "Your final reward is : 213.20\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3859])\n",
      "146.9739719543848\n",
      "length of actions is  850\n",
      "213.95459551055922\n",
      "length of actions is  715\n",
      "125.34449162199678\n",
      "length of actions is  1000\n",
      "82.88813626607968\n",
      "length of actions is  1000\n",
      "126.1612704155834\n",
      "length of actions is  1000\n",
      "Your final reward is : 139.06\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3371])\n",
      "162.71608278408115\n",
      "length of actions is  771\n",
      "219.71390448525824\n",
      "length of actions is  731\n",
      "214.72265689753982\n",
      "length of actions is  376\n",
      "131.832164795768\n",
      "length of actions is  1000\n",
      "179.9097200749191\n",
      "length of actions is  754\n",
      "Your final reward is : 181.78\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2948])\n",
      "185.2081651778369\n",
      "length of actions is  678\n",
      "213.43969751799654\n",
      "length of actions is  399\n",
      "253.53918759058533\n",
      "length of actions is  287\n",
      "217.96598303376268\n",
      "length of actions is  581\n",
      "209.2866082448756\n",
      "length of actions is  627\n",
      "Your final reward is : 215.89\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2734])\n",
      "163.8178633222363\n",
      "length of actions is  756\n",
      "242.73994674198474\n",
      "length of actions is  315\n",
      "204.27047808404137\n",
      "length of actions is  371\n",
      "256.011266675725\n",
      "length of actions is  319\n",
      "236.4846401914804\n",
      "length of actions is  524\n",
      "Your final reward is : 220.66\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2144])\n",
      "145.62445482687392\n",
      "length of actions is  811\n",
      "226.51458855658274\n",
      "length of actions is  511\n",
      "186.8527899121967\n",
      "length of actions is  699\n",
      "213.92150818760126\n",
      "length of actions is  704\n",
      "195.54801249209763\n",
      "length of actions is  620\n",
      "Your final reward is : 193.69\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2454])\n",
      "183.2260759356493\n",
      "length of actions is  697\n",
      "178.3533426716571\n",
      "length of actions is  1000\n",
      "213.6897132614218\n",
      "length of actions is  334\n",
      "230.96128591164444\n",
      "length of actions is  623\n",
      "234.03683412033962\n",
      "length of actions is  364\n",
      "Your final reward is : 208.05\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2197])\n",
      "194.39616090141095\n",
      "length of actions is  609\n",
      "216.82102664176227\n",
      "length of actions is  610\n",
      "183.06707239079032\n",
      "length of actions is  566\n",
      "220.14089689461088\n",
      "length of actions is  459\n",
      "245.49852818952454\n",
      "length of actions is  266\n",
      "Your final reward is : 211.98\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2948])\n",
      "190.03998585996197\n",
      "length of actions is  619\n",
      "198.45844517461273\n",
      "length of actions is  434\n",
      "214.86993549185252\n",
      "length of actions is  531\n",
      "197.96220094754943\n",
      "length of actions is  558\n",
      "174.43639642100538\n",
      "length of actions is  743\n",
      "Your final reward is : 195.15\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2687])\n",
      "169.34484437076\n",
      "length of actions is  726\n",
      "229.02051349667212\n",
      "length of actions is  479\n",
      "237.07659964236876\n",
      "length of actions is  554\n",
      "240.69067337355722\n",
      "length of actions is  372\n",
      "192.64634591188974\n",
      "length of actions is  438\n",
      "Your final reward is : 213.76\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2412])\n",
      "181.4995158560259\n",
      "length of actions is  678\n",
      "232.8097902721164\n",
      "length of actions is  484\n",
      "241.9819543613712\n",
      "length of actions is  409\n",
      "142.32177827827002\n",
      "length of actions is  553\n",
      "199.22424842949027\n",
      "length of actions is  696\n",
      "Your final reward is : 199.57\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3517])\n",
      "204.72395589478896\n",
      "length of actions is  516\n",
      "201.718794300475\n",
      "length of actions is  752\n",
      "102.57949772673365\n",
      "length of actions is  1000\n",
      "198.23373038616543\n",
      "length of actions is  601\n",
      "213.34069672040116\n",
      "length of actions is  521\n",
      "Your final reward is : 184.12\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2319])\n",
      "176.43487288439252\n",
      "length of actions is  704\n",
      "-46.65127101199461\n",
      "length of actions is  208\n",
      "-14.769878627260283\n",
      "length of actions is  190\n",
      "-296.8003694621677\n",
      "length of actions is  265\n",
      "-17.006954011895104\n",
      "length of actions is  192\n",
      "Your final reward is : -39.76\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2857])\n",
      "175.0241443272031\n",
      "length of actions is  704\n",
      "-10.903625691360745\n",
      "length of actions is  211\n",
      "214.4905887990233\n",
      "length of actions is  534\n",
      "113.11198906563536\n",
      "length of actions is  1000\n",
      "108.44174922189478\n",
      "length of actions is  1000\n",
      "Your final reward is : 120.03\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3108])\n",
      "177.02569158653677\n",
      "length of actions is  697\n",
      "6.783834379910843\n",
      "length of actions is  195\n",
      "204.52007818726963\n",
      "length of actions is  581\n",
      "225.13180050166505\n",
      "length of actions is  392\n",
      "218.84897810643008\n",
      "length of actions is  307\n",
      "Your final reward is : 166.46\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2432])\n",
      "187.66519520300213\n",
      "length of actions is  637\n",
      "215.1713883951357\n",
      "length of actions is  362\n",
      "231.98806094398557\n",
      "length of actions is  578\n",
      "232.46650363964176\n",
      "length of actions is  297\n",
      "116.55883125550818\n",
      "length of actions is  1000\n",
      "Your final reward is : 196.77\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1971])\n",
      "197.99505839442466\n",
      "length of actions is  602\n",
      "184.27617500671056\n",
      "length of actions is  778\n",
      "250.59656806171765\n",
      "length of actions is  339\n",
      "238.75805232873003\n",
      "length of actions is  350\n",
      "214.81742362729204\n",
      "length of actions is  390\n",
      "Your final reward is : 217.29\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1978])\n",
      "192.27460818269213\n",
      "length of actions is  635\n",
      "197.26632963765385\n",
      "length of actions is  759\n",
      "116.86921263716613\n",
      "length of actions is  1000\n",
      "83.0149391044417\n",
      "length of actions is  1000\n",
      "192.88594552526814\n",
      "length of actions is  288\n",
      "Your final reward is : 156.46\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3168])\n",
      "190.77556765088013\n",
      "length of actions is  630\n",
      "210.46318771139119\n",
      "length of actions is  446\n",
      "216.30062056687905\n",
      "length of actions is  345\n",
      "-11.316651686728463\n",
      "length of actions is  215\n",
      "224.84291126119803\n",
      "length of actions is  368\n",
      "Your final reward is : 166.21\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3250])\n",
      "90.47101178195555\n",
      "length of actions is  1000\n",
      "248.3828648331251\n",
      "length of actions is  368\n",
      "106.90007283746891\n",
      "length of actions is  1000\n",
      "212.49437685600353\n",
      "length of actions is  389\n",
      "219.05581966725538\n",
      "length of actions is  383\n",
      "Your final reward is : 175.46\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2879])\n",
      "236.8646357038477\n",
      "length of actions is  347\n",
      "241.03312214441246\n",
      "length of actions is  499\n",
      "183.1807395928082\n",
      "length of actions is  510\n",
      "139.75911280511178\n",
      "length of actions is  880\n",
      "219.3195589014737\n",
      "length of actions is  402\n",
      "Your final reward is : 204.03\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2505])\n",
      "186.5208804940928\n",
      "length of actions is  654\n",
      "198.70144029786996\n",
      "length of actions is  684\n",
      "198.24315345643535\n",
      "length of actions is  345\n",
      "214.42930771956392\n",
      "length of actions is  979\n",
      "232.67326898100663\n",
      "length of actions is  357\n",
      "Your final reward is : 206.11\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2867])\n",
      "186.4685225042359\n",
      "length of actions is  649\n",
      "209.24739113395634\n",
      "length of actions is  439\n",
      "224.29630957153404\n",
      "length of actions is  471\n",
      "10.709998414588071\n",
      "length of actions is  184\n",
      "123.45941188094123\n",
      "length of actions is  1000\n",
      "Your final reward is : 150.84\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2275])\n",
      "182.18115698293798\n",
      "length of actions is  674\n",
      "184.29941490744181\n",
      "length of actions is  751\n",
      "220.24638847107025\n",
      "length of actions is  496\n",
      "107.83163904366153\n",
      "length of actions is  1000\n",
      "221.44280520348264\n",
      "length of actions is  270\n",
      "Your final reward is : 183.20\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2412])\n",
      "197.65034765369367\n",
      "length of actions is  612\n",
      "210.32060152796095\n",
      "length of actions is  578\n",
      "130.60308144830375\n",
      "length of actions is  1000\n",
      "178.3132741921093\n",
      "length of actions is  478\n",
      "219.3232468469008\n",
      "length of actions is  429\n",
      "Your final reward is : 187.24\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2043])\n",
      "210.38440552967177\n",
      "length of actions is  541\n",
      "204.89900935685733\n",
      "length of actions is  293\n",
      "240.34092702559795\n",
      "length of actions is  660\n",
      "91.90362364639216\n",
      "length of actions is  1000\n",
      "246.76371094847332\n",
      "length of actions is  453\n",
      "Your final reward is : 198.86\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2197])\n",
      "183.75036979994263\n",
      "length of actions is  664\n",
      "196.94598486275635\n",
      "length of actions is  546\n",
      "235.55425012503943\n",
      "length of actions is  421\n",
      "212.0799575316738\n",
      "length of actions is  495\n",
      "-76.22446100438917\n",
      "length of actions is  202\n",
      "Your final reward is : 150.42\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2197])\n",
      "190.64920044522984\n",
      "length of actions is  641\n",
      "176.83470413793708\n",
      "length of actions is  752\n",
      "169.41191117956086\n",
      "length of actions is  329\n",
      "217.76901729366688\n",
      "length of actions is  502\n",
      "249.0729358458034\n",
      "length of actions is  372\n",
      "Your final reward is : 200.75\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2917])\n",
      "199.94147474739188\n",
      "length of actions is  620\n",
      "188.45852923122163\n",
      "length of actions is  571\n",
      "159.61432530078957\n",
      "length of actions is  584\n",
      "215.89009398910156\n",
      "length of actions is  387\n",
      "-37.61453281103387\n",
      "length of actions is  459\n",
      "Your final reward is : 145.26\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2917])\n",
      "189.53451680417896\n",
      "length of actions is  668\n",
      "202.1046775544243\n",
      "length of actions is  633\n",
      "181.7376772887609\n",
      "length of actions is  475\n",
      "195.6558145644335\n",
      "length of actions is  371\n",
      "212.24230843662298\n",
      "length of actions is  680\n",
      "Your final reward is : 196.25\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2829])\n",
      "196.329644964514\n",
      "length of actions is  606\n",
      "196.12783324392393\n",
      "length of actions is  849\n",
      "-35.8201204043602\n",
      "length of actions is  1000\n",
      "199.52204829911878\n",
      "length of actions is  446\n",
      "-8.328331657243037\n",
      "length of actions is  1000\n",
      "Your final reward is : 109.57\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3859])\n",
      "66.78845811630677\n",
      "length of actions is  1000\n",
      "198.6581707201465\n",
      "length of actions is  208\n",
      "-11.751269101992838\n",
      "length of actions is  1000\n",
      "93.64840080491888\n",
      "length of actions is  1000\n",
      "223.2226546732211\n",
      "length of actions is  433\n",
      "Your final reward is : 114.11\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4323])\n",
      "159.90341097147802\n",
      "length of actions is  915\n",
      "98.48341414069996\n",
      "length of actions is  1000\n",
      "84.8093480180933\n",
      "length of actions is  1000\n",
      "24.056085420232996\n",
      "length of actions is  1000\n",
      "-75.23366183612754\n",
      "length of actions is  152\n",
      "Your final reward is : 58.40\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4085])\n",
      "168.03360210015032\n",
      "length of actions is  921\n",
      "85.70137371426554\n",
      "length of actions is  1000\n",
      "210.09995326239167\n",
      "length of actions is  938\n",
      "192.42357670607853\n",
      "length of actions is  422\n",
      "222.14702528023832\n",
      "length of actions is  533\n",
      "Your final reward is : 175.68\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3711])\n",
      "73.53467290747832\n",
      "length of actions is  1000\n",
      "-37.40162595207057\n",
      "length of actions is  160\n",
      "203.20974966579644\n",
      "length of actions is  389\n",
      "103.09379472991023\n",
      "length of actions is  1000\n",
      "105.34921058868869\n",
      "length of actions is  1000\n",
      "Your final reward is : 89.56\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4048])\n",
      "174.93977973909028\n",
      "length of actions is  720\n",
      "169.31528484558706\n",
      "length of actions is  632\n",
      "199.25452423892872\n",
      "length of actions is  636\n",
      "142.9551306855973\n",
      "length of actions is  678\n",
      "217.5175840147083\n",
      "length of actions is  727\n",
      "Your final reward is : 180.80\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4350])\n",
      "177.13357903302781\n",
      "length of actions is  683\n",
      "65.41838880447457\n",
      "length of actions is  1000\n",
      "192.24140197949973\n",
      "length of actions is  482\n",
      "193.16883027872797\n",
      "length of actions is  360\n",
      "205.55505005514718\n",
      "length of actions is  398\n",
      "Your final reward is : 166.70\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4084])\n",
      "137.4103366905483\n",
      "length of actions is  836\n",
      "-22.02076522669278\n",
      "length of actions is  1000\n",
      "178.44138353770032\n",
      "length of actions is  643\n",
      "-37.115526322191364\n",
      "length of actions is  1000\n",
      "-57.78732384619171\n",
      "length of actions is  1000\n",
      "Your final reward is : 39.79\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4257])\n",
      "175.76619187117635\n",
      "length of actions is  695\n",
      "199.73343406310613\n",
      "length of actions is  624\n",
      "188.9920787274879\n",
      "length of actions is  779\n",
      "-62.531967405113875\n",
      "length of actions is  1000\n",
      "205.39789522762877\n",
      "length of actions is  434\n",
      "Your final reward is : 141.47\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3812])\n",
      "157.7974335511206\n",
      "length of actions is  777\n",
      "162.96965179778476\n",
      "length of actions is  612\n",
      "181.40553604684249\n",
      "length of actions is  783\n",
      "-48.1438656853788\n",
      "length of actions is  1000\n",
      "183.16621212148283\n",
      "length of actions is  576\n",
      "Your final reward is : 127.44\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3715])\n",
      "153.5049535513505\n",
      "length of actions is  741\n",
      "204.2842850353048\n",
      "length of actions is  752\n",
      "-52.51861749493489\n",
      "length of actions is  1000\n",
      "212.06463817539085\n",
      "length of actions is  422\n",
      "184.18305960129769\n",
      "length of actions is  541\n",
      "Your final reward is : 140.30\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4315])\n",
      "141.0173929622822\n",
      "length of actions is  826\n",
      "-70.38383273184715\n",
      "length of actions is  1000\n",
      "-140.4200612197791\n",
      "length of actions is  796\n",
      "181.60102687792923\n",
      "length of actions is  751\n",
      "204.96349606786754\n",
      "length of actions is  639\n",
      "Your final reward is : 63.36\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3017])\n",
      "182.9273372709448\n",
      "length of actions is  647\n",
      "176.85596180313556\n",
      "length of actions is  804\n",
      "-88.96171265339474\n",
      "length of actions is  451\n",
      "200.93926040019556\n",
      "length of actions is  422\n",
      "213.6110216857399\n",
      "length of actions is  639\n",
      "Your final reward is : 137.07\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4023])\n",
      "168.3257790998736\n",
      "length of actions is  678\n",
      "-55.13881312473141\n",
      "length of actions is  155\n",
      "200.97090512269995\n",
      "length of actions is  545\n",
      "-47.88525085276019\n",
      "length of actions is  155\n",
      "179.85933045053997\n",
      "length of actions is  504\n",
      "Your final reward is : 89.23\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3949])\n",
      "194.09021702314465\n",
      "length of actions is  638\n",
      "-180.90943510248246\n",
      "length of actions is  924\n",
      "223.4468404568252\n",
      "length of actions is  645\n",
      "182.58748690235524\n",
      "length of actions is  575\n",
      "210.49112012952025\n",
      "length of actions is  451\n",
      "Your final reward is : 125.94\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3063])\n",
      "166.65334777651242\n",
      "length of actions is  670\n",
      "-48.08659298852105\n",
      "length of actions is  1000\n",
      "208.33567266763023\n",
      "length of actions is  540\n",
      "-71.17220637437873\n",
      "length of actions is  1000\n",
      "181.6857774485467\n",
      "length of actions is  760\n",
      "Your final reward is : 87.48\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4137])\n",
      "196.31446556648942\n",
      "length of actions is  617\n",
      "183.6142672934854\n",
      "length of actions is  737\n",
      "-75.97527339981053\n",
      "length of actions is  1000\n",
      "174.18900576563732\n",
      "length of actions is  523\n",
      "189.18042803408738\n",
      "length of actions is  502\n",
      "Your final reward is : 133.46\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3859])\n",
      "185.3960167624841\n",
      "length of actions is  688\n",
      "-60.32711025723647\n",
      "length of actions is  1000\n",
      "203.39080307068062\n",
      "length of actions is  601\n",
      "-37.24067963559655\n",
      "length of actions is  1000\n",
      "203.6651020166061\n",
      "length of actions is  544\n",
      "Your final reward is : 98.98\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2948])\n",
      "142.48216949061714\n",
      "length of actions is  820\n",
      "181.48532821135558\n",
      "length of actions is  647\n",
      "-57.767776978515485\n",
      "length of actions is  1000\n",
      "209.73122630364097\n",
      "length of actions is  478\n",
      "-64.2282667452988\n",
      "length of actions is  1000\n",
      "Your final reward is : 82.34\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3205])\n",
      "164.6082987940473\n",
      "length of actions is  705\n",
      "193.77647445852\n",
      "length of actions is  470\n",
      "195.26569219071195\n",
      "length of actions is  471\n",
      "205.68374929684302\n",
      "length of actions is  558\n",
      "187.57673725033345\n",
      "length of actions is  623\n",
      "Your final reward is : 189.38\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4368])\n",
      "131.67016525312854\n",
      "length of actions is  785\n",
      "-17.040864042536832\n",
      "length of actions is  1000\n",
      "-45.592953846871936\n",
      "length of actions is  420\n",
      "198.5594212491896\n",
      "length of actions is  573\n",
      "163.64629964286365\n",
      "length of actions is  629\n",
      "Your final reward is : 86.25\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2827])\n",
      "149.96559593779088\n",
      "length of actions is  691\n",
      "197.66876720326815\n",
      "length of actions is  453\n",
      "175.11392439063812\n",
      "length of actions is  539\n",
      "189.35813749592188\n",
      "length of actions is  614\n",
      "-17.94744912170599\n",
      "length of actions is  1000\n",
      "Your final reward is : 138.83\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4050])\n",
      "126.39712066366337\n",
      "length of actions is  937\n",
      "6.158896039132599\n",
      "length of actions is  1000\n",
      "8.502747741695199\n",
      "length of actions is  1000\n",
      "229.10191969158075\n",
      "length of actions is  483\n",
      "-21.244373885343876\n",
      "length of actions is  1000\n",
      "Your final reward is : 69.78\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2638])\n",
      "158.0699409161297\n",
      "length of actions is  562\n",
      "130.7496199243118\n",
      "length of actions is  766\n",
      "196.02763278124894\n",
      "length of actions is  545\n",
      "203.67351981836936\n",
      "length of actions is  385\n",
      "108.89710221989698\n",
      "length of actions is  795\n",
      "Your final reward is : 159.48\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2974])\n",
      "152.7885885008617\n",
      "length of actions is  631\n",
      "126.18024665886333\n",
      "length of actions is  658\n",
      "205.8198540635834\n",
      "length of actions is  415\n",
      "-1.0607197670115065\n",
      "length of actions is  1000\n",
      "115.05035215789738\n",
      "length of actions is  617\n",
      "Your final reward is : 119.76\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3174])\n",
      "59.091280046649146\n",
      "length of actions is  1000\n",
      "-20.728542166794714\n",
      "length of actions is  1000\n",
      "232.38269134064353\n",
      "length of actions is  400\n",
      "171.46983023224115\n",
      "length of actions is  903\n",
      "183.78358444019395\n",
      "length of actions is  746\n",
      "Your final reward is : 125.20\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3770])\n",
      "167.89559647899898\n",
      "length of actions is  537\n",
      "234.28891291301306\n",
      "length of actions is  405\n",
      "140.25822169607588\n",
      "length of actions is  910\n",
      "81.8490834071439\n",
      "length of actions is  1000\n",
      "153.6877666004562\n",
      "length of actions is  658\n",
      "Your final reward is : 155.60\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3495])\n",
      "168.63465624131535\n",
      "length of actions is  538\n",
      "216.72981865836587\n",
      "length of actions is  339\n",
      "165.47474138897624\n",
      "length of actions is  986\n",
      "200.61943252507365\n",
      "length of actions is  400\n",
      "105.62361241482449\n",
      "length of actions is  1000\n",
      "Your final reward is : 171.42\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3405])\n",
      "169.6855253749555\n",
      "length of actions is  547\n",
      "189.28093959257092\n",
      "length of actions is  433\n",
      "228.3388560134825\n",
      "length of actions is  421\n",
      "194.03237263409693\n",
      "length of actions is  396\n",
      "215.02437083705263\n",
      "length of actions is  431\n",
      "Your final reward is : 199.27\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3106])\n",
      "180.53153018465738\n",
      "length of actions is  520\n",
      "227.18999547437113\n",
      "length of actions is  408\n",
      "176.53763363410067\n",
      "length of actions is  613\n",
      "184.33579780481045\n",
      "length of actions is  452\n",
      "218.96978491727617\n",
      "length of actions is  399\n",
      "Your final reward is : 197.51\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2997])\n",
      "181.63600767704287\n",
      "length of actions is  472\n",
      "190.53332401550966\n",
      "length of actions is  504\n",
      "228.68153105879165\n",
      "length of actions is  344\n",
      "168.99506806070988\n",
      "length of actions is  701\n",
      "218.08121153185704\n",
      "length of actions is  379\n",
      "Your final reward is : 197.59\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3089])\n",
      "184.0393858444475\n",
      "length of actions is  470\n",
      "72.72337553789602\n",
      "length of actions is  1000\n",
      "-4.011001074194738\n",
      "length of actions is  1000\n",
      "131.4167033053426\n",
      "length of actions is  1000\n",
      "193.952079600949\n",
      "length of actions is  482\n",
      "Your final reward is : 115.62\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2412])\n",
      "178.62289448845178\n",
      "length of actions is  519\n",
      "177.40721129595684\n",
      "length of actions is  560\n",
      "49.09859058225045\n",
      "length of actions is  1000\n",
      "242.68173518804625\n",
      "length of actions is  362\n",
      "168.9203242451089\n",
      "length of actions is  786\n",
      "Your final reward is : 163.35\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2601])\n",
      "170.53238357352978\n",
      "length of actions is  555\n",
      "183.18717621703377\n",
      "length of actions is  361\n",
      "211.310278051174\n",
      "length of actions is  502\n",
      "241.70380461554296\n",
      "length of actions is  299\n",
      "72.8194619165817\n",
      "length of actions is  1000\n",
      "Your final reward is : 175.91\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2867])\n",
      "157.12013115923224\n",
      "length of actions is  701\n",
      "184.1235020284166\n",
      "length of actions is  614\n",
      "227.17426036430982\n",
      "length of actions is  359\n",
      "219.40600103859398\n",
      "length of actions is  444\n",
      "197.47486901486684\n",
      "length of actions is  676\n",
      "Your final reward is : 197.06\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2537])\n",
      "153.95071966718643\n",
      "length of actions is  741\n",
      "199.7230096204908\n",
      "length of actions is  760\n",
      "203.9259051698082\n",
      "length of actions is  557\n",
      "182.09138745648528\n",
      "length of actions is  633\n",
      "191.7402409164713\n",
      "length of actions is  843\n",
      "Your final reward is : 186.29\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2830])\n",
      "178.29785268540408\n",
      "length of actions is  843\n",
      "269.41093417959405\n",
      "length of actions is  320\n",
      "228.85755892798738\n",
      "length of actions is  982\n",
      "238.5396608698115\n",
      "length of actions is  397\n",
      "193.38888196138032\n",
      "length of actions is  649\n",
      "Your final reward is : 221.70\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3359])\n",
      "169.90246837249708\n",
      "length of actions is  585\n",
      "75.60619551206278\n",
      "length of actions is  1000\n",
      "244.2824314831487\n",
      "length of actions is  312\n",
      "265.68079441484997\n",
      "length of actions is  294\n",
      "208.90788034290307\n",
      "length of actions is  394\n",
      "Your final reward is : 192.88\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2604])\n",
      "193.47548240290092\n",
      "length of actions is  843\n",
      "261.172473347164\n",
      "length of actions is  343\n",
      "255.4945205780347\n",
      "length of actions is  346\n",
      "204.80626817433188\n",
      "length of actions is  634\n",
      "192.24402420323872\n",
      "length of actions is  394\n",
      "Your final reward is : 221.44\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2688])\n",
      "197.570958035877\n",
      "length of actions is  518\n",
      "203.28287395294535\n",
      "length of actions is  655\n",
      "239.47271209688955\n",
      "length of actions is  334\n",
      "231.59668663800602\n",
      "length of actions is  475\n",
      "210.6629036476144\n",
      "length of actions is  316\n",
      "Your final reward is : 216.52\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2834])\n",
      "196.51323909077712\n",
      "length of actions is  533\n",
      "214.7545405114614\n",
      "length of actions is  468\n",
      "213.18417768082907\n",
      "length of actions is  494\n",
      "201.63324986769058\n",
      "length of actions is  372\n",
      "215.14072350524665\n",
      "length of actions is  663\n",
      "Your final reward is : 208.25\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3166])\n",
      "173.33696086367854\n",
      "length of actions is  649\n",
      "218.9448397330263\n",
      "length of actions is  309\n",
      "226.43144319883118\n",
      "length of actions is  371\n",
      "121.2929518329272\n",
      "length of actions is  1000\n",
      "175.40961800772385\n",
      "length of actions is  276\n",
      "Your final reward is : 183.08\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2696])\n",
      "194.22617365453306\n",
      "length of actions is  635\n",
      "212.41854776951538\n",
      "length of actions is  684\n",
      "211.84603336784593\n",
      "length of actions is  672\n",
      "210.54663101260448\n",
      "length of actions is  559\n",
      "194.00128129464338\n",
      "length of actions is  564\n",
      "Your final reward is : 204.61\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3371])\n",
      "202.31211890666043\n",
      "length of actions is  545\n",
      "236.60944266553426\n",
      "length of actions is  480\n",
      "218.26242425459742\n",
      "length of actions is  513\n",
      "212.63441341925466\n",
      "length of actions is  467\n",
      "223.66458466327092\n",
      "length of actions is  630\n",
      "Your final reward is : 218.70\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2658])\n",
      "193.46037441354628\n",
      "length of actions is  503\n",
      "186.25770902032255\n",
      "length of actions is  458\n",
      "199.49394322869296\n",
      "length of actions is  477\n",
      "4.079785207125434\n",
      "length of actions is  1000\n",
      "104.26991310476329\n",
      "length of actions is  1000\n",
      "Your final reward is : 137.51\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2474])\n",
      "184.56435334952522\n",
      "length of actions is  630\n",
      "183.3001628432409\n",
      "length of actions is  560\n",
      "245.9675870914316\n",
      "length of actions is  521\n",
      "217.572419807472\n",
      "length of actions is  453\n",
      "98.83451648424617\n",
      "length of actions is  1000\n",
      "Your final reward is : 186.05\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2421])\n",
      "188.32041456123716\n",
      "length of actions is  790\n",
      "218.4490670087411\n",
      "length of actions is  719\n",
      "135.6965199920361\n",
      "length of actions is  810\n",
      "220.80080921007257\n",
      "length of actions is  411\n",
      "245.49433892843084\n",
      "length of actions is  569\n",
      "Your final reward is : 201.75\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2150])\n",
      "191.46912296835106\n",
      "length of actions is  629\n",
      "232.6060015751944\n",
      "length of actions is  462\n",
      "199.61962408136196\n",
      "length of actions is  530\n",
      "226.619717967724\n",
      "length of actions is  671\n",
      "185.75845881328578\n",
      "length of actions is  784\n",
      "Your final reward is : 207.21\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3795])\n",
      "182.25777288864083\n",
      "length of actions is  621\n",
      "89.81524821974342\n",
      "length of actions is  1000\n",
      "96.47048597886379\n",
      "length of actions is  1000\n",
      "96.68635224174038\n",
      "length of actions is  1000\n",
      "237.49509134680062\n",
      "length of actions is  398\n",
      "Your final reward is : 140.54\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2727])\n",
      "198.83973806867363\n",
      "length of actions is  559\n",
      "4.417720400240744\n",
      "length of actions is  1000\n",
      "209.5276691851501\n",
      "length of actions is  460\n",
      "231.47940478441149\n",
      "length of actions is  538\n",
      "210.63079462328665\n",
      "length of actions is  479\n",
      "Your final reward is : 170.98\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2559])\n",
      "189.96665950333306\n",
      "length of actions is  631\n",
      "188.19953955110424\n",
      "length of actions is  593\n",
      "213.91480145840023\n",
      "length of actions is  475\n",
      "-15.96715201742002\n",
      "length of actions is  1000\n",
      "203.4736050579869\n",
      "length of actions is  423\n",
      "Your final reward is : 155.92\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1970])\n",
      "212.4198159253217\n",
      "length of actions is  498\n",
      "224.1081906630295\n",
      "length of actions is  471\n",
      "240.02113975652682\n",
      "length of actions is  342\n",
      "250.6284508034959\n",
      "length of actions is  441\n",
      "200.68030108613004\n",
      "length of actions is  563\n",
      "Your final reward is : 225.57\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2608])\n",
      "208.3100954904731\n",
      "length of actions is  537\n",
      "204.73301662395258\n",
      "length of actions is  377\n",
      "237.0038323565779\n",
      "length of actions is  424\n",
      "202.7706330326344\n",
      "length of actions is  490\n",
      "229.88051616783986\n",
      "length of actions is  302\n",
      "Your final reward is : 216.54\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2145])\n",
      "198.62294340115363\n",
      "length of actions is  526\n",
      "230.67781750430143\n",
      "length of actions is  393\n",
      "113.40439367713367\n",
      "length of actions is  1000\n",
      "259.0947188343592\n",
      "length of actions is  343\n",
      "253.55227379228737\n",
      "length of actions is  314\n",
      "Your final reward is : 211.07\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2975])\n",
      "192.23604966351076\n",
      "length of actions is  574\n",
      "221.55112338388963\n",
      "length of actions is  338\n",
      "194.14708223293007\n",
      "length of actions is  772\n",
      "-26.76270521331198\n",
      "length of actions is  1000\n",
      "267.6526375203302\n",
      "length of actions is  252\n",
      "Your final reward is : 169.76\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3507])\n",
      "191.16670594933328\n",
      "length of actions is  555\n",
      "221.03209505133265\n",
      "length of actions is  333\n",
      "237.17503929042664\n",
      "length of actions is  381\n",
      "99.4984460279816\n",
      "length of actions is  1000\n",
      "237.61783421105335\n",
      "length of actions is  483\n",
      "Your final reward is : 197.30\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3010])\n",
      "216.11340618380592\n",
      "length of actions is  512\n",
      "230.43259388563172\n",
      "length of actions is  372\n",
      "240.4071524619661\n",
      "length of actions is  464\n",
      "-9.702410496485154\n",
      "length of actions is  1000\n",
      "217.8848312596152\n",
      "length of actions is  417\n",
      "Your final reward is : 179.03\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2197])\n",
      "222.6332953799872\n",
      "length of actions is  431\n",
      "242.03032127683815\n",
      "length of actions is  408\n",
      "259.2603546053639\n",
      "length of actions is  357\n",
      "168.64010733067383\n",
      "length of actions is  1000\n",
      "226.81008828377972\n",
      "length of actions is  285\n",
      "Your final reward is : 223.87\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2484])\n",
      "204.8018788812933\n",
      "length of actions is  557\n",
      "-8.18392100731479\n",
      "length of actions is  1000\n",
      "226.5965519456088\n",
      "length of actions is  720\n",
      "230.66363462283047\n",
      "length of actions is  389\n",
      "262.17695711474323\n",
      "length of actions is  367\n",
      "Your final reward is : 183.21\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2687])\n",
      "222.1274366146066\n",
      "length of actions is  451\n",
      "104.62394690071021\n",
      "length of actions is  1000\n",
      "-51.498469706282606\n",
      "length of actions is  1000\n",
      "239.85970497617356\n",
      "length of actions is  407\n",
      "272.19495947198754\n",
      "length of actions is  419\n",
      "Your final reward is : 157.46\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3676])\n",
      "117.91959563714111\n",
      "length of actions is  1000\n",
      "-14.647216632731089\n",
      "length of actions is  1000\n",
      "23.5580301264364\n",
      "length of actions is  1000\n",
      "229.59884512142108\n",
      "length of actions is  959\n",
      "123.13024206298142\n",
      "length of actions is  1000\n",
      "Your final reward is : 95.91\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2600])\n",
      "226.53818214768194\n",
      "length of actions is  443\n",
      "-19.61633215266722\n",
      "length of actions is  1000\n",
      "106.77705017661496\n",
      "length of actions is  1000\n",
      "273.1692155164593\n",
      "length of actions is  344\n",
      "-38.63195025141107\n",
      "length of actions is  1000\n",
      "Your final reward is : 109.65\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2440])\n",
      "220.05198197777082\n",
      "length of actions is  468\n",
      "128.00831284212694\n",
      "length of actions is  1000\n",
      "227.51738233993723\n",
      "length of actions is  333\n",
      "-0.6877216430850925\n",
      "length of actions is  1000\n",
      "228.88343676223218\n",
      "length of actions is  486\n",
      "Your final reward is : 160.75\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2917])\n",
      "218.62491460669924\n",
      "length of actions is  432\n",
      "219.2404654111062\n",
      "length of actions is  716\n",
      "156.38143178991533\n",
      "length of actions is  1000\n",
      "161.96526505693575\n",
      "length of actions is  796\n",
      "116.97174380318984\n",
      "length of actions is  1000\n",
      "Your final reward is : 174.64\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3327])\n",
      "231.92422187787255\n",
      "length of actions is  398\n",
      "252.78080995572338\n",
      "length of actions is  481\n",
      "-50.11968947803343\n",
      "length of actions is  1000\n",
      "256.3805308543368\n",
      "length of actions is  456\n",
      "-12.695493389804597\n",
      "length of actions is  296\n",
      "Your final reward is : 135.65\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3136])\n",
      "221.12795546447182\n",
      "length of actions is  479\n",
      "257.197845995978\n",
      "length of actions is  398\n",
      "239.06408950447445\n",
      "length of actions is  594\n",
      "262.11294840166295\n",
      "length of actions is  237\n",
      "286.3136154833008\n",
      "length of actions is  333\n",
      "Your final reward is : 253.16\n",
      "Improve to score 253.16 at batch 267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kate\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:132: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.from_numpy(rewards) looks like  torch.Size([1708])\n",
      "236.4617644502525\n",
      "length of actions is  378\n",
      "237.56900680152697\n",
      "length of actions is  379\n",
      "273.225683980446\n",
      "length of actions is  243\n",
      "112.56746109317342\n",
      "length of actions is  1000\n",
      "128.81830469554967\n",
      "length of actions is  1000\n",
      "Your final reward is : 197.73\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2974])\n",
      "217.50288969340656\n",
      "length of actions is  486\n",
      "214.22009685890126\n",
      "length of actions is  262\n",
      "242.60240268422334\n",
      "length of actions is  288\n",
      "-89.95253711374758\n",
      "length of actions is  1000\n",
      "-49.35343291912566\n",
      "length of actions is  1000\n",
      "Your final reward is : 107.00\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2273])\n",
      "238.06762995873996\n",
      "length of actions is  395\n",
      "237.29099438319162\n",
      "length of actions is  400\n",
      "264.0955170753642\n",
      "length of actions is  299\n",
      "269.9443674025589\n",
      "length of actions is  306\n",
      "121.27149419224772\n",
      "length of actions is  1000\n",
      "Your final reward is : 226.13\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2277])\n",
      "241.6294377171948\n",
      "length of actions is  350\n",
      "250.32246322187862\n",
      "length of actions is  207\n",
      "274.77994900397186\n",
      "length of actions is  397\n",
      "265.750977666233\n",
      "length of actions is  362\n",
      "-23.468940102323597\n",
      "length of actions is  1000\n",
      "Your final reward is : 201.80\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1972])\n",
      "249.56396262100074\n",
      "length of actions is  313\n",
      "80.38432501716034\n",
      "length of actions is  961\n",
      "257.098136969321\n",
      "length of actions is  222\n",
      "256.54684214171976\n",
      "length of actions is  318\n",
      "251.210778546496\n",
      "length of actions is  233\n",
      "Your final reward is : 218.96\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2562])\n",
      "233.45721146309992\n",
      "length of actions is  717\n",
      "149.84874324343588\n",
      "length of actions is  709\n",
      "-61.69545309952462\n",
      "length of actions is  1000\n",
      "280.7228822585363\n",
      "length of actions is  344\n",
      "-14.127967873603515\n",
      "length of actions is  1000\n",
      "Your final reward is : 117.64\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3771])\n",
      "234.70137191090052\n",
      "length of actions is  310\n",
      "206.19122349076264\n",
      "length of actions is  281\n",
      "-27.75523532250803\n",
      "length of actions is  1000\n",
      "-17.550143509285004\n",
      "length of actions is  1000\n",
      "231.50983023118337\n",
      "length of actions is  287\n",
      "Your final reward is : 125.42\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2977])\n",
      "249.07146391499887\n",
      "length of actions is  336\n",
      "240.85555674349334\n",
      "length of actions is  209\n",
      "266.20949953021795\n",
      "length of actions is  323\n",
      "273.4354863830704\n",
      "length of actions is  269\n",
      "252.01168620208315\n",
      "length of actions is  370\n",
      "Your final reward is : 256.32\n",
      "Improve to score 256.32 at batch 275\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1503])\n",
      "243.07006867570462\n",
      "length of actions is  321\n",
      "122.67927653274788\n",
      "length of actions is  957\n",
      "263.12583780716113\n",
      "length of actions is  219\n",
      "270.9394662866574\n",
      "length of actions is  240\n",
      "-31.110011797278194\n",
      "length of actions is  1000\n",
      "Your final reward is : 173.74\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1964])\n",
      "248.88011789786205\n",
      "length of actions is  341\n",
      "-85.75376110234957\n",
      "length of actions is  1000\n",
      "260.64455620328783\n",
      "length of actions is  309\n",
      "-37.23274974582584\n",
      "length of actions is  1000\n",
      "231.5944322471183\n",
      "length of actions is  296\n",
      "Your final reward is : 123.63\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3024])\n",
      "249.5585723123\n",
      "length of actions is  298\n",
      "241.05881762395788\n",
      "length of actions is  245\n",
      "206.5137379313822\n",
      "length of actions is  678\n",
      "252.14765473389176\n",
      "length of actions is  324\n",
      "229.9710835596514\n",
      "length of actions is  273\n",
      "Your final reward is : 235.85\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2963])\n",
      "247.02025257618936\n",
      "length of actions is  297\n",
      "233.78259218039832\n",
      "length of actions is  318\n",
      "282.62162992411777\n",
      "length of actions is  366\n",
      "-54.33551478275342\n",
      "length of actions is  1000\n",
      "246.20618509548152\n",
      "length of actions is  326\n",
      "Your final reward is : 191.06\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1504])\n",
      "241.86567430597637\n",
      "length of actions is  292\n",
      "281.4067876100255\n",
      "length of actions is  223\n",
      "-39.97090602731241\n",
      "length of actions is  1000\n",
      "240.49513958554184\n",
      "length of actions is  256\n",
      "254.8707651633145\n",
      "length of actions is  346\n",
      "Your final reward is : 195.73\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3515])\n",
      "117.49435973920642\n",
      "length of actions is  1000\n",
      "38.3153121922776\n",
      "length of actions is  1000\n",
      "-28.200931686423242\n",
      "length of actions is  1000\n",
      "127.63483004636569\n",
      "length of actions is  1000\n",
      "93.07733018732551\n",
      "length of actions is  1000\n",
      "Your final reward is : 69.66\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2455])\n",
      "128.92887827081202\n",
      "length of actions is  1000\n",
      "120.70078640651504\n",
      "length of actions is  1000\n",
      "208.03707292740813\n",
      "length of actions is  686\n",
      "-24.370314559635617\n",
      "length of actions is  488\n",
      "117.98448715045382\n",
      "length of actions is  1000\n",
      "Your final reward is : 110.26\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3652])\n",
      "244.91786056602595\n",
      "length of actions is  384\n",
      "240.89514682281504\n",
      "length of actions is  886\n",
      "-63.62947429639236\n",
      "length of actions is  1000\n",
      "188.6124599340768\n",
      "length of actions is  495\n",
      "261.5867225017581\n",
      "length of actions is  206\n",
      "Your final reward is : 174.48\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1989])\n",
      "243.61973340923848\n",
      "length of actions is  253\n",
      "22.266682959303996\n",
      "length of actions is  1000\n",
      "-25.55109413723065\n",
      "length of actions is  333\n",
      "171.87639351003168\n",
      "length of actions is  634\n",
      "263.0166526693083\n",
      "length of actions is  256\n",
      "Your final reward is : 135.05\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1488])\n",
      "250.1944817603137\n",
      "length of actions is  278\n",
      "184.08724092397745\n",
      "length of actions is  543\n",
      "254.92264583567135\n",
      "length of actions is  222\n",
      "105.59241909535537\n",
      "length of actions is  1000\n",
      "148.65668647303323\n",
      "length of actions is  1000\n",
      "Your final reward is : 188.69\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3047])\n",
      "250.69544134128336\n",
      "length of actions is  245\n",
      "-6.894676858586392\n",
      "length of actions is  1000\n",
      "267.12398595540276\n",
      "length of actions is  247\n",
      "268.65675138626864\n",
      "length of actions is  303\n",
      "258.9724376117624\n",
      "length of actions is  184\n",
      "Your final reward is : 207.71\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2985])\n",
      "246.29356716677583\n",
      "length of actions is  323\n",
      "219.1709406817539\n",
      "length of actions is  244\n",
      "133.65511410539756\n",
      "length of actions is  1000\n",
      "-41.7398251891404\n",
      "length of actions is  1000\n",
      "246.47982870085983\n",
      "length of actions is  241\n",
      "Your final reward is : 160.77\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2687])\n",
      "253.32009796910714\n",
      "length of actions is  267\n",
      "231.94678047203098\n",
      "length of actions is  442\n",
      "-41.5172956918533\n",
      "length of actions is  1000\n",
      "275.1323143037059\n",
      "length of actions is  262\n",
      "253.40617349963466\n",
      "length of actions is  204\n",
      "Your final reward is : 194.46\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2212])\n",
      "241.9595287928958\n",
      "length of actions is  271\n",
      "123.6287805221557\n",
      "length of actions is  1000\n",
      "-53.82103605788967\n",
      "length of actions is  1000\n",
      "141.47101080429445\n",
      "length of actions is  1000\n",
      "-21.44543797585075\n",
      "length of actions is  1000\n",
      "Your final reward is : 86.36\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2441])\n",
      "244.82447769264408\n",
      "length of actions is  266\n",
      "264.9151028778946\n",
      "length of actions is  264\n",
      "232.03000253862345\n",
      "length of actions is  167\n",
      "221.63262987570732\n",
      "length of actions is  183\n",
      "221.37279329711748\n",
      "length of actions is  317\n",
      "Your final reward is : 236.96\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2413])\n",
      "245.3533895887037\n",
      "length of actions is  282\n",
      "184.25704527141602\n",
      "length of actions is  434\n",
      "147.3276753148144\n",
      "length of actions is  1000\n",
      "136.7938038232807\n",
      "length of actions is  1000\n",
      "-8.95857140398713\n",
      "length of actions is  1000\n",
      "Your final reward is : 140.95\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3475])\n",
      "244.79844188154385\n",
      "length of actions is  335\n",
      "226.86790089149846\n",
      "length of actions is  255\n",
      "140.9427884797004\n",
      "length of actions is  1000\n",
      "185.44733829672896\n",
      "length of actions is  184\n",
      "-2.378526295436161\n",
      "length of actions is  1000\n",
      "Your final reward is : 159.14\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3148])\n",
      "232.75038174136242\n",
      "length of actions is  388\n",
      "0.5479203151804355\n",
      "length of actions is  1000\n",
      "16.83363717358546\n",
      "length of actions is  113\n",
      "191.41416281762702\n",
      "length of actions is  550\n",
      "40.26408019633274\n",
      "length of actions is  166\n",
      "Your final reward is : 96.36\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1015])\n",
      "243.8955765504948\n",
      "length of actions is  328\n",
      "-8.539067409170016\n",
      "length of actions is  101\n",
      "99.07593143637948\n",
      "length of actions is  982\n",
      "-23.621766863923966\n",
      "length of actions is  104\n",
      "7.603870772083056\n",
      "length of actions is  126\n",
      "Your final reward is : 63.68\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2984])\n",
      "228.38189672262473\n",
      "length of actions is  403\n",
      "30.021116991353892\n",
      "length of actions is  159\n",
      "234.90479049785233\n",
      "length of actions is  460\n",
      "-58.55914061494201\n",
      "length of actions is  97\n",
      "-80.29152687197985\n",
      "length of actions is  87\n",
      "Your final reward is : 70.89\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4336])\n",
      "187.09941266485458\n",
      "length of actions is  527\n",
      "41.253106523263114\n",
      "length of actions is  149\n",
      "31.46140853910297\n",
      "length of actions is  1000\n",
      "129.42996733284\n",
      "length of actions is  938\n",
      "160.1656194508455\n",
      "length of actions is  864\n",
      "Your final reward is : 109.88\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3344])\n",
      "217.20448392528897\n",
      "length of actions is  790\n",
      "150.1263248726411\n",
      "length of actions is  1000\n",
      "50.67290893172795\n",
      "length of actions is  1000\n",
      "271.37814660472014\n",
      "length of actions is  238\n",
      "224.70585020356083\n",
      "length of actions is  465\n",
      "Your final reward is : 182.82\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2275])\n",
      "215.13529226694374\n",
      "length of actions is  459\n",
      "267.49612770355213\n",
      "length of actions is  280\n",
      "21.506490715283533\n",
      "length of actions is  1000\n",
      "274.2369871663635\n",
      "length of actions is  195\n",
      "-21.604102869814184\n",
      "length of actions is  126\n",
      "Your final reward is : 151.35\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1576])\n",
      "238.74316203890479\n",
      "length of actions is  324\n",
      "187.91717808557132\n",
      "length of actions is  839\n",
      "68.67227695090301\n",
      "length of actions is  1000\n",
      "263.5171772992361\n",
      "length of actions is  184\n",
      "216.13651336109615\n",
      "length of actions is  258\n",
      "Your final reward is : 195.00\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1513])\n",
      "222.32178093966775\n",
      "length of actions is  292\n",
      "43.373728219152696\n",
      "length of actions is  134\n",
      "23.593539839977552\n",
      "length of actions is  169\n",
      "233.7055811132302\n",
      "length of actions is  422\n",
      "15.3186279672843\n",
      "length of actions is  164\n",
      "Your final reward is : 107.66\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1735])\n",
      "225.47096789914073\n",
      "length of actions is  235\n",
      "139.4626243697055\n",
      "length of actions is  999\n",
      "124.88418645391175\n",
      "length of actions is  1000\n",
      "-0.31306293927124207\n",
      "length of actions is  1000\n",
      "10.422018317832595\n",
      "length of actions is  100\n",
      "Your final reward is : 99.99\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1033])\n",
      "211.6580331563511\n",
      "length of actions is  208\n",
      "140.08710741846951\n",
      "length of actions is  1000\n",
      "4.689251796916824\n",
      "length of actions is  1000\n",
      "-25.889322253690608\n",
      "length of actions is  165\n",
      "0.5743038171314367\n",
      "length of actions is  154\n",
      "Your final reward is : 66.22\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3246])\n",
      "231.43170871093483\n",
      "length of actions is  178\n",
      "6.470525596489708\n",
      "length of actions is  171\n",
      "-13.937049754494112\n",
      "length of actions is  156\n",
      "2.5319741170034433\n",
      "length of actions is  135\n",
      "-24.77468285085591\n",
      "length of actions is  124\n",
      "Your final reward is : 40.34\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1966])\n",
      "234.88848257563973\n",
      "length of actions is  699\n",
      "-46.15071987342183\n",
      "length of actions is  91\n",
      "5.068134500803453\n",
      "length of actions is  130\n",
      "10.02052909010753\n",
      "length of actions is  162\n",
      "-14.231195285107944\n",
      "length of actions is  94\n",
      "Your final reward is : 37.92\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3006])\n",
      "210.71348979338626\n",
      "length of actions is  737\n",
      "59.689164536087254\n",
      "length of actions is  1000\n",
      "-27.399512722025836\n",
      "length of actions is  1000\n",
      "238.45017422337665\n",
      "length of actions is  293\n",
      "272.31182923824554\n",
      "length of actions is  290\n",
      "Your final reward is : 150.75\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4172])\n",
      "102.0864231093194\n",
      "length of actions is  1000\n",
      "-2.7841164375379712\n",
      "length of actions is  1000\n",
      "142.96604463756626\n",
      "length of actions is  1000\n",
      "-6.612714044531202\n",
      "length of actions is  128\n",
      "44.40617943609007\n",
      "length of actions is  115\n",
      "Your final reward is : 56.01\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1764])\n",
      "-2.190072078778968\n",
      "length of actions is  124\n",
      "-4.975472708346175\n",
      "length of actions is  1000\n",
      "27.352818571348067\n",
      "length of actions is  112\n",
      "15.991384008355894\n",
      "length of actions is  83\n",
      "31.374815019854964\n",
      "length of actions is  117\n",
      "Your final reward is : 13.51\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3786])\n",
      "176.1708914345663\n",
      "length of actions is  611\n",
      "0.6032115573993888\n",
      "length of actions is  1000\n",
      "3.116545521005232\n",
      "length of actions is  1000\n",
      "-7.1811348286262575\n",
      "length of actions is  1000\n",
      "1.8853232542786287\n",
      "length of actions is  1000\n",
      "Your final reward is : 34.92\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2107])\n",
      "235.44985197232535\n",
      "length of actions is  232\n",
      "253.8507690542952\n",
      "length of actions is  259\n",
      "186.91417720636593\n",
      "length of actions is  731\n",
      "265.2914601606117\n",
      "length of actions is  288\n",
      "259.32607329533175\n",
      "length of actions is  334\n",
      "Your final reward is : 240.17\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2976])\n",
      "205.51380522651453\n",
      "length of actions is  442\n",
      "15.728686191350008\n",
      "length of actions is  1000\n",
      "2.5780297848451665\n",
      "length of actions is  1000\n",
      "198.20730993992916\n",
      "length of actions is  416\n",
      "231.32307906948716\n",
      "length of actions is  390\n",
      "Your final reward is : 130.67\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2420])\n",
      "233.08661830666662\n",
      "length of actions is  273\n",
      "279.73142347337\n",
      "length of actions is  998\n",
      "5.599052839531606\n",
      "length of actions is  1000\n",
      "252.0066630699888\n",
      "length of actions is  182\n",
      "212.41818335316384\n",
      "length of actions is  186\n",
      "Your final reward is : 196.57\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1817])\n",
      "229.43521199595028\n",
      "length of actions is  257\n",
      "256.2527859423901\n",
      "length of actions is  204\n",
      "250.7074243894807\n",
      "length of actions is  256\n",
      "270.04041520019393\n",
      "length of actions is  208\n",
      "262.32818822034744\n",
      "length of actions is  312\n",
      "Your final reward is : 253.75\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1674])\n",
      "233.01196222826914\n",
      "length of actions is  186\n",
      "122.1188809010282\n",
      "length of actions is  1000\n",
      "204.57360927322065\n",
      "length of actions is  426\n",
      "236.45511389261915\n",
      "length of actions is  198\n",
      "-8.998259044090403\n",
      "length of actions is  293\n",
      "Your final reward is : 157.43\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1135])\n",
      "229.10965690837043\n",
      "length of actions is  260\n",
      "193.21262323542334\n",
      "length of actions is  915\n",
      "225.96580814046922\n",
      "length of actions is  202\n",
      "203.1950894632771\n",
      "length of actions is  194\n",
      "320.29138116758594\n",
      "length of actions is  200\n",
      "Your final reward is : 234.35\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1318])\n",
      "223.8979486974106\n",
      "length of actions is  219\n",
      "284.6674270371315\n",
      "length of actions is  969\n",
      "6.4370123508885655\n",
      "length of actions is  291\n",
      "230.79666174681716\n",
      "length of actions is  449\n",
      "202.7860458505112\n",
      "length of actions is  182\n",
      "Your final reward is : 189.72\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1364])\n",
      "216.8975831679076\n",
      "length of actions is  323\n",
      "98.93276046127333\n",
      "length of actions is  1000\n",
      "-9.445548550168475\n",
      "length of actions is  1000\n",
      "-11.567207374083125\n",
      "length of actions is  146\n",
      "192.2740920048351\n",
      "length of actions is  333\n",
      "Your final reward is : 97.42\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2976])\n",
      "221.814976172049\n",
      "length of actions is  316\n",
      "19.066137844077172\n",
      "length of actions is  1000\n",
      "156.97430853634097\n",
      "length of actions is  710\n",
      "225.98077720021234\n",
      "length of actions is  336\n",
      "134.00266445211466\n",
      "length of actions is  1000\n",
      "Your final reward is : 151.57\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1910])\n",
      "214.79006752823682\n",
      "length of actions is  283\n",
      "210.53696493312188\n",
      "length of actions is  464\n",
      "189.2505054949238\n",
      "length of actions is  775\n",
      "-13.875998109343977\n",
      "length of actions is  1000\n",
      "15.399175481037755\n",
      "length of actions is  1000\n",
      "Your final reward is : 123.22\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2095])\n",
      "205.8446930699139\n",
      "length of actions is  380\n",
      "192.5600290017594\n",
      "length of actions is  642\n",
      "68.55338546547848\n",
      "length of actions is  1000\n",
      "99.68663337831559\n",
      "length of actions is  1000\n",
      "14.24128584955784\n",
      "length of actions is  1000\n",
      "Your final reward is : 116.18\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1974])\n",
      "-16.20906420159683\n",
      "length of actions is  1000\n",
      "10.625180470085597\n",
      "length of actions is  1000\n",
      "-10.798415589308277\n",
      "length of actions is  1000\n",
      "-6.40079433635396\n",
      "length of actions is  1000\n",
      "-54.46394284256247\n",
      "length of actions is  1000\n",
      "Your final reward is : -15.45\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1542])\n",
      "155.7354421213908\n",
      "length of actions is  792\n",
      "147.51049827114045\n",
      "length of actions is  1000\n",
      "2.9189318582606223\n",
      "length of actions is  1000\n",
      "164.90440059069545\n",
      "length of actions is  991\n",
      "26.427742473782626\n",
      "length of actions is  1000\n",
      "Your final reward is : 99.50\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2920])\n",
      "179.85936215465927\n",
      "length of actions is  650\n",
      "135.41306438128674\n",
      "length of actions is  765\n",
      "81.61310947145707\n",
      "length of actions is  1000\n",
      "30.79632445062518\n",
      "length of actions is  1000\n",
      "140.33097401184534\n",
      "length of actions is  1000\n",
      "Your final reward is : 113.60\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2444])\n",
      "188.27611495615548\n",
      "length of actions is  547\n",
      "218.76155829872607\n",
      "length of actions is  366\n",
      "220.75477576773915\n",
      "length of actions is  285\n",
      "199.46994549386264\n",
      "length of actions is  627\n",
      "210.9104731665847\n",
      "length of actions is  649\n",
      "Your final reward is : 207.63\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2600])\n",
      "-15.343370594856543\n",
      "length of actions is  1000\n",
      "222.3610985665402\n",
      "length of actions is  531\n",
      "-22.336857475521462\n",
      "length of actions is  1000\n",
      "149.80679100147609\n",
      "length of actions is  1000\n",
      "-39.38944722537944\n",
      "length of actions is  1000\n",
      "Your final reward is : 59.02\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3185])\n",
      "221.46474235280618\n",
      "length of actions is  312\n",
      "203.04902956736925\n",
      "length of actions is  624\n",
      "0.7691838715968657\n",
      "length of actions is  186\n",
      "176.32597042007583\n",
      "length of actions is  729\n",
      "265.45933852297105\n",
      "length of actions is  228\n",
      "Your final reward is : 173.41\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3140])\n",
      "233.64150026309218\n",
      "length of actions is  274\n",
      "256.52211835911\n",
      "length of actions is  356\n",
      "1.2753336011125735\n",
      "length of actions is  1000\n",
      "3.8765997274501753\n",
      "length of actions is  1000\n",
      "241.1319824462145\n",
      "length of actions is  427\n",
      "Your final reward is : 147.29\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3077])\n",
      "238.36204702488857\n",
      "length of actions is  292\n",
      "256.8461528983331\n",
      "length of actions is  309\n",
      "26.635605347180658\n",
      "length of actions is  262\n",
      "215.66938768030275\n",
      "length of actions is  426\n",
      "269.3003270925175\n",
      "length of actions is  217\n",
      "Your final reward is : 201.36\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1497])\n",
      "251.11808867199608\n",
      "length of actions is  314\n",
      "259.5616558284122\n",
      "length of actions is  326\n",
      "240.23331597969553\n",
      "length of actions is  330\n",
      "148.96750367864175\n",
      "length of actions is  1000\n",
      "262.61051747731557\n",
      "length of actions is  336\n",
      "Your final reward is : 232.50\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1514])\n",
      "251.70834435613682\n",
      "length of actions is  322\n",
      "249.50028139695988\n",
      "length of actions is  429\n",
      "250.80686688591342\n",
      "length of actions is  266\n",
      "247.79754048049858\n",
      "length of actions is  334\n",
      "104.91959465062929\n",
      "length of actions is  1000\n",
      "Your final reward is : 220.95\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1963])\n",
      "256.0602646843971\n",
      "length of actions is  297\n",
      "218.33189267178503\n",
      "length of actions is  421\n",
      "252.79039347944084\n",
      "length of actions is  328\n",
      "214.65748830262584\n",
      "length of actions is  402\n",
      "214.8464377918557\n",
      "length of actions is  450\n",
      "Your final reward is : 231.34\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2348])\n",
      "255.16440194539365\n",
      "length of actions is  271\n",
      "224.43472766109426\n",
      "length of actions is  559\n",
      "245.78144909870096\n",
      "length of actions is  342\n",
      "266.70429601315516\n",
      "length of actions is  278\n",
      "206.83843308982387\n",
      "length of actions is  406\n",
      "Your final reward is : 239.78\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3082])\n",
      "258.72206849490146\n",
      "length of actions is  298\n",
      "215.4541918203239\n",
      "length of actions is  402\n",
      "255.33501175926696\n",
      "length of actions is  464\n",
      "253.6970422999749\n",
      "length of actions is  365\n",
      "210.54498496328188\n",
      "length of actions is  536\n",
      "Your final reward is : 238.75\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2423])\n",
      "259.4927572642603\n",
      "length of actions is  284\n",
      "247.2525327955918\n",
      "length of actions is  390\n",
      "286.2650801518908\n",
      "length of actions is  270\n",
      "239.7052223272853\n",
      "length of actions is  445\n",
      "230.77325493813248\n",
      "length of actions is  232\n",
      "Your final reward is : 252.70\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2436])\n",
      "243.60639391211456\n",
      "length of actions is  360\n",
      "246.62218619844595\n",
      "length of actions is  356\n",
      "262.10614986823043\n",
      "length of actions is  541\n",
      "10.557560737541111\n",
      "length of actions is  1000\n",
      "255.74607171712387\n",
      "length of actions is  460\n",
      "Your final reward is : 203.73\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2292])\n",
      "258.15547803040903\n",
      "length of actions is  286\n",
      "263.1372865904254\n",
      "length of actions is  336\n",
      "138.47206672498626\n",
      "length of actions is  1000\n",
      "272.0837744461505\n",
      "length of actions is  234\n",
      "164.36292509621916\n",
      "length of actions is  1000\n",
      "Your final reward is : 219.24\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2019])\n",
      "255.7694436034781\n",
      "length of actions is  264\n",
      "274.8113235530817\n",
      "length of actions is  295\n",
      "267.80169236358006\n",
      "length of actions is  362\n",
      "281.2403505270131\n",
      "length of actions is  387\n",
      "264.01148538178387\n",
      "length of actions is  228\n",
      "Your final reward is : 268.73\n",
      "Improve to score 268.73 at batch 336\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2198])\n",
      "259.36359405924225\n",
      "length of actions is  257\n",
      "271.2555831013095\n",
      "length of actions is  267\n",
      "249.19238074850122\n",
      "length of actions is  310\n",
      "273.79825924690556\n",
      "length of actions is  353\n",
      "255.2120355062781\n",
      "length of actions is  237\n",
      "Your final reward is : 261.76\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2041])\n",
      "255.78377750104133\n",
      "length of actions is  263\n",
      "123.66754864385274\n",
      "length of actions is  1000\n",
      "279.65474003050474\n",
      "length of actions is  237\n",
      "263.6741239456372\n",
      "length of actions is  352\n",
      "246.84081636513915\n",
      "length of actions is  308\n",
      "Your final reward is : 233.92\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2148])\n",
      "256.68454286217883\n",
      "length of actions is  257\n",
      "273.1825675571167\n",
      "length of actions is  249\n",
      "265.52736079087805\n",
      "length of actions is  269\n",
      "253.10670556206253\n",
      "length of actions is  222\n",
      "275.8736380056617\n",
      "length of actions is  339\n",
      "Your final reward is : 264.87\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1423])\n",
      "260.49622334356457\n",
      "length of actions is  222\n",
      "275.8797264668777\n",
      "length of actions is  364\n",
      "250.55020016325466\n",
      "length of actions is  187\n",
      "282.6597903945844\n",
      "length of actions is  274\n",
      "242.47782588219\n",
      "length of actions is  217\n",
      "Your final reward is : 262.41\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1577])\n",
      "252.37777703951772\n",
      "length of actions is  276\n",
      "269.07063923451585\n",
      "length of actions is  295\n",
      "281.325541444043\n",
      "length of actions is  253\n",
      "267.0626804825591\n",
      "length of actions is  324\n",
      "250.46624926030623\n",
      "length of actions is  523\n",
      "Your final reward is : 264.06\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2737])\n",
      "258.8489102896527\n",
      "length of actions is  274\n",
      "282.68465064428074\n",
      "length of actions is  223\n",
      "254.62783442522274\n",
      "length of actions is  320\n",
      "249.11401256734456\n",
      "length of actions is  350\n",
      "236.50729313693137\n",
      "length of actions is  290\n",
      "Your final reward is : 256.36\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1774])\n",
      "257.350030473832\n",
      "length of actions is  247\n",
      "260.86884079277553\n",
      "length of actions is  232\n",
      "278.0981572020079\n",
      "length of actions is  198\n",
      "287.45962158911607\n",
      "length of actions is  289\n",
      "239.23873170361557\n",
      "length of actions is  293\n",
      "Your final reward is : 264.60\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1250])\n",
      "259.1362876795072\n",
      "length of actions is  251\n",
      "264.5826733706256\n",
      "length of actions is  158\n",
      "262.0172025456373\n",
      "length of actions is  284\n",
      "8.33570587201287\n",
      "length of actions is  1000\n",
      "278.08083319728973\n",
      "length of actions is  181\n",
      "Your final reward is : 214.43\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1214])\n",
      "263.9384410526823\n",
      "length of actions is  243\n",
      "275.767984522867\n",
      "length of actions is  243\n",
      "245.6703824590731\n",
      "length of actions is  398\n",
      "262.65281765745823\n",
      "length of actions is  228\n",
      "262.52706910145196\n",
      "length of actions is  294\n",
      "Your final reward is : 262.11\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1581])\n",
      "260.92877417897233\n",
      "length of actions is  238\n",
      "243.1740350082461\n",
      "length of actions is  216\n",
      "261.4657240274835\n",
      "length of actions is  201\n",
      "263.3003873981646\n",
      "length of actions is  213\n",
      "275.35256241612035\n",
      "length of actions is  260\n",
      "Your final reward is : 260.84\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1214])\n",
      "268.04197243324074\n",
      "length of actions is  205\n",
      "257.07947002049696\n",
      "length of actions is  232\n",
      "190.71099336778286\n",
      "length of actions is  1000\n",
      "283.201186758771\n",
      "length of actions is  152\n",
      "259.5735278014892\n",
      "length of actions is  805\n",
      "Your final reward is : 251.72\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1084])\n",
      "267.96538338323546\n",
      "length of actions is  200\n",
      "286.08012121133663\n",
      "length of actions is  228\n",
      "12.202176938918893\n",
      "length of actions is  1000\n",
      "249.49117788802403\n",
      "length of actions is  252\n",
      "271.2732576642104\n",
      "length of actions is  305\n",
      "Your final reward is : 217.40\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1317])\n",
      "267.66577732988685\n",
      "length of actions is  206\n",
      "265.03901766168656\n",
      "length of actions is  294\n",
      "240.93114767846987\n",
      "length of actions is  216\n",
      "261.34329510340865\n",
      "length of actions is  217\n",
      "298.05455720242276\n",
      "length of actions is  224\n",
      "Your final reward is : 266.61\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1214])\n",
      "270.0301440920272\n",
      "length of actions is  195\n",
      "244.93641233659372\n",
      "length of actions is  214\n",
      "146.66625485506768\n",
      "length of actions is  1000\n",
      "1.8555713635981042\n",
      "length of actions is  1000\n",
      "290.79455005591853\n",
      "length of actions is  216\n",
      "Your final reward is : 190.86\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1221])\n",
      "132.37364761668405\n",
      "length of actions is  1000\n",
      "110.30738012707072\n",
      "length of actions is  1000\n",
      "287.6360983697382\n",
      "length of actions is  187\n",
      "274.90842338280817\n",
      "length of actions is  211\n",
      "245.706215876975\n",
      "length of actions is  152\n",
      "Your final reward is : 210.19\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1109])\n",
      "270.11187009658113\n",
      "length of actions is  199\n",
      "264.70973549425514\n",
      "length of actions is  251\n",
      "275.51289419350337\n",
      "length of actions is  177\n",
      "286.91870353246685\n",
      "length of actions is  243\n",
      "136.8149703945215\n",
      "length of actions is  1000\n",
      "Your final reward is : 246.81\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2507])\n",
      "248.68948244609555\n",
      "length of actions is  754\n",
      "271.2277562264442\n",
      "length of actions is  216\n",
      "271.60070980108515\n",
      "length of actions is  201\n",
      "237.73639960714803\n",
      "length of actions is  252\n",
      "229.18460944951613\n",
      "length of actions is  257\n",
      "Your final reward is : 251.69\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2158])\n",
      "131.82987203760902\n",
      "length of actions is  1000\n",
      "89.14733976457991\n",
      "length of actions is  1000\n",
      "174.53380373426893\n",
      "length of actions is  1000\n",
      "156.76865995636413\n",
      "length of actions is  1000\n",
      "122.95424356889302\n",
      "length of actions is  1000\n",
      "Your final reward is : 135.05\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1786])\n",
      "242.3795888228687\n",
      "length of actions is  945\n",
      "236.47795959092375\n",
      "length of actions is  180\n",
      "271.46015004930587\n",
      "length of actions is  222\n",
      "249.49067642143547\n",
      "length of actions is  341\n",
      "235.54675839392826\n",
      "length of actions is  250\n",
      "Your final reward is : 247.07\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1850])\n",
      "244.36005269906607\n",
      "length of actions is  176\n",
      "277.496828530039\n",
      "length of actions is  259\n",
      "128.23953235735064\n",
      "length of actions is  1000\n",
      "244.87282798328113\n",
      "length of actions is  237\n",
      "270.67678501974353\n",
      "length of actions is  225\n",
      "Your final reward is : 233.13\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2083])\n",
      "261.09867402545325\n",
      "length of actions is  185\n",
      "285.44678167348957\n",
      "length of actions is  252\n",
      "290.34338828557964\n",
      "length of actions is  232\n",
      "135.49087394102352\n",
      "length of actions is  1000\n",
      "274.5345338651491\n",
      "length of actions is  194\n",
      "Your final reward is : 249.38\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2225])\n",
      "269.05863609836126\n",
      "length of actions is  199\n",
      "152.42232780867056\n",
      "length of actions is  1000\n",
      "229.48531534360183\n",
      "length of actions is  258\n",
      "216.0028005704587\n",
      "length of actions is  472\n",
      "280.46282888909496\n",
      "length of actions is  226\n",
      "Your final reward is : 229.49\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1533])\n",
      "132.04999055707626\n",
      "length of actions is  1000\n",
      "31.56097777559623\n",
      "length of actions is  96\n",
      "252.33868730096432\n",
      "length of actions is  295\n",
      "254.06326319980005\n",
      "length of actions is  258\n",
      "279.03792983316094\n",
      "length of actions is  250\n",
      "Your final reward is : 189.81\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1360])\n",
      "247.23993141653267\n",
      "length of actions is  494\n",
      "199.444496193369\n",
      "length of actions is  650\n",
      "224.3187392918481\n",
      "length of actions is  270\n",
      "275.3675749863776\n",
      "length of actions is  227\n",
      "281.4231585235739\n",
      "length of actions is  236\n",
      "Your final reward is : 245.56\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1025])\n",
      "262.9768837459022\n",
      "length of actions is  206\n",
      "279.0358711322889\n",
      "length of actions is  217\n",
      "268.3754747824793\n",
      "length of actions is  257\n",
      "259.3932155224623\n",
      "length of actions is  194\n",
      "249.66781116657765\n",
      "length of actions is  194\n",
      "Your final reward is : 263.89\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1963])\n",
      "268.50301713967383\n",
      "length of actions is  198\n",
      "254.57089788856152\n",
      "length of actions is  223\n",
      "237.57993331327935\n",
      "length of actions is  307\n",
      "247.29840474315216\n",
      "length of actions is  291\n",
      "255.17159398898778\n",
      "length of actions is  264\n",
      "Your final reward is : 252.62\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1086])\n",
      "130.20019318499885\n",
      "length of actions is  1000\n",
      "33.24595015466792\n",
      "length of actions is  104\n",
      "251.4448639935211\n",
      "length of actions is  202\n",
      "252.8342925781108\n",
      "length of actions is  203\n",
      "253.40369631537484\n",
      "length of actions is  215\n",
      "Your final reward is : 184.23\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1816])\n",
      "268.9895293294476\n",
      "length of actions is  195\n",
      "252.91827530951278\n",
      "length of actions is  196\n",
      "274.12960629292627\n",
      "length of actions is  222\n",
      "270.97654925951133\n",
      "length of actions is  195\n",
      "259.68314894391216\n",
      "length of actions is  182\n",
      "Your final reward is : 265.34\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1526])\n",
      "268.3683266776116\n",
      "length of actions is  206\n",
      "282.597915297879\n",
      "length of actions is  205\n",
      "252.01318013759789\n",
      "length of actions is  168\n",
      "259.9620265979922\n",
      "length of actions is  168\n",
      "251.0667903571823\n",
      "length of actions is  212\n",
      "Your final reward is : 262.80\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1103])\n",
      "132.0575888051821\n",
      "length of actions is  1000\n",
      "33.815108582012584\n",
      "length of actions is  104\n",
      "253.07660218278437\n",
      "length of actions is  187\n",
      "150.5632900246681\n",
      "length of actions is  1000\n",
      "-9.729238049913889\n",
      "length of actions is  142\n",
      "Your final reward is : 111.96\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1703])\n",
      "271.4748334707761\n",
      "length of actions is  184\n",
      "-16.644603777850605\n",
      "length of actions is  127\n",
      "264.28945473969543\n",
      "length of actions is  179\n",
      "271.8352391030817\n",
      "length of actions is  183\n",
      "-10.57210915287449\n",
      "length of actions is  78\n",
      "Your final reward is : 156.08\n",
      "torch.from_numpy(rewards) looks like  torch.Size([736])\n",
      "269.24611952520416\n",
      "length of actions is  198\n",
      "264.1362224883102\n",
      "length of actions is  215\n",
      "256.74507036512546\n",
      "length of actions is  212\n",
      "256.2246072274386\n",
      "length of actions is  202\n",
      "272.9903700932366\n",
      "length of actions is  165\n",
      "Your final reward is : 263.87\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1081])\n",
      "260.8907845048559\n",
      "length of actions is  174\n",
      "291.8660914968232\n",
      "length of actions is  177\n",
      "258.29158459840426\n",
      "length of actions is  171\n",
      "274.6799891106427\n",
      "length of actions is  157\n",
      "299.7574095627591\n",
      "length of actions is  206\n",
      "Your final reward is : 277.10\n",
      "Improve to score 277.10 at batch 369\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1023])\n",
      "271.4093802471397\n",
      "length of actions is  192\n",
      "123.12199097551813\n",
      "length of actions is  1000\n",
      "-18.39124940746656\n",
      "length of actions is  115\n",
      "258.84565871564473\n",
      "length of actions is  190\n",
      "289.1788095140238\n",
      "length of actions is  208\n",
      "Your final reward is : 184.83\n",
      "torch.from_numpy(rewards) looks like  torch.Size([977])\n",
      "268.3344214464237\n",
      "length of actions is  192\n",
      "256.17051444759636\n",
      "length of actions is  200\n",
      "289.5582066512259\n",
      "length of actions is  214\n",
      "-26.478742077047997\n",
      "length of actions is  124\n",
      "271.8780404534\n",
      "length of actions is  214\n",
      "Your final reward is : 211.89\n",
      "torch.from_numpy(rewards) looks like  torch.Size([821])\n",
      "273.9111474892625\n",
      "length of actions is  191\n",
      "280.5570259500232\n",
      "length of actions is  243\n",
      "286.30648786062693\n",
      "length of actions is  266\n",
      "280.552812543517\n",
      "length of actions is  254\n",
      "43.3183149191714\n",
      "length of actions is  139\n",
      "Your final reward is : 232.93\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1349])\n",
      "257.631900346091\n",
      "length of actions is  179\n",
      "280.872733420788\n",
      "length of actions is  204\n",
      "259.997164742843\n",
      "length of actions is  218\n",
      "-34.92662364947857\n",
      "length of actions is  148\n",
      "247.53809392629796\n",
      "length of actions is  416\n",
      "Your final reward is : 202.22\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2084])\n",
      "259.17710791418347\n",
      "length of actions is  320\n",
      "37.41559574009656\n",
      "length of actions is  141\n",
      "146.2713108478664\n",
      "length of actions is  1000\n",
      "175.02276684665424\n",
      "length of actions is  1000\n",
      "153.11579757948638\n",
      "length of actions is  1000\n",
      "Your final reward is : 154.20\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2727])\n",
      "258.2011872456119\n",
      "length of actions is  319\n",
      "264.27440561926596\n",
      "length of actions is  157\n",
      "-68.60454531918634\n",
      "length of actions is  122\n",
      "132.45718406800472\n",
      "length of actions is  1000\n",
      "5.798307915483377\n",
      "length of actions is  127\n",
      "Your final reward is : 118.43\n",
      "torch.from_numpy(rewards) looks like  torch.Size([727])\n",
      "252.7521578101628\n",
      "length of actions is  521\n",
      "267.96348966189885\n",
      "length of actions is  958\n",
      "173.06821190007517\n",
      "length of actions is  1000\n",
      "167.57426660524052\n",
      "length of actions is  1000\n",
      "62.836735844082625\n",
      "length of actions is  142\n",
      "Your final reward is : 184.84\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1178])\n",
      "269.61685577077395\n",
      "length of actions is  200\n",
      "50.565164933896\n",
      "length of actions is  142\n",
      "148.565243536781\n",
      "length of actions is  1000\n",
      "268.6149194854022\n",
      "length of actions is  280\n",
      "240.11502936609253\n",
      "length of actions is  339\n",
      "Your final reward is : 195.50\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2739])\n",
      "252.98713553766893\n",
      "length of actions is  616\n",
      "158.55772052513768\n",
      "length of actions is  1000\n",
      "62.50642039269022\n",
      "length of actions is  125\n",
      "253.63850976027842\n",
      "length of actions is  314\n",
      "132.79158839920416\n",
      "length of actions is  1000\n",
      "Your final reward is : 172.10\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1039])\n",
      "263.09481857353194\n",
      "length of actions is  190\n",
      "265.71212564880557\n",
      "length of actions is  295\n",
      "274.3726189545812\n",
      "length of actions is  274\n",
      "266.48334471322613\n",
      "length of actions is  244\n",
      "13.977930068143749\n",
      "length of actions is  135\n",
      "Your final reward is : 216.73\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3560])\n",
      "134.20470947753674\n",
      "length of actions is  1000\n",
      "31.33349665183374\n",
      "length of actions is  98\n",
      "159.52597813961694\n",
      "length of actions is  1000\n",
      "221.9812531913408\n",
      "length of actions is  262\n",
      "235.34355974395135\n",
      "length of actions is  303\n",
      "Your final reward is : 156.48\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1785])\n",
      "259.80622245027325\n",
      "length of actions is  194\n",
      "162.88328026753592\n",
      "length of actions is  1000\n",
      "-10.418216113978616\n",
      "length of actions is  88\n",
      "159.08879765479224\n",
      "length of actions is  1000\n",
      "274.2311133105182\n",
      "length of actions is  440\n",
      "Your final reward is : 169.12\n",
      "torch.from_numpy(rewards) looks like  torch.Size([864])\n",
      "259.4761293738824\n",
      "length of actions is  192\n",
      "245.99902378047113\n",
      "length of actions is  265\n",
      "251.63942114398165\n",
      "length of actions is  581\n",
      "238.98484989763452\n",
      "length of actions is  345\n",
      "267.8939419062022\n",
      "length of actions is  185\n",
      "Your final reward is : 252.80\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2412])\n",
      "135.2124835474396\n",
      "length of actions is  1000\n",
      "-23.983758167670857\n",
      "length of actions is  85\n",
      "143.15389644912062\n",
      "length of actions is  1000\n",
      "32.12408434949356\n",
      "length of actions is  131\n",
      "154.72300279974303\n",
      "length of actions is  1000\n",
      "Your final reward is : 88.25\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2112])\n",
      "147.73174485842782\n",
      "length of actions is  1000\n",
      "29.66177333427609\n",
      "length of actions is  90\n",
      "270.38408582192346\n",
      "length of actions is  176\n",
      "132.65711360903606\n",
      "length of actions is  865\n",
      "0.16808726575192168\n",
      "length of actions is  86\n",
      "Your final reward is : 116.12\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2785])\n",
      "251.8476014216285\n",
      "length of actions is  574\n",
      "220.0692561193894\n",
      "length of actions is  326\n",
      "16.852627644379652\n",
      "length of actions is  82\n",
      "-42.14466773969282\n",
      "length of actions is  203\n",
      "88.86974606361008\n",
      "length of actions is  1000\n",
      "Your final reward is : 107.10\n",
      "torch.from_numpy(rewards) looks like  torch.Size([701])\n",
      "252.5744860929498\n",
      "length of actions is  769\n",
      "-17.07749688896031\n",
      "length of actions is  419\n",
      "7.454520174521463\n",
      "length of actions is  88\n",
      "34.84127196729068\n",
      "length of actions is  104\n",
      "-0.4680249156114087\n",
      "length of actions is  147\n",
      "Your final reward is : 55.46\n",
      "torch.from_numpy(rewards) looks like  torch.Size([817])\n",
      "128.96063313324504\n",
      "length of actions is  1000\n",
      "21.868418784767087\n",
      "length of actions is  103\n",
      "71.8749037981336\n",
      "length of actions is  101\n",
      "0.43992652950879574\n",
      "length of actions is  89\n",
      "43.876823803866586\n",
      "length of actions is  180\n",
      "Your final reward is : 53.40\n",
      "torch.from_numpy(rewards) looks like  torch.Size([879])\n",
      "138.0613370230075\n",
      "length of actions is  1000\n",
      "19.468896371209354\n",
      "length of actions is  106\n",
      "251.9091788709872\n",
      "length of actions is  191\n",
      "164.12442993143975\n",
      "length of actions is  1000\n",
      "221.14974848154168\n",
      "length of actions is  457\n",
      "Your final reward is : 158.94\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2044])\n",
      "258.03205879796735\n",
      "length of actions is  452\n",
      "19.615118212237547\n",
      "length of actions is  140\n",
      "233.02184879528718\n",
      "length of actions is  405\n",
      "-56.26202539924141\n",
      "length of actions is  567\n",
      "232.90412904253483\n",
      "length of actions is  304\n",
      "Your final reward is : 137.46\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3225])\n",
      "143.35905667677127\n",
      "length of actions is  1000\n",
      "27.492716804680143\n",
      "length of actions is  93\n",
      "59.41296810603049\n",
      "length of actions is  118\n",
      "11.631640478183272\n",
      "length of actions is  124\n",
      "120.91304574358801\n",
      "length of actions is  1000\n",
      "Your final reward is : 72.56\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2407])\n",
      "261.9011960714524\n",
      "length of actions is  423\n",
      "267.3009787283291\n",
      "length of actions is  180\n",
      "129.09557544260466\n",
      "length of actions is  1000\n",
      "239.84735566270695\n",
      "length of actions is  411\n",
      "-5.218277394185122\n",
      "length of actions is  129\n",
      "Your final reward is : 178.59\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1905])\n",
      "154.75792184431558\n",
      "length of actions is  1000\n",
      "19.58927857601296\n",
      "length of actions is  110\n",
      "1.1173898548591836\n",
      "length of actions is  139\n",
      "243.7953085392071\n",
      "length of actions is  228\n",
      "249.12865996782566\n",
      "length of actions is  285\n",
      "Your final reward is : 133.68\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1096])\n",
      "149.81435252613196\n",
      "length of actions is  1000\n",
      "259.70820075299\n",
      "length of actions is  321\n",
      "26.405570504957097\n",
      "length of actions is  117\n",
      "-9.671975572248826\n",
      "length of actions is  127\n",
      "7.695371493380264\n",
      "length of actions is  129\n",
      "Your final reward is : 86.79\n",
      "torch.from_numpy(rewards) looks like  torch.Size([704])\n",
      "48.01710855982003\n",
      "length of actions is  131\n",
      "150.01129914577598\n",
      "length of actions is  1000\n",
      "102.22549280889865\n",
      "length of actions is  1000\n",
      "241.32253764194502\n",
      "length of actions is  186\n",
      "259.2798851246809\n",
      "length of actions is  223\n",
      "Your final reward is : 160.17\n",
      "torch.from_numpy(rewards) looks like  torch.Size([818])\n",
      "262.08621822469763\n",
      "length of actions is  474\n",
      "278.6233906937224\n",
      "length of actions is  223\n",
      "248.03524996238318\n",
      "length of actions is  201\n",
      "285.2578482822858\n",
      "length of actions is  173\n",
      "16.103640234738265\n",
      "length of actions is  111\n",
      "Your final reward is : 218.02\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4090])\n",
      "256.18956520742455\n",
      "length of actions is  351\n",
      "297.786354409686\n",
      "length of actions is  261\n",
      "154.25586197047295\n",
      "length of actions is  1000\n",
      "250.00708582092\n",
      "length of actions is  844\n",
      "236.42865084183097\n",
      "length of actions is  171\n",
      "Your final reward is : 238.93\n",
      "torch.from_numpy(rewards) looks like  torch.Size([636])\n",
      "259.4583646146921\n",
      "length of actions is  262\n",
      "268.8202024350363\n",
      "length of actions is  217\n",
      "243.5475484833695\n",
      "length of actions is  997\n",
      "230.15779658726018\n",
      "length of actions is  336\n",
      "272.5903827315117\n",
      "length of actions is  284\n",
      "Your final reward is : 254.91\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1728])\n",
      "257.88127270902135\n",
      "length of actions is  314\n",
      "271.9750056157885\n",
      "length of actions is  234\n",
      "66.83597033735711\n",
      "length of actions is  121\n",
      "271.2018472852717\n",
      "length of actions is  235\n",
      "-25.41014001501256\n",
      "length of actions is  157\n",
      "Your final reward is : 168.50\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1854])\n",
      "256.4397663811273\n",
      "length of actions is  380\n",
      "40.358145340872966\n",
      "length of actions is  170\n",
      "44.79259632739533\n",
      "length of actions is  206\n",
      "167.83500042255713\n",
      "length of actions is  1000\n",
      "164.45772767865017\n",
      "length of actions is  1000\n",
      "Your final reward is : 134.78\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2326])\n",
      "151.24445877931547\n",
      "length of actions is  1000\n",
      "282.5956467981083\n",
      "length of actions is  231\n",
      "272.5337639174621\n",
      "length of actions is  533\n",
      "263.16415136338185\n",
      "length of actions is  169\n",
      "158.96023685960895\n",
      "length of actions is  1000\n",
      "Your final reward is : 225.70\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1969])\n",
      "146.6897747633774\n",
      "length of actions is  1000\n",
      "281.0736811942812\n",
      "length of actions is  250\n",
      "154.86317542361104\n",
      "length of actions is  1000\n",
      "41.70219137737428\n",
      "length of actions is  153\n",
      "24.997350873164322\n",
      "length of actions is  143\n",
      "Your final reward is : 129.87\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3309])\n",
      "122.34374716519798\n",
      "length of actions is  1000\n",
      "281.22115742663914\n",
      "length of actions is  225\n",
      "144.38514186824784\n",
      "length of actions is  1000\n",
      "159.3555134429025\n",
      "length of actions is  1000\n",
      "234.11184020364303\n",
      "length of actions is  443\n",
      "Your final reward is : 188.28\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3687])\n",
      "128.1568420552551\n",
      "length of actions is  1000\n",
      "300.0407648664821\n",
      "length of actions is  237\n",
      "146.18794653583006\n",
      "length of actions is  1000\n",
      "246.89874523863446\n",
      "length of actions is  252\n",
      "258.5701766431298\n",
      "length of actions is  201\n",
      "Your final reward is : 215.97\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1772])\n",
      "122.78817203748704\n",
      "length of actions is  1000\n",
      "293.60949504503805\n",
      "length of actions is  226\n",
      "165.6988031572781\n",
      "length of actions is  1000\n",
      "166.46428930558713\n",
      "length of actions is  1000\n",
      "163.49604049093398\n",
      "length of actions is  1000\n",
      "Your final reward is : 182.41\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1879])\n",
      "244.75529261861018\n",
      "length of actions is  727\n",
      "185.93130086974003\n",
      "length of actions is  1000\n",
      "256.4703242669668\n",
      "length of actions is  226\n",
      "46.24781109349843\n",
      "length of actions is  138\n",
      "160.18795446721018\n",
      "length of actions is  1000\n",
      "Your final reward is : 178.72\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1106])\n",
      "247.8039922060511\n",
      "length of actions is  564\n",
      "160.58022098092206\n",
      "length of actions is  1000\n",
      "44.11032661046187\n",
      "length of actions is  172\n",
      "152.5855379287182\n",
      "length of actions is  1000\n",
      "132.2819741227834\n",
      "length of actions is  1000\n",
      "Your final reward is : 147.47\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1776])\n",
      "251.1547545086873\n",
      "length of actions is  461\n",
      "275.52303724626336\n",
      "length of actions is  158\n",
      "263.5684596023791\n",
      "length of actions is  941\n",
      "215.28724263968195\n",
      "length of actions is  1000\n",
      "163.94464718748546\n",
      "length of actions is  1000\n",
      "Your final reward is : 233.90\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1694])\n",
      "131.6136120764469\n",
      "length of actions is  1000\n",
      "273.39325833377757\n",
      "length of actions is  280\n",
      "168.39894007548344\n",
      "length of actions is  1000\n",
      "37.233080196843844\n",
      "length of actions is  180\n",
      "163.39384750922463\n",
      "length of actions is  1000\n",
      "Your final reward is : 154.81\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1963])\n",
      "119.9430733637686\n",
      "length of actions is  1000\n",
      "275.3224806567439\n",
      "length of actions is  298\n",
      "242.26771446351282\n",
      "length of actions is  263\n",
      "165.28023180238037\n",
      "length of actions is  501\n",
      "135.66022450000838\n",
      "length of actions is  1000\n",
      "Your final reward is : 187.69\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1622])\n",
      "133.37563970995816\n",
      "length of actions is  1000\n",
      "171.0346959384612\n",
      "length of actions is  1000\n",
      "262.6426284529395\n",
      "length of actions is  261\n",
      "285.385852386255\n",
      "length of actions is  250\n",
      "162.45163252292207\n",
      "length of actions is  1000\n",
      "Your final reward is : 202.98\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1116])\n",
      "233.65282734235365\n",
      "length of actions is  933\n",
      "276.35033651529807\n",
      "length of actions is  176\n",
      "138.13681980231024\n",
      "length of actions is  1000\n",
      "137.2779475097663\n",
      "length of actions is  1000\n",
      "261.4899937127677\n",
      "length of actions is  360\n",
      "Your final reward is : 209.38\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4018])\n",
      "133.71768088116963\n",
      "length of actions is  1000\n",
      "264.60091132413163\n",
      "length of actions is  963\n",
      "272.47214933805355\n",
      "length of actions is  185\n",
      "274.81475126055534\n",
      "length of actions is  341\n",
      "254.98606730021066\n",
      "length of actions is  202\n",
      "Your final reward is : 240.12\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2546])\n",
      "132.3110094858837\n",
      "length of actions is  1000\n",
      "283.8251353740535\n",
      "length of actions is  282\n",
      "245.3989543954353\n",
      "length of actions is  263\n",
      "70.54524763943238\n",
      "length of actions is  184\n",
      "249.5489786952172\n",
      "length of actions is  819\n",
      "Your final reward is : 196.33\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2690])\n",
      "121.81631033755068\n",
      "length of actions is  1000\n",
      "294.96516408050195\n",
      "length of actions is  221\n",
      "44.60215730173462\n",
      "length of actions is  114\n",
      "152.14624311165016\n",
      "length of actions is  1000\n",
      "16.21871409254686\n",
      "length of actions is  191\n",
      "Your final reward is : 125.95\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3441])\n",
      "121.59632915049005\n",
      "length of actions is  1000\n",
      "279.7605445676238\n",
      "length of actions is  279\n",
      "139.52695802534302\n",
      "length of actions is  1000\n",
      "239.69649659461797\n",
      "length of actions is  452\n",
      "-29.584475166477034\n",
      "length of actions is  181\n",
      "Your final reward is : 150.20\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1590])\n",
      "128.5800835193069\n",
      "length of actions is  1000\n",
      "287.2221492590601\n",
      "length of actions is  256\n",
      "283.18171723837247\n",
      "length of actions is  230\n",
      "170.0717051717759\n",
      "length of actions is  1000\n",
      "262.88623219994304\n",
      "length of actions is  241\n",
      "Your final reward is : 226.39\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2600])\n",
      "136.8496770236862\n",
      "length of actions is  1000\n",
      "285.7914170987429\n",
      "length of actions is  296\n",
      "99.45286492794203\n",
      "length of actions is  1000\n",
      "272.927415871889\n",
      "length of actions is  427\n",
      "164.1367305495129\n",
      "length of actions is  680\n",
      "Your final reward is : 191.83\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4531])\n",
      "124.22574101536311\n",
      "length of actions is  1000\n",
      "288.53238227489663\n",
      "length of actions is  254\n",
      "145.60046487828913\n",
      "length of actions is  1000\n",
      "150.21345164234734\n",
      "length of actions is  1000\n",
      "66.24269250894352\n",
      "length of actions is  137\n",
      "Your final reward is : 154.96\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3407])\n",
      "144.86301820877807\n",
      "length of actions is  1000\n",
      "291.24890093107905\n",
      "length of actions is  218\n",
      "266.24231946388056\n",
      "length of actions is  271\n",
      "28.05186510555643\n",
      "length of actions is  131\n",
      "269.69897058784386\n",
      "length of actions is  241\n",
      "Your final reward is : 200.02\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1079])\n",
      "259.3889127338301\n",
      "length of actions is  255\n",
      "237.1249282739687\n",
      "length of actions is  244\n",
      "280.1305072790188\n",
      "length of actions is  221\n",
      "286.87671558489467\n",
      "length of actions is  250\n",
      "282.97823099602385\n",
      "length of actions is  243\n",
      "Your final reward is : 269.30\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2727])\n",
      "261.8924743425482\n",
      "length of actions is  334\n",
      "278.3652222985682\n",
      "length of actions is  222\n",
      "260.14640347361683\n",
      "length of actions is  209\n",
      "163.98114133385937\n",
      "length of actions is  1000\n",
      "67.81714377726414\n",
      "length of actions is  125\n",
      "Your final reward is : 206.44\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2044])\n",
      "268.7095375683904\n",
      "length of actions is  630\n",
      "252.3323765867861\n",
      "length of actions is  222\n",
      "69.15827561163934\n",
      "length of actions is  129\n",
      "275.459580097519\n",
      "length of actions is  214\n",
      "246.49658544132652\n",
      "length of actions is  262\n",
      "Your final reward is : 222.43\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1075])\n",
      "254.35135140118427\n",
      "length of actions is  269\n",
      "297.30891212418646\n",
      "length of actions is  211\n",
      "280.63092313455644\n",
      "length of actions is  227\n",
      "294.2995303454545\n",
      "length of actions is  213\n",
      "148.25598301765854\n",
      "length of actions is  1000\n",
      "Your final reward is : 254.97\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1820])\n",
      "145.10902402319786\n",
      "length of actions is  1000\n",
      "162.07159070484627\n",
      "length of actions is  1000\n",
      "271.64982006938885\n",
      "length of actions is  262\n",
      "285.4341059655636\n",
      "length of actions is  247\n",
      "278.0685553172567\n",
      "length of actions is  491\n",
      "Your final reward is : 228.47\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2044])\n",
      "264.34043468164145\n",
      "length of actions is  236\n",
      "289.2888011265884\n",
      "length of actions is  214\n",
      "274.61602451454246\n",
      "length of actions is  204\n",
      "285.1214221426477\n",
      "length of actions is  203\n",
      "233.5760829175547\n",
      "length of actions is  210\n",
      "Your final reward is : 269.39\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1552])\n",
      "262.50594268742634\n",
      "length of actions is  234\n",
      "267.98987704745105\n",
      "length of actions is  225\n",
      "287.61205348848546\n",
      "length of actions is  180\n",
      "277.5020994049799\n",
      "length of actions is  244\n",
      "247.09217083712062\n",
      "length of actions is  219\n",
      "Your final reward is : 268.54\n",
      "torch.from_numpy(rewards) looks like  torch.Size([948])\n",
      "260.3477937040626\n",
      "length of actions is  258\n",
      "286.11747010471856\n",
      "length of actions is  218\n",
      "175.14120478552584\n",
      "length of actions is  1000\n",
      "272.7034033063585\n",
      "length of actions is  243\n",
      "250.51890688108548\n",
      "length of actions is  245\n",
      "Your final reward is : 248.97\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1349])\n",
      "265.8122326825581\n",
      "length of actions is  218\n",
      "281.70845897925955\n",
      "length of actions is  220\n",
      "171.25916847937717\n",
      "length of actions is  1000\n",
      "284.55250286849355\n",
      "length of actions is  250\n",
      "240.0249502417954\n",
      "length of actions is  239\n",
      "Your final reward is : 248.67\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1963])\n",
      "141.4229732193571\n",
      "length of actions is  1000\n",
      "302.7136095651198\n",
      "length of actions is  218\n",
      "264.9436485145027\n",
      "length of actions is  268\n",
      "297.31990951617286\n",
      "length of actions is  193\n",
      "266.52856509024525\n",
      "length of actions is  244\n",
      "Your final reward is : 254.59\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1314])\n",
      "261.0983696400875\n",
      "length of actions is  232\n",
      "271.41547513914475\n",
      "length of actions is  251\n",
      "264.66034015215484\n",
      "length of actions is  240\n",
      "255.69168815552493\n",
      "length of actions is  256\n",
      "282.494129783629\n",
      "length of actions is  214\n",
      "Your final reward is : 267.07\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1184])\n",
      "159.0226172563619\n",
      "length of actions is  1000\n",
      "302.7510857789397\n",
      "length of actions is  228\n",
      "277.23643721531334\n",
      "length of actions is  230\n",
      "237.0208563095252\n",
      "length of actions is  252\n",
      "260.4434794384956\n",
      "length of actions is  245\n",
      "Your final reward is : 247.29\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1522])\n",
      "161.94174105863652\n",
      "length of actions is  1000\n",
      "301.8679249660949\n",
      "length of actions is  210\n",
      "280.60505561763364\n",
      "length of actions is  200\n",
      "287.1512206440158\n",
      "length of actions is  195\n",
      "257.64955876372744\n",
      "length of actions is  218\n",
      "Your final reward is : 257.84\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1043])\n",
      "153.03453308142892\n",
      "length of actions is  1000\n",
      "65.36774856147346\n",
      "length of actions is  133\n",
      "248.41513233777803\n",
      "length of actions is  243\n",
      "172.2848022278254\n",
      "length of actions is  1000\n",
      "54.16894129896434\n",
      "length of actions is  131\n",
      "Your final reward is : 138.65\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2280])\n",
      "154.97108527601617\n",
      "length of actions is  1000\n",
      "67.536392538494\n",
      "length of actions is  136\n",
      "126.53245391219147\n",
      "length of actions is  1000\n",
      "58.86006091390371\n",
      "length of actions is  138\n",
      "147.1645330386987\n",
      "length of actions is  1000\n",
      "Your final reward is : 111.01\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3439])\n",
      "161.06795940748887\n",
      "length of actions is  1000\n",
      "60.66672369419277\n",
      "length of actions is  128\n",
      "172.12963042940663\n",
      "length of actions is  1000\n",
      "160.1927358468519\n",
      "length of actions is  1000\n",
      "192.41144550620314\n",
      "length of actions is  1000\n",
      "Your final reward is : 149.29\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2044])\n",
      "276.0209602313659\n",
      "length of actions is  196\n",
      "267.5284354492054\n",
      "length of actions is  238\n",
      "296.25073723437885\n",
      "length of actions is  190\n",
      "231.00571188364293\n",
      "length of actions is  505\n",
      "232.59969914077493\n",
      "length of actions is  253\n",
      "Your final reward is : 260.68\n",
      "torch.from_numpy(rewards) looks like  torch.Size([948])\n",
      "32.5319776035048\n",
      "length of actions is  126\n",
      "44.771453393658675\n",
      "length of actions is  133\n",
      "216.20951282977745\n",
      "length of actions is  383\n",
      "253.37629206230653\n",
      "length of actions is  250\n",
      "235.15536553169414\n",
      "length of actions is  265\n",
      "Your final reward is : 156.41\n",
      "torch.from_numpy(rewards) looks like  torch.Size([714])\n",
      "36.467655564146725\n",
      "length of actions is  131\n",
      "263.16799909011036\n",
      "length of actions is  180\n",
      "246.48879261299876\n",
      "length of actions is  189\n",
      "46.855918447098105\n",
      "length of actions is  102\n",
      "34.73171686030892\n",
      "length of actions is  111\n",
      "Your final reward is : 125.54\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1135])\n",
      "7.53279434240099\n",
      "length of actions is  130\n",
      "36.3509822373251\n",
      "length of actions is  134\n",
      "145.26060203876298\n",
      "length of actions is  1000\n",
      "139.28061135061247\n",
      "length of actions is  1000\n",
      "48.96537010016311\n",
      "length of actions is  122\n",
      "Your final reward is : 75.48\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1382])\n",
      "26.049647719486003\n",
      "length of actions is  134\n",
      "54.492523791728416\n",
      "length of actions is  126\n",
      "265.7209262768473\n",
      "length of actions is  177\n",
      "22.98334838102825\n",
      "length of actions is  166\n",
      "261.06322490874044\n",
      "length of actions is  215\n",
      "Your final reward is : 126.06\n",
      "torch.from_numpy(rewards) looks like  torch.Size([860])\n",
      "16.002346402701434\n",
      "length of actions is  130\n",
      "159.22660576485305\n",
      "length of actions is  1000\n",
      "61.40744767113864\n",
      "length of actions is  130\n",
      "283.4784115700952\n",
      "length of actions is  210\n",
      "284.19839385320904\n",
      "length of actions is  200\n",
      "Your final reward is : 160.86\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1076])\n",
      "15.378339914621137\n",
      "length of actions is  129\n",
      "281.68347231413736\n",
      "length of actions is  312\n",
      "245.316160789515\n",
      "length of actions is  179\n",
      "248.97591017175392\n",
      "length of actions is  184\n",
      "12.340651623399097\n",
      "length of actions is  153\n",
      "Your final reward is : 160.74\n",
      "torch.from_numpy(rewards) looks like  torch.Size([686])\n",
      "9.739058640554177\n",
      "length of actions is  126\n",
      "17.61489394356977\n",
      "length of actions is  129\n",
      "57.21786388998831\n",
      "length of actions is  141\n",
      "55.57914239761135\n",
      "length of actions is  122\n",
      "65.31920687886185\n",
      "length of actions is  148\n",
      "Your final reward is : 41.09\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1582])\n",
      "21.697651979682632\n",
      "length of actions is  125\n",
      "123.51004768326155\n",
      "length of actions is  1000\n",
      "280.49232487929135\n",
      "length of actions is  171\n",
      "34.64070277322591\n",
      "length of actions is  124\n",
      "33.259774775000324\n",
      "length of actions is  116\n",
      "Your final reward is : 98.72\n",
      "torch.from_numpy(rewards) looks like  torch.Size([948])\n",
      "8.927501428450697\n",
      "length of actions is  125\n",
      "237.3017330831711\n",
      "length of actions is  199\n",
      "56.41790858192232\n",
      "length of actions is  139\n",
      "14.30397245146277\n",
      "length of actions is  179\n",
      "10.72185663746427\n",
      "length of actions is  147\n",
      "Your final reward is : 65.53\n",
      "torch.from_numpy(rewards) looks like  torch.Size([934])\n",
      "12.18511805355513\n",
      "length of actions is  127\n",
      "8.325247773258496\n",
      "length of actions is  190\n",
      "137.54150585902227\n",
      "length of actions is  1000\n",
      "264.2386110433565\n",
      "length of actions is  206\n",
      "150.63798056165356\n",
      "length of actions is  378\n",
      "Your final reward is : 114.59\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2150])\n",
      "22.152411308335516\n",
      "length of actions is  128\n",
      "34.7548067978052\n",
      "length of actions is  153\n",
      "257.0579810834648\n",
      "length of actions is  188\n",
      "57.5882145986333\n",
      "length of actions is  128\n",
      "39.049056819295544\n",
      "length of actions is  120\n",
      "Your final reward is : 82.12\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1215])\n",
      "20.269761395610928\n",
      "length of actions is  131\n",
      "146.6680724174377\n",
      "length of actions is  1000\n",
      "267.08723511115994\n",
      "length of actions is  255\n",
      "256.9588404649929\n",
      "length of actions is  491\n",
      "263.02161123985303\n",
      "length of actions is  734\n",
      "Your final reward is : 190.80\n",
      "torch.from_numpy(rewards) looks like  torch.Size([759])\n",
      "31.272916063472906\n",
      "length of actions is  122\n",
      "58.09274234556514\n",
      "length of actions is  117\n",
      "263.93144046934265\n",
      "length of actions is  212\n",
      "30.639144955479964\n",
      "length of actions is  126\n",
      "21.35915926845766\n",
      "length of actions is  167\n",
      "Your final reward is : 81.06\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1009])\n",
      "29.4354492466461\n",
      "length of actions is  120\n",
      "137.22239377664536\n",
      "length of actions is  1000\n",
      "276.23969566801486\n",
      "length of actions is  170\n",
      "135.04038919453214\n",
      "length of actions is  1000\n",
      "52.111329870953625\n",
      "length of actions is  116\n",
      "Your final reward is : 126.01\n",
      "torch.from_numpy(rewards) looks like  torch.Size([935])\n",
      "34.00692935221454\n",
      "length of actions is  123\n",
      "240.26429998046973\n",
      "length of actions is  206\n",
      "61.81825195418321\n",
      "length of actions is  142\n",
      "262.57273395713946\n",
      "length of actions is  212\n",
      "273.56930358318755\n",
      "length of actions is  206\n",
      "Your final reward is : 174.45\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1032])\n",
      "26.746622456852435\n",
      "length of actions is  122\n",
      "38.10876177924419\n",
      "length of actions is  112\n",
      "58.38529553347297\n",
      "length of actions is  130\n",
      "193.35559023042342\n",
      "length of actions is  428\n",
      "38.66860075131146\n",
      "length of actions is  116\n",
      "Your final reward is : 71.05\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1215])\n",
      "46.43196253666886\n",
      "length of actions is  127\n",
      "23.76865885379469\n",
      "length of actions is  154\n",
      "248.5637923661931\n",
      "length of actions is  215\n",
      "246.21668811907398\n",
      "length of actions is  254\n",
      "46.231534981070354\n",
      "length of actions is  116\n",
      "Your final reward is : 122.24\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1574])\n",
      "31.270632882758207\n",
      "length of actions is  128\n",
      "47.41639517343023\n",
      "length of actions is  139\n",
      "238.44674804496972\n",
      "length of actions is  228\n",
      "32.525941357582326\n",
      "length of actions is  126\n",
      "260.0744278379659\n",
      "length of actions is  254\n",
      "Your final reward is : 121.95\n",
      "torch.from_numpy(rewards) looks like  torch.Size([892])\n",
      "270.30836323680865\n",
      "length of actions is  263\n",
      "61.85483868707186\n",
      "length of actions is  133\n",
      "59.02116484804941\n",
      "length of actions is  113\n",
      "244.09761591804275\n",
      "length of actions is  232\n",
      "278.3960071887462\n",
      "length of actions is  204\n",
      "Your final reward is : 182.74\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1163])\n",
      "272.6226806998642\n",
      "length of actions is  193\n",
      "149.88550044406833\n",
      "length of actions is  1000\n",
      "38.75086761024926\n",
      "length of actions is  120\n",
      "43.66197074280774\n",
      "length of actions is  124\n",
      "153.65690087494974\n",
      "length of actions is  1000\n",
      "Your final reward is : 131.72\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1509])\n",
      "51.95040760257993\n",
      "length of actions is  132\n",
      "294.3115113746584\n",
      "length of actions is  255\n",
      "21.486897661698436\n",
      "length of actions is  116\n",
      "31.76623033089973\n",
      "length of actions is  127\n",
      "272.10393028663833\n",
      "length of actions is  237\n",
      "Your final reward is : 134.32\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1111])\n",
      "24.36058605782773\n",
      "length of actions is  119\n",
      "274.1121852398089\n",
      "length of actions is  175\n",
      "239.7425757287926\n",
      "length of actions is  176\n",
      "271.2473130383627\n",
      "length of actions is  194\n",
      "65.70424588383139\n",
      "length of actions is  133\n",
      "Your final reward is : 175.03\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1126])\n",
      "33.86842173410713\n",
      "length of actions is  119\n",
      "161.87839495730304\n",
      "length of actions is  1000\n",
      "138.55992470865317\n",
      "length of actions is  1000\n",
      "251.85960908338427\n",
      "length of actions is  237\n",
      "55.677762755230106\n",
      "length of actions is  105\n",
      "Your final reward is : 128.37\n",
      "torch.from_numpy(rewards) looks like  torch.Size([594])\n",
      "30.15260631330878\n",
      "length of actions is  122\n",
      "48.16623980291874\n",
      "length of actions is  108\n",
      "240.73095624949121\n",
      "length of actions is  166\n",
      "33.97728366423425\n",
      "length of actions is  103\n",
      "265.04025435916867\n",
      "length of actions is  196\n",
      "Your final reward is : 123.61\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1178])\n",
      "30.909409316830533\n",
      "length of actions is  119\n",
      "272.4684082944256\n",
      "length of actions is  198\n",
      "249.10362872034463\n",
      "length of actions is  163\n",
      "287.2979817239045\n",
      "length of actions is  187\n",
      "261.48104380734975\n",
      "length of actions is  197\n",
      "Your final reward is : 220.25\n",
      "torch.from_numpy(rewards) looks like  torch.Size([743])\n",
      "21.36395866900118\n",
      "length of actions is  117\n",
      "57.08394780748378\n",
      "length of actions is  113\n",
      "243.31410040734164\n",
      "length of actions is  204\n",
      "35.16009361238295\n",
      "length of actions is  106\n",
      "26.80406973169086\n",
      "length of actions is  107\n",
      "Your final reward is : 76.75\n",
      "torch.from_numpy(rewards) looks like  torch.Size([602])\n",
      "23.884342553600348\n",
      "length of actions is  115\n",
      "8.60642000926012\n",
      "length of actions is  136\n",
      "272.1098514770555\n",
      "length of actions is  195\n",
      "252.42788029335068\n",
      "length of actions is  175\n",
      "258.6126859719983\n",
      "length of actions is  193\n",
      "Your final reward is : 163.13\n",
      "torch.from_numpy(rewards) looks like  torch.Size([857])\n",
      "20.923324102031515\n",
      "length of actions is  121\n",
      "24.21153526792466\n",
      "length of actions is  122\n",
      "32.996688458705705\n",
      "length of actions is  96\n",
      "50.705719114297125\n",
      "length of actions is  102\n",
      "0.9063945983184567\n",
      "length of actions is  118\n",
      "Your final reward is : 25.95\n",
      "torch.from_numpy(rewards) looks like  torch.Size([927])\n",
      "16.53321524457317\n",
      "length of actions is  114\n",
      "0.8488776694849065\n",
      "length of actions is  154\n",
      "37.46300371484298\n",
      "length of actions is  137\n",
      "252.46499194779625\n",
      "length of actions is  200\n",
      "46.25523536453542\n",
      "length of actions is  121\n",
      "Your final reward is : 70.71\n",
      "torch.from_numpy(rewards) looks like  torch.Size([653])\n",
      "16.160333161281685\n",
      "length of actions is  120\n",
      "150.2675428948667\n",
      "length of actions is  1000\n",
      "270.42761368580926\n",
      "length of actions is  904\n",
      "56.175586728010956\n",
      "length of actions is  148\n",
      "18.742398557175292\n",
      "length of actions is  118\n",
      "Your final reward is : 102.35\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1126])\n",
      "24.646543139289903\n",
      "length of actions is  119\n",
      "278.3092870044363\n",
      "length of actions is  221\n",
      "-11.068024584749566\n",
      "length of actions is  166\n",
      "48.96641366618698\n",
      "length of actions is  143\n",
      "296.2356760395711\n",
      "length of actions is  230\n",
      "Your final reward is : 127.42\n",
      "torch.from_numpy(rewards) looks like  torch.Size([552])\n",
      "15.93853042398122\n",
      "length of actions is  124\n",
      "148.94166309351826\n",
      "length of actions is  1000\n",
      "150.12940343960952\n",
      "length of actions is  1000\n",
      "231.8878552116308\n",
      "length of actions is  296\n",
      "118.98552633017354\n",
      "length of actions is  1000\n",
      "Your final reward is : 133.18\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2078])\n",
      "26.47941639800429\n",
      "length of actions is  123\n",
      "235.1939825231558\n",
      "length of actions is  235\n",
      "57.207685494310596\n",
      "length of actions is  149\n",
      "277.22634251130376\n",
      "length of actions is  209\n",
      "278.0296515156027\n",
      "length of actions is  166\n",
      "Your final reward is : 174.83\n",
      "torch.from_numpy(rewards) looks like  torch.Size([583])\n",
      "32.80240782429823\n",
      "length of actions is  121\n",
      "11.988540564391883\n",
      "length of actions is  132\n",
      "250.0477974709149\n",
      "length of actions is  186\n",
      "162.16518295589822\n",
      "length of actions is  997\n",
      "43.069701251418536\n",
      "length of actions is  111\n",
      "Your final reward is : 100.01\n",
      "torch.from_numpy(rewards) looks like  torch.Size([986])\n",
      "18.52194241131967\n",
      "length of actions is  125\n",
      "246.23562242910575\n",
      "length of actions is  159\n",
      "282.89595664010903\n",
      "length of actions is  165\n",
      "17.940662486315546\n",
      "length of actions is  127\n",
      "60.31159373462759\n",
      "length of actions is  81\n",
      "Your final reward is : 125.18\n",
      "torch.from_numpy(rewards) looks like  torch.Size([822])\n",
      "26.513524886726245\n",
      "length of actions is  123\n",
      "226.26413832418132\n",
      "length of actions is  208\n",
      "177.5634019186847\n",
      "length of actions is  1000\n",
      "35.01883265544075\n",
      "length of actions is  110\n",
      "-13.706737388547964\n",
      "length of actions is  142\n",
      "Your final reward is : 90.33\n",
      "torch.from_numpy(rewards) looks like  torch.Size([857])\n",
      "34.33305328223486\n",
      "length of actions is  136\n",
      "14.88639181973673\n",
      "length of actions is  133\n",
      "295.9356081950332\n",
      "length of actions is  199\n",
      "-6.567525419996215\n",
      "length of actions is  119\n",
      "279.2388307910908\n",
      "length of actions is  189\n",
      "Your final reward is : 123.57\n",
      "torch.from_numpy(rewards) looks like  torch.Size([737])\n",
      "267.9917147582637\n",
      "length of actions is  267\n",
      "269.67611081070027\n",
      "length of actions is  190\n",
      "128.82762389618446\n",
      "length of actions is  1000\n",
      "276.291040198112\n",
      "length of actions is  203\n",
      "243.77370713178163\n",
      "length of actions is  214\n",
      "Your final reward is : 237.31\n",
      "torch.from_numpy(rewards) looks like  torch.Size([835])\n",
      "263.12204899586527\n",
      "length of actions is  506\n",
      "265.222028259936\n",
      "length of actions is  200\n",
      "269.26255716893064\n",
      "length of actions is  237\n",
      "282.65472315260877\n",
      "length of actions is  357\n",
      "13.656256756083295\n",
      "length of actions is  117\n",
      "Your final reward is : 218.78\n",
      "torch.from_numpy(rewards) looks like  torch.Size([988])\n",
      "267.6885036858149\n",
      "length of actions is  342\n",
      "167.65084155962995\n",
      "length of actions is  479\n",
      "251.05108141125143\n",
      "length of actions is  194\n",
      "299.3515274657269\n",
      "length of actions is  145\n",
      "13.70392465565935\n",
      "length of actions is  139\n",
      "Your final reward is : 199.89\n",
      "torch.from_numpy(rewards) looks like  torch.Size([817])\n",
      "29.82297790804205\n",
      "length of actions is  120\n",
      "265.47081932910663\n",
      "length of actions is  163\n",
      "285.69223112424777\n",
      "length of actions is  207\n",
      "264.71358617335795\n",
      "length of actions is  175\n",
      "45.41909593539481\n",
      "length of actions is  97\n",
      "Your final reward is : 178.22\n",
      "torch.from_numpy(rewards) looks like  torch.Size([734])\n",
      "262.27313344207386\n",
      "length of actions is  204\n",
      "271.49355175540677\n",
      "length of actions is  176\n",
      "69.06984361313346\n",
      "length of actions is  138\n",
      "60.325678293893446\n",
      "length of actions is  142\n",
      "299.621964450837\n",
      "length of actions is  205\n",
      "Your final reward is : 192.56\n",
      "torch.from_numpy(rewards) looks like  torch.Size([986])\n",
      "271.0417499583806\n",
      "length of actions is  195\n",
      "243.36883027669572\n",
      "length of actions is  213\n",
      "-20.90932772870123\n",
      "length of actions is  141\n",
      "243.59645932198777\n",
      "length of actions is  234\n",
      "289.31362458319995\n",
      "length of actions is  221\n",
      "Your final reward is : 205.28\n",
      "torch.from_numpy(rewards) looks like  torch.Size([794])\n",
      "252.22948160588598\n",
      "length of actions is  495\n",
      "249.20727451546173\n",
      "length of actions is  166\n",
      "257.5817004506822\n",
      "length of actions is  580\n",
      "249.2908397799228\n",
      "length of actions is  322\n",
      "259.3676739866511\n",
      "length of actions is  193\n",
      "Your final reward is : 253.54\n",
      "torch.from_numpy(rewards) looks like  torch.Size([667])\n",
      "248.02354675461282\n",
      "length of actions is  634\n",
      "258.09658736145377\n",
      "length of actions is  189\n",
      "304.22211076416465\n",
      "length of actions is  221\n",
      "12.300532935338467\n",
      "length of actions is  127\n",
      "39.90129457032219\n",
      "length of actions is  89\n",
      "Your final reward is : 172.51\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2001])\n",
      "136.74872171161726\n",
      "length of actions is  1000\n",
      "77.18802217237558\n",
      "length of actions is  138\n",
      "277.2055426298357\n",
      "length of actions is  227\n",
      "34.24598256745938\n",
      "length of actions is  115\n",
      "49.65635432756699\n",
      "length of actions is  94\n",
      "Your final reward is : 115.01\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1224])\n",
      "139.08276521004197\n",
      "length of actions is  1000\n",
      "172.90864817027816\n",
      "length of actions is  1000\n",
      "152.6506405768014\n",
      "length of actions is  1000\n",
      "30.37769737128042\n",
      "length of actions is  126\n",
      "126.25971692767071\n",
      "length of actions is  1000\n",
      "Your final reward is : 124.26\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1427])\n",
      "271.1463298819317\n",
      "length of actions is  252\n",
      "275.33289285838055\n",
      "length of actions is  168\n",
      "26.98410933568242\n",
      "length of actions is  113\n",
      "85.61127189957497\n",
      "length of actions is  96\n",
      "267.73546581276725\n",
      "length of actions is  183\n",
      "Your final reward is : 185.36\n",
      "torch.from_numpy(rewards) looks like  torch.Size([733])\n",
      "271.98810439018723\n",
      "length of actions is  206\n",
      "36.99371554512706\n",
      "length of actions is  128\n",
      "182.9956441911316\n",
      "length of actions is  316\n",
      "35.78142977567123\n",
      "length of actions is  126\n",
      "263.6046826988574\n",
      "length of actions is  170\n",
      "Your final reward is : 158.27\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1216])\n",
      "149.93854261867753\n",
      "length of actions is  1000\n",
      "155.03582434741185\n",
      "length of actions is  1000\n",
      "274.31260431240884\n",
      "length of actions is  201\n",
      "275.2503538867229\n",
      "length of actions is  234\n",
      "53.31798159774445\n",
      "length of actions is  104\n",
      "Your final reward is : 181.57\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1158])\n",
      "268.57820503270636\n",
      "length of actions is  183\n",
      "274.7883646803497\n",
      "length of actions is  221\n",
      "62.43075333456892\n",
      "length of actions is  137\n",
      "283.76616105648446\n",
      "length of actions is  229\n",
      "242.44680407095314\n",
      "length of actions is  189\n",
      "Your final reward is : 226.40\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1675])\n",
      "271.4234898681831\n",
      "length of actions is  240\n",
      "123.48463179849503\n",
      "length of actions is  1000\n",
      "285.663233868058\n",
      "length of actions is  205\n",
      "287.39624390349445\n",
      "length of actions is  220\n",
      "254.38261038053017\n",
      "length of actions is  153\n",
      "Your final reward is : 244.47\n",
      "torch.from_numpy(rewards) looks like  torch.Size([986])\n",
      "140.7293474378699\n",
      "length of actions is  1000\n",
      "304.6265183273196\n",
      "length of actions is  231\n",
      "9.405390014160417\n",
      "length of actions is  114\n",
      "40.78984164909764\n",
      "length of actions is  88\n",
      "11.529969102753142\n",
      "length of actions is  104\n",
      "Your final reward is : 101.42\n",
      "torch.from_numpy(rewards) looks like  torch.Size([944])\n",
      "37.9809880595777\n",
      "length of actions is  105\n",
      "54.918576041838406\n",
      "length of actions is  88\n",
      "254.67219147203744\n",
      "length of actions is  212\n",
      "247.9768927502398\n",
      "length of actions is  751\n",
      "5.741926961210268\n",
      "length of actions is  122\n",
      "Your final reward is : 120.26\n",
      "torch.from_numpy(rewards) looks like  torch.Size([569])\n",
      "29.720430299667697\n",
      "length of actions is  106\n",
      "265.32637659382385\n",
      "length of actions is  177\n",
      "281.29707921842476\n",
      "length of actions is  214\n",
      "-11.459488662717547\n",
      "length of actions is  108\n",
      "252.41952572613786\n",
      "length of actions is  183\n",
      "Your final reward is : 163.46\n",
      "torch.from_numpy(rewards) looks like  torch.Size([594])\n",
      "26.968242697373284\n",
      "length of actions is  112\n",
      "29.369221885014213\n",
      "length of actions is  88\n",
      "53.28306918565647\n",
      "length of actions is  89\n",
      "83.00413997036296\n",
      "length of actions is  196\n",
      "156.13580842468195\n",
      "length of actions is  1000\n",
      "Your final reward is : 69.75\n",
      "torch.from_numpy(rewards) looks like  torch.Size([729])\n",
      "30.212863220216377\n",
      "length of actions is  107\n",
      "34.26849811756384\n",
      "length of actions is  122\n",
      "-2.2433611956133177\n",
      "length of actions is  93\n",
      "32.19830183913922\n",
      "length of actions is  135\n",
      "299.6284299113036\n",
      "length of actions is  219\n",
      "Your final reward is : 78.81\n",
      "torch.from_numpy(rewards) looks like  torch.Size([760])\n",
      "31.551515972541864\n",
      "length of actions is  108\n",
      "231.7780083685649\n",
      "length of actions is  141\n",
      "44.26826471787396\n",
      "length of actions is  117\n",
      "18.130188279505973\n",
      "length of actions is  110\n",
      "239.396607647945\n",
      "length of actions is  180\n",
      "Your final reward is : 113.02\n",
      "torch.from_numpy(rewards) looks like  torch.Size([986])\n",
      "38.823467269364755\n",
      "length of actions is  105\n",
      "47.87667170809169\n",
      "length of actions is  85\n",
      "38.300351111914836\n",
      "length of actions is  111\n",
      "58.658517014947705\n",
      "length of actions is  96\n",
      "254.18678300101482\n",
      "length of actions is  596\n",
      "Your final reward is : 87.57\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1075])\n",
      "25.331979766883578\n",
      "length of actions is  98\n",
      "58.31511221778206\n",
      "length of actions is  152\n",
      "16.54318496200301\n",
      "length of actions is  100\n",
      "1.092677728900199\n",
      "length of actions is  151\n",
      "19.3029722164641\n",
      "length of actions is  161\n",
      "Your final reward is : 24.12\n",
      "torch.from_numpy(rewards) looks like  torch.Size([550])\n",
      "11.724162441100717\n",
      "length of actions is  98\n",
      "38.98295440649838\n",
      "length of actions is  147\n",
      "41.58142254585644\n",
      "length of actions is  125\n",
      "55.03933573499367\n",
      "length of actions is  142\n",
      "-26.604564896373546\n",
      "length of actions is  115\n",
      "Your final reward is : 24.14\n",
      "torch.from_numpy(rewards) looks like  torch.Size([541])\n",
      "21.13043587851253\n",
      "length of actions is  101\n",
      "31.307958326884005\n",
      "length of actions is  80\n",
      "-3.452159550610034\n",
      "length of actions is  103\n",
      "143.15393104654402\n",
      "length of actions is  1000\n",
      "6.499934141884097\n",
      "length of actions is  109\n",
      "Your final reward is : 39.73\n",
      "torch.from_numpy(rewards) looks like  torch.Size([609])\n",
      "32.21568672373937\n",
      "length of actions is  105\n",
      "51.736714026788206\n",
      "length of actions is  88\n",
      "261.8894674524661\n",
      "length of actions is  211\n",
      "-5.736377599038988\n",
      "length of actions is  134\n",
      "247.57661575298962\n",
      "length of actions is  225\n",
      "Your final reward is : 117.54\n",
      "torch.from_numpy(rewards) looks like  torch.Size([743])\n",
      "26.054387254856607\n",
      "length of actions is  99\n",
      "299.52220296755934\n",
      "length of actions is  257\n",
      "47.31060634901294\n",
      "length of actions is  137\n",
      "41.20628115842868\n",
      "length of actions is  152\n",
      "289.76767176668443\n",
      "length of actions is  232\n",
      "Your final reward is : 140.77\n",
      "torch.from_numpy(rewards) looks like  torch.Size([517])\n",
      "22.31844165750975\n",
      "length of actions is  102\n",
      "255.32191318972988\n",
      "length of actions is  153\n",
      "-2.1871093840429126\n",
      "length of actions is  137\n",
      "-2.9990714349355443\n",
      "length of actions is  99\n",
      "17.70306873662433\n",
      "length of actions is  107\n",
      "Your final reward is : 58.03\n",
      "torch.from_numpy(rewards) looks like  torch.Size([534])\n",
      "15.99040086645158\n",
      "length of actions is  98\n",
      "47.54382704595824\n",
      "length of actions is  151\n",
      "42.62716358459005\n",
      "length of actions is  116\n",
      "27.078786735965394\n",
      "length of actions is  96\n",
      "34.691183159281564\n",
      "length of actions is  88\n",
      "Your final reward is : 33.59\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1032])\n",
      "20.99613840379169\n",
      "length of actions is  99\n",
      "60.07860278484466\n",
      "length of actions is  169\n",
      "150.95707467853404\n",
      "length of actions is  1000\n",
      "222.4258481465913\n",
      "length of actions is  295\n",
      "25.24074638288431\n",
      "length of actions is  185\n",
      "Your final reward is : 95.94\n",
      "torch.from_numpy(rewards) looks like  torch.Size([608])\n",
      "35.51614611204235\n",
      "length of actions is  103\n",
      "34.17340184761912\n",
      "length of actions is  103\n",
      "49.030224533285576\n",
      "length of actions is  122\n",
      "176.96014159237137\n",
      "length of actions is  1000\n",
      "260.020564215915\n",
      "length of actions is  139\n",
      "Your final reward is : 111.14\n",
      "torch.from_numpy(rewards) looks like  torch.Size([743])\n",
      "19.348742109437197\n",
      "length of actions is  96\n",
      "255.30269902201678\n",
      "length of actions is  613\n",
      "9.980213796255455\n",
      "length of actions is  91\n",
      "33.95398714779748\n",
      "length of actions is  97\n",
      "14.101355135057076\n",
      "length of actions is  105\n",
      "Your final reward is : 66.54\n",
      "torch.from_numpy(rewards) looks like  torch.Size([494])\n",
      "21.994116171394396\n",
      "length of actions is  98\n",
      "57.48297767243585\n",
      "length of actions is  160\n",
      "-8.630758863230213\n",
      "length of actions is  137\n",
      "24.834574714629284\n",
      "length of actions is  107\n",
      "39.242013941247166\n",
      "length of actions is  148\n",
      "Your final reward is : 26.98\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2357])\n",
      "23.435541803280742\n",
      "length of actions is  93\n",
      "37.740945134397634\n",
      "length of actions is  149\n",
      "6.999988515665251\n",
      "length of actions is  102\n",
      "150.94434093910255\n",
      "length of actions is  1000\n",
      "7.708942979722494\n",
      "length of actions is  102\n",
      "Your final reward is : 45.37\n",
      "torch.from_numpy(rewards) looks like  torch.Size([685])\n",
      "24.011950718836218\n",
      "length of actions is  93\n",
      "46.77684234737586\n",
      "length of actions is  148\n",
      "-6.1200846996598415\n",
      "length of actions is  88\n",
      "-2.7796354205530918\n",
      "length of actions is  93\n",
      "-26.436743930979006\n",
      "length of actions is  102\n",
      "Your final reward is : 7.09\n",
      "torch.from_numpy(rewards) looks like  torch.Size([439])\n",
      "20.61914576558931\n",
      "length of actions is  94\n",
      "-22.535090356029187\n",
      "length of actions is  87\n",
      "-16.985914105704367\n",
      "length of actions is  93\n",
      "74.35087171635752\n",
      "length of actions is  148\n",
      "-23.654438127972384\n",
      "length of actions is  107\n",
      "Your final reward is : 6.36\n",
      "torch.from_numpy(rewards) looks like  torch.Size([577])\n",
      "-0.8342137678056503\n",
      "length of actions is  90\n",
      "42.81250420231129\n",
      "length of actions is  139\n",
      "4.4006954620816\n",
      "length of actions is  93\n",
      "-9.078201647565749\n",
      "length of actions is  112\n",
      "33.91982881334067\n",
      "length of actions is  85\n",
      "Your final reward is : 14.24\n",
      "torch.from_numpy(rewards) looks like  torch.Size([588])\n",
      "-2.9367376975194475\n",
      "length of actions is  93\n",
      "139.47613955699987\n",
      "length of actions is  1000\n",
      "8.58788248655938\n",
      "length of actions is  87\n",
      "152.6976398012389\n",
      "length of actions is  1000\n",
      "-22.776591045898442\n",
      "length of actions is  91\n",
      "Your final reward is : 55.01\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1463])\n",
      "11.998878733704103\n",
      "length of actions is  98\n",
      "36.36421215641582\n",
      "length of actions is  148\n",
      "42.063814738155486\n",
      "length of actions is  136\n",
      "-1.168153542559324\n",
      "length of actions is  117\n",
      "12.836602925517042\n",
      "length of actions is  150\n",
      "Your final reward is : 20.42\n",
      "torch.from_numpy(rewards) looks like  torch.Size([605])\n",
      "8.810270498090077\n",
      "length of actions is  98\n",
      "57.36472444459869\n",
      "length of actions is  148\n",
      "42.879794506537564\n",
      "length of actions is  134\n",
      "26.736626436025773\n",
      "length of actions is  84\n",
      "37.15218607954594\n",
      "length of actions is  82\n",
      "Your final reward is : 34.59\n",
      "torch.from_numpy(rewards) looks like  torch.Size([807])\n",
      "6.544174963036994\n",
      "length of actions is  98\n",
      "277.3110582994558\n",
      "length of actions is  245\n",
      "6.844022416263854\n",
      "length of actions is  80\n",
      "294.0031874706571\n",
      "length of actions is  206\n",
      "242.5833719978711\n",
      "length of actions is  216\n",
      "Your final reward is : 165.46\n",
      "torch.from_numpy(rewards) looks like  torch.Size([518])\n",
      "-5.91629963251583\n",
      "length of actions is  95\n",
      "-38.733013515882476\n",
      "length of actions is  113\n",
      "227.75890365556023\n",
      "length of actions is  201\n",
      "15.923456074678867\n",
      "length of actions is  107\n",
      "-21.728702367534325\n",
      "length of actions is  82\n",
      "Your final reward is : 35.46\n",
      "torch.from_numpy(rewards) looks like  torch.Size([556])\n",
      "15.800160985902536\n",
      "length of actions is  97\n",
      "21.066381502327204\n",
      "length of actions is  86\n",
      "-11.747755516191091\n",
      "length of actions is  112\n",
      "251.84722789289106\n",
      "length of actions is  180\n",
      "39.192738150869104\n",
      "length of actions is  144\n",
      "Your final reward is : 63.23\n",
      "torch.from_numpy(rewards) looks like  torch.Size([656])\n",
      "-6.378148266616023\n",
      "length of actions is  92\n",
      "-47.86006035996681\n",
      "length of actions is  94\n",
      "48.13987080248933\n",
      "length of actions is  84\n",
      "16.342043029743735\n",
      "length of actions is  79\n",
      "97.93699069039971\n",
      "length of actions is  159\n",
      "Your final reward is : 21.64\n",
      "torch.from_numpy(rewards) looks like  torch.Size([686])\n",
      "-7.949425519803427\n",
      "length of actions is  100\n",
      "-14.597867937683702\n",
      "length of actions is  88\n",
      "25.35022191779825\n",
      "length of actions is  115\n",
      "114.47879370590061\n",
      "length of actions is  1000\n",
      "-51.919305959062754\n",
      "length of actions is  100\n",
      "Your final reward is : 13.07\n",
      "torch.from_numpy(rewards) looks like  torch.Size([711])\n",
      "-12.79761864870018\n",
      "length of actions is  94\n",
      "-29.212610242872174\n",
      "length of actions is  93\n",
      "-27.847410197007193\n",
      "length of actions is  158\n",
      "9.64620267427776\n",
      "length of actions is  160\n",
      "-37.13700478500195\n",
      "length of actions is  101\n",
      "Your final reward is : -19.47\n",
      "torch.from_numpy(rewards) looks like  torch.Size([755])\n",
      "22.647123020030193\n",
      "length of actions is  97\n",
      "5.655901824081923\n",
      "length of actions is  81\n",
      "-14.410902254759222\n",
      "length of actions is  93\n",
      "10.180030328894887\n",
      "length of actions is  83\n",
      "19.523879601817782\n",
      "length of actions is  110\n",
      "Your final reward is : 8.72\n",
      "torch.from_numpy(rewards) looks like  torch.Size([586])\n",
      "-2.229593784861976\n",
      "length of actions is  95\n",
      "-46.82224319319673\n",
      "length of actions is  109\n",
      "35.98957858968373\n",
      "length of actions is  141\n",
      "109.92323482153041\n",
      "length of actions is  1000\n",
      "-34.353089110645755\n",
      "length of actions is  101\n",
      "Your final reward is : 12.50\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1466])\n",
      "6.193188388763673\n",
      "length of actions is  101\n",
      "35.18524572719957\n",
      "length of actions is  151\n",
      "224.5910495974417\n",
      "length of actions is  167\n",
      "-40.66298541090113\n",
      "length of actions is  106\n",
      "27.043545243704614\n",
      "length of actions is  78\n",
      "Your final reward is : 50.47\n",
      "torch.from_numpy(rewards) looks like  torch.Size([452])\n",
      "2.715138433841119\n",
      "length of actions is  95\n",
      "-35.587829702135465\n",
      "length of actions is  108\n",
      "-43.805973777793895\n",
      "length of actions is  113\n",
      "42.09087575312708\n",
      "length of actions is  151\n",
      "-25.412359122954086\n",
      "length of actions is  87\n",
      "Your final reward is : -12.00\n",
      "torch.from_numpy(rewards) looks like  torch.Size([494])\n",
      "-13.498676992882892\n",
      "length of actions is  99\n",
      "38.65614980155047\n",
      "length of actions is  167\n",
      "217.7079373458704\n",
      "length of actions is  223\n",
      "-7.657511279425989\n",
      "length of actions is  112\n",
      "30.27380461707628\n",
      "length of actions is  154\n",
      "Your final reward is : 53.10\n",
      "torch.from_numpy(rewards) looks like  torch.Size([613])\n",
      "2.243604765872348\n",
      "length of actions is  97\n",
      "-15.444230307557888\n",
      "length of actions is  80\n",
      "-22.45545353686444\n",
      "length of actions is  118\n",
      "245.47129998847353\n",
      "length of actions is  143\n",
      "3.527501896789218\n",
      "length of actions is  107\n",
      "Your final reward is : 42.67\n",
      "torch.from_numpy(rewards) looks like  torch.Size([710])\n",
      "2.9261829496304586\n",
      "length of actions is  99\n",
      "22.77171657717892\n",
      "length of actions is  151\n",
      "148.94768496187802\n",
      "length of actions is  1000\n",
      "-1.983658406550603\n",
      "length of actions is  165\n",
      "22.037225369420938\n",
      "length of actions is  155\n",
      "Your final reward is : 38.94\n",
      "torch.from_numpy(rewards) looks like  torch.Size([573])\n",
      "-4.362773359270918\n",
      "length of actions is  99\n",
      "24.23860131762231\n",
      "length of actions is  157\n",
      "-3.587072994599737\n",
      "length of actions is  95\n",
      "-1.3310968826198462\n",
      "length of actions is  107\n",
      "-6.667889784061941\n",
      "length of actions is  111\n",
      "Your final reward is : 1.66\n",
      "torch.from_numpy(rewards) looks like  torch.Size([792])\n",
      "16.83878441656286\n",
      "length of actions is  106\n",
      "251.8314952540943\n",
      "length of actions is  265\n",
      "0.1737884510038441\n",
      "length of actions is  112\n",
      "69.09835015618663\n",
      "length of actions is  149\n",
      "258.5480388887969\n",
      "length of actions is  173\n",
      "Your final reward is : 119.30\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1095])\n",
      "17.638742087249838\n",
      "length of actions is  104\n",
      "1.2774953361498547\n",
      "length of actions is  95\n",
      "23.33660363153851\n",
      "length of actions is  119\n",
      "36.47682460942684\n",
      "length of actions is  106\n",
      "27.329465757588935\n",
      "length of actions is  92\n",
      "Your final reward is : 21.21\n",
      "torch.from_numpy(rewards) looks like  torch.Size([723])\n",
      "13.054735943839745\n",
      "length of actions is  103\n",
      "19.900183782988307\n",
      "length of actions is  103\n",
      "32.48452638749896\n",
      "length of actions is  123\n",
      "219.37879804349691\n",
      "length of actions is  187\n",
      "1.5676228622610466\n",
      "length of actions is  94\n",
      "Your final reward is : 57.28\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1611])\n",
      "18.390408038400764\n",
      "length of actions is  101\n",
      "15.22583122513528\n",
      "length of actions is  147\n",
      "211.42386194770626\n",
      "length of actions is  832\n",
      "29.25314258051816\n",
      "length of actions is  98\n",
      "-26.976909008724434\n",
      "length of actions is  96\n",
      "Your final reward is : 49.46\n",
      "torch.from_numpy(rewards) looks like  torch.Size([805])\n",
      "25.46717890191114\n",
      "length of actions is  104\n",
      "23.02868265115599\n",
      "length of actions is  95\n",
      "30.29051970717694\n",
      "length of actions is  121\n",
      "24.988163088726495\n",
      "length of actions is  91\n",
      "-28.727786005690845\n",
      "length of actions is  109\n",
      "Your final reward is : 15.01\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1471])\n",
      "29.601310606464693\n",
      "length of actions is  111\n",
      "9.458896220442753\n",
      "length of actions is  130\n",
      "112.7749456308534\n",
      "length of actions is  1000\n",
      "246.54375290479868\n",
      "length of actions is  238\n",
      "-12.744112741422512\n",
      "length of actions is  150\n",
      "Your final reward is : 77.13\n",
      "torch.from_numpy(rewards) looks like  torch.Size([584])\n",
      "26.106379578234254\n",
      "length of actions is  109\n",
      "63.70253911666612\n",
      "length of actions is  164\n",
      "43.96802606651272\n",
      "length of actions is  128\n",
      "25.30246036964651\n",
      "length of actions is  131\n",
      "46.07858208096272\n",
      "length of actions is  104\n",
      "Your final reward is : 41.03\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1002])\n",
      "41.198239118733795\n",
      "length of actions is  105\n",
      "46.89773426940522\n",
      "length of actions is  92\n",
      "20.457200036908944\n",
      "length of actions is  94\n",
      "68.27374582906813\n",
      "length of actions is  145\n",
      "9.312563467351168\n",
      "length of actions is  115\n",
      "Your final reward is : 37.23\n",
      "torch.from_numpy(rewards) looks like  torch.Size([736])\n",
      "26.424971083460818\n",
      "length of actions is  109\n",
      "58.35208809481861\n",
      "length of actions is  157\n",
      "31.37981755779711\n",
      "length of actions is  144\n",
      "256.0353058720141\n",
      "length of actions is  216\n",
      "4.5496737964922715\n",
      "length of actions is  169\n",
      "Your final reward is : 75.35\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1432])\n",
      "28.68272743998915\n",
      "length of actions is  108\n",
      "248.49951076026332\n",
      "length of actions is  202\n",
      "50.045648361059705\n",
      "length of actions is  136\n",
      "247.40432574760106\n",
      "length of actions is  201\n",
      "262.6853428340544\n",
      "length of actions is  205\n",
      "Your final reward is : 167.46\n",
      "torch.from_numpy(rewards) looks like  torch.Size([622])\n",
      "25.74123387906174\n",
      "length of actions is  109\n",
      "61.279932902274936\n",
      "length of actions is  161\n",
      "54.49093706540785\n",
      "length of actions is  146\n",
      "38.65427217762826\n",
      "length of actions is  108\n",
      "302.42220223127816\n",
      "length of actions is  248\n",
      "Your final reward is : 96.52\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1347])\n",
      "34.35659663516165\n",
      "length of actions is  117\n",
      "44.89070877246019\n",
      "length of actions is  150\n",
      "238.77066800102406\n",
      "length of actions is  233\n",
      "62.93717587526848\n",
      "length of actions is  114\n",
      "297.8223262251965\n",
      "length of actions is  930\n",
      "Your final reward is : 135.76\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1517])\n",
      "27.667323888323637\n",
      "length of actions is  121\n",
      "47.069014189136226\n",
      "length of actions is  127\n",
      "256.38131775786434\n",
      "length of actions is  249\n",
      "158.34801655476895\n",
      "length of actions is  1000\n",
      "146.39298883237743\n",
      "length of actions is  1000\n",
      "Your final reward is : 127.17\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1430])\n",
      "163.16286686951693\n",
      "length of actions is  1000\n",
      "184.52430889078755\n",
      "length of actions is  1000\n",
      "141.85028952785632\n",
      "length of actions is  1000\n",
      "40.9355205957994\n",
      "length of actions is  128\n",
      "55.69046993063455\n",
      "length of actions is  113\n",
      "Your final reward is : 117.23\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1430])\n",
      "160.41661133063585\n",
      "length of actions is  1000\n",
      "298.7619591065257\n",
      "length of actions is  208\n",
      "270.2856915298694\n",
      "length of actions is  988\n",
      "67.01007112993958\n",
      "length of actions is  164\n",
      "253.48827517265917\n",
      "length of actions is  227\n",
      "Your final reward is : 209.99\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1315])\n",
      "275.28120180413293\n",
      "length of actions is  186\n",
      "250.48402018452865\n",
      "length of actions is  233\n",
      "81.68371082830876\n",
      "length of actions is  161\n",
      "248.42775915158583\n",
      "length of actions is  225\n",
      "254.67341086669055\n",
      "length of actions is  226\n",
      "Your final reward is : 222.11\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1497])\n",
      "267.17671437135834\n",
      "length of actions is  230\n",
      "262.50978380241094\n",
      "length of actions is  209\n",
      "250.08188326266858\n",
      "length of actions is  235\n",
      "291.0338832310791\n",
      "length of actions is  223\n",
      "260.4365269632748\n",
      "length of actions is  228\n",
      "Your final reward is : 266.25\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1777])\n",
      "268.4339075087146\n",
      "length of actions is  198\n",
      "255.41380048940002\n",
      "length of actions is  257\n",
      "35.41156130333417\n",
      "length of actions is  142\n",
      "223.7124394450011\n",
      "length of actions is  241\n",
      "248.39440840157155\n",
      "length of actions is  227\n",
      "Your final reward is : 206.27\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1977])\n",
      "266.65405240645623\n",
      "length of actions is  236\n",
      "292.7466612843122\n",
      "length of actions is  207\n",
      "249.82198550766574\n",
      "length of actions is  235\n",
      "255.27510668912245\n",
      "length of actions is  247\n",
      "268.75018532208003\n",
      "length of actions is  224\n",
      "Your final reward is : 266.65\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3748])\n",
      "143.35583501829282\n",
      "length of actions is  1000\n",
      "187.26616100219093\n",
      "length of actions is  1000\n",
      "159.00790587851864\n",
      "length of actions is  1000\n",
      "97.82908871040696\n",
      "length of actions is  1000\n",
      "112.10262110907749\n",
      "length of actions is  1000\n",
      "Your final reward is : 139.91\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3092])\n",
      "200.74442319601133\n",
      "length of actions is  463\n",
      "265.83905236863814\n",
      "length of actions is  316\n",
      "157.55042927985684\n",
      "length of actions is  797\n",
      "276.83126094016967\n",
      "length of actions is  253\n",
      "239.99476416058508\n",
      "length of actions is  395\n",
      "Your final reward is : 228.19\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3439])\n",
      "190.88645702697636\n",
      "length of actions is  529\n",
      "99.32790973222981\n",
      "length of actions is  1000\n",
      "49.71497732227953\n",
      "length of actions is  1000\n",
      "132.88939019243267\n",
      "length of actions is  1000\n",
      "133.8775583456433\n",
      "length of actions is  1000\n",
      "Your final reward is : 121.34\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2535])\n",
      "57.7901724021775\n",
      "length of actions is  1000\n",
      "181.43391890780342\n",
      "length of actions is  1000\n",
      "18.937487023593487\n",
      "length of actions is  1000\n",
      "39.50598362308005\n",
      "length of actions is  1000\n",
      "-61.95543192892512\n",
      "length of actions is  1000\n",
      "Your final reward is : 47.14\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3422])\n",
      "-38.04770126301585\n",
      "length of actions is  1000\n",
      "51.54499298174517\n",
      "length of actions is  123\n",
      "191.72381117414955\n",
      "length of actions is  1000\n",
      "-16.196992685122456\n",
      "length of actions is  1000\n",
      "8.236559898261081\n",
      "length of actions is  1000\n",
      "Your final reward is : 39.45\n",
      "torch.from_numpy(rewards) looks like  torch.Size([5000])\n",
      "-30.202867380623882\n",
      "length of actions is  1000\n",
      "292.46272130619803\n",
      "length of actions is  218\n",
      "-8.35708361089909\n",
      "length of actions is  1000\n",
      "-32.830198627510114\n",
      "length of actions is  1000\n",
      "20.600107286833776\n",
      "length of actions is  1000\n",
      "Your final reward is : 48.33\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3578])\n",
      "-19.130523358279262\n",
      "length of actions is  1000\n",
      "57.61275708035092\n",
      "length of actions is  127\n",
      "-14.160942609771237\n",
      "length of actions is  1000\n",
      "295.4906343026415\n",
      "length of actions is  276\n",
      "-33.6722028948118\n",
      "length of actions is  1000\n",
      "Your final reward is : 57.23\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3656])\n",
      "-26.387516091728124\n",
      "length of actions is  1000\n",
      "298.40314432171965\n",
      "length of actions is  203\n",
      "247.05089249824664\n",
      "length of actions is  236\n",
      "274.3322166056026\n",
      "length of actions is  221\n",
      "231.77748230753693\n",
      "length of actions is  563\n",
      "Your final reward is : 205.04\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4095])\n",
      "261.84438990795945\n",
      "length of actions is  238\n",
      "-45.59649385581813\n",
      "length of actions is  1000\n",
      "67.04827777992503\n",
      "length of actions is  197\n",
      "-42.68887437353451\n",
      "length of actions is  1000\n",
      "301.64251523090945\n",
      "length of actions is  222\n",
      "Your final reward is : 108.45\n",
      "torch.from_numpy(rewards) looks like  torch.Size([5000])\n",
      "262.90192607856466\n",
      "length of actions is  240\n",
      "-48.75483080091034\n",
      "length of actions is  1000\n",
      "-5.358453369025268\n",
      "length of actions is  1000\n",
      "151.67908699581895\n",
      "length of actions is  1000\n",
      "-21.81150956655095\n",
      "length of actions is  1000\n",
      "Your final reward is : 67.73\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3497])\n",
      "234.76407708854921\n",
      "length of actions is  966\n",
      "-17.858864152534398\n",
      "length of actions is  1000\n",
      "265.2128802485162\n",
      "length of actions is  227\n",
      "119.82603472981125\n",
      "length of actions is  1000\n",
      "287.1599690698542\n",
      "length of actions is  225\n",
      "Your final reward is : 177.82\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4219])\n",
      "227.83910595461975\n",
      "length of actions is  900\n",
      "67.00765195255974\n",
      "length of actions is  1000\n",
      "158.2297221730484\n",
      "length of actions is  1000\n",
      "30.4919532378828\n",
      "length of actions is  1000\n",
      "243.7704481176558\n",
      "length of actions is  384\n",
      "Your final reward is : 145.47\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3204])\n",
      "262.1137603030238\n",
      "length of actions is  261\n",
      "-51.04901570309201\n",
      "length of actions is  1000\n",
      "-50.90477418739635\n",
      "length of actions is  1000\n",
      "21.116950757395788\n",
      "length of actions is  1000\n",
      "71.19522003674356\n",
      "length of actions is  1000\n",
      "Your final reward is : 50.49\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4257])\n",
      "258.8485764446393\n",
      "length of actions is  258\n",
      "7.508248039517202\n",
      "length of actions is  1000\n",
      "130.81779478677404\n",
      "length of actions is  847\n",
      "158.0451625875043\n",
      "length of actions is  850\n",
      "135.17874075471582\n",
      "length of actions is  835\n",
      "Your final reward is : 138.08\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3497])\n",
      "267.708859630634\n",
      "length of actions is  238\n",
      "10.225442431465757\n",
      "length of actions is  1000\n",
      "69.51409259212934\n",
      "length of actions is  196\n",
      "67.8572622065156\n",
      "length of actions is  1000\n",
      "42.762313992551526\n",
      "length of actions is  1000\n",
      "Your final reward is : 91.61\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2275])\n",
      "270.29815182858925\n",
      "length of actions is  227\n",
      "201.9357928749895\n",
      "length of actions is  650\n",
      "308.05498200635947\n",
      "length of actions is  289\n",
      "209.95422551528128\n",
      "length of actions is  452\n",
      "194.1913570695541\n",
      "length of actions is  692\n",
      "Your final reward is : 236.89\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2275])\n",
      "270.81448779422954\n",
      "length of actions is  218\n",
      "193.81598464597687\n",
      "length of actions is  630\n",
      "171.3828557837678\n",
      "length of actions is  1000\n",
      "230.74811142574268\n",
      "length of actions is  485\n",
      "59.80593798052932\n",
      "length of actions is  1000\n",
      "Your final reward is : 185.31\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4368])\n",
      "271.0031907103869\n",
      "length of actions is  216\n",
      "167.39644425350738\n",
      "length of actions is  899\n",
      "42.31934368198074\n",
      "length of actions is  202\n",
      "260.12949581748626\n",
      "length of actions is  190\n",
      "238.22891016094152\n",
      "length of actions is  277\n",
      "Your final reward is : 195.82\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2314])\n",
      "157.54772148892388\n",
      "length of actions is  1000\n",
      "304.712520993048\n",
      "length of actions is  199\n",
      "212.35057205568714\n",
      "length of actions is  331\n",
      "272.81612285238816\n",
      "length of actions is  242\n",
      "68.36713546503597\n",
      "length of actions is  150\n",
      "Your final reward is : 203.16\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2273])\n",
      "271.32149386262444\n",
      "length of actions is  234\n",
      "205.3411709212896\n",
      "length of actions is  547\n",
      "296.4457451409321\n",
      "length of actions is  284\n",
      "211.1504159372947\n",
      "length of actions is  319\n",
      "286.1349402671708\n",
      "length of actions is  278\n",
      "Your final reward is : 254.08\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2208])\n",
      "271.96066493796616\n",
      "length of actions is  216\n",
      "224.50243644564836\n",
      "length of actions is  464\n",
      "132.37855285348277\n",
      "length of actions is  1000\n",
      "272.913421546203\n",
      "length of actions is  236\n",
      "96.31181909932835\n",
      "length of actions is  1000\n",
      "Your final reward is : 199.61\n",
      "torch.from_numpy(rewards) looks like  torch.Size([5000])\n",
      "274.5070098803374\n",
      "length of actions is  214\n",
      "94.63185124889571\n",
      "length of actions is  1000\n",
      "155.63990593333435\n",
      "length of actions is  1000\n",
      "265.8909118880151\n",
      "length of actions is  220\n",
      "138.57748697521708\n",
      "length of actions is  1000\n",
      "Your final reward is : 185.85\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1497])\n",
      "274.38291990564863\n",
      "length of actions is  206\n",
      "270.46799322621666\n",
      "length of actions is  248\n",
      "261.32552859889336\n",
      "length of actions is  202\n",
      "245.90092023491064\n",
      "length of actions is  400\n",
      "263.63183270795764\n",
      "length of actions is  270\n",
      "Your final reward is : 263.14\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1415])\n",
      "271.23745798919003\n",
      "length of actions is  214\n",
      "241.9256218584047\n",
      "length of actions is  402\n",
      "159.74429240006828\n",
      "length of actions is  1000\n",
      "272.80594438145005\n",
      "length of actions is  218\n",
      "262.6191359189171\n",
      "length of actions is  315\n",
      "Your final reward is : 241.67\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1617])\n",
      "272.49462697421075\n",
      "length of actions is  202\n",
      "124.76352931504879\n",
      "length of actions is  1000\n",
      "233.1179028241737\n",
      "length of actions is  408\n",
      "275.9980559299604\n",
      "length of actions is  174\n",
      "288.86775081426777\n",
      "length of actions is  284\n",
      "Your final reward is : 239.05\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1577])\n",
      "270.4554160262151\n",
      "length of actions is  204\n",
      "225.16672767993248\n",
      "length of actions is  459\n",
      "269.3134699432509\n",
      "length of actions is  203\n",
      "284.21054095186435\n",
      "length of actions is  207\n",
      "240.07529835008575\n",
      "length of actions is  387\n",
      "Your final reward is : 257.84\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1497])\n",
      "260.31662162195516\n",
      "length of actions is  276\n",
      "254.75904011628592\n",
      "length of actions is  358\n",
      "319.7248100907508\n",
      "length of actions is  208\n",
      "300.20063004558693\n",
      "length of actions is  247\n",
      "253.44371191959462\n",
      "length of actions is  442\n",
      "Your final reward is : 277.69\n",
      "Improve to score 277.69 at batch 573\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1330])\n",
      "267.70386568222136\n",
      "length of actions is  268\n",
      "262.04604384152844\n",
      "length of actions is  186\n",
      "263.1648473283106\n",
      "length of actions is  200\n",
      "266.1832092804185\n",
      "length of actions is  294\n",
      "251.18602018677115\n",
      "length of actions is  332\n",
      "Your final reward is : 262.06\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1359])\n",
      "160.8854697737088\n",
      "length of actions is  1000\n",
      "308.14402644570157\n",
      "length of actions is  209\n",
      "139.10122644532748\n",
      "length of actions is  1000\n",
      "152.2723295283708\n",
      "length of actions is  1000\n",
      "202.29813515228477\n",
      "length of actions is  1000\n",
      "Your final reward is : 192.54\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1310])\n",
      "135.64083925629333\n",
      "length of actions is  1000\n",
      "310.5528124743344\n",
      "length of actions is  195\n",
      "25.774697205748026\n",
      "length of actions is  144\n",
      "267.9311825786502\n",
      "length of actions is  818\n",
      "122.27649470114865\n",
      "length of actions is  1000\n",
      "Your final reward is : 172.44\n",
      "torch.from_numpy(rewards) looks like  torch.Size([896])\n",
      "156.16252590449528\n",
      "length of actions is  1000\n",
      "309.635012132751\n",
      "length of actions is  195\n",
      "271.40381650487296\n",
      "length of actions is  209\n",
      "215.31948416654984\n",
      "length of actions is  393\n",
      "290.51227283836977\n",
      "length of actions is  176\n",
      "Your final reward is : 248.61\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1379])\n",
      "158.63608691044752\n",
      "length of actions is  1000\n",
      "309.45066621123806\n",
      "length of actions is  218\n",
      "249.8825575376024\n",
      "length of actions is  331\n",
      "180.5639145486815\n",
      "length of actions is  1000\n",
      "274.19004656626373\n",
      "length of actions is  885\n",
      "Your final reward is : 234.54\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1592])\n",
      "271.93008839327\n",
      "length of actions is  216\n",
      "236.38791865740725\n",
      "length of actions is  387\n",
      "244.45400025592318\n",
      "length of actions is  377\n",
      "285.2785670828758\n",
      "length of actions is  251\n",
      "263.6556642156959\n",
      "length of actions is  296\n",
      "Your final reward is : 260.34\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1497])\n",
      "260.1123690331974\n",
      "length of actions is  202\n",
      "256.93205545128603\n",
      "length of actions is  361\n",
      "282.6286017956628\n",
      "length of actions is  261\n",
      "285.02976204026174\n",
      "length of actions is  207\n",
      "314.1147902273311\n",
      "length of actions is  188\n",
      "Your final reward is : 279.76\n",
      "Improve to score 279.76 at batch 580\n",
      "torch.from_numpy(rewards) looks like  torch.Size([886])\n",
      "160.95918112875253\n",
      "length of actions is  1000\n",
      "69.49927008651261\n",
      "length of actions is  127\n",
      "237.8090703940419\n",
      "length of actions is  344\n",
      "290.9398448976952\n",
      "length of actions is  167\n",
      "284.01763522353696\n",
      "length of actions is  190\n",
      "Your final reward is : 208.65\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1976])\n",
      "160.79623593354592\n",
      "length of actions is  1000\n",
      "65.44416648846763\n",
      "length of actions is  123\n",
      "33.63031409723041\n",
      "length of actions is  176\n",
      "259.16574137086263\n",
      "length of actions is  263\n",
      "147.01517775269377\n",
      "length of actions is  1000\n",
      "Your final reward is : 133.21\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1213])\n",
      "141.96183914285888\n",
      "length of actions is  1000\n",
      "66.95537081322217\n",
      "length of actions is  122\n",
      "257.7416335741364\n",
      "length of actions is  188\n",
      "277.0500277741985\n",
      "length of actions is  208\n",
      "66.21694395675888\n",
      "length of actions is  115\n",
      "Your final reward is : 161.99\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1705])\n",
      "160.7560804687439\n",
      "length of actions is  1000\n",
      "62.49515075009754\n",
      "length of actions is  119\n",
      "253.55447905872467\n",
      "length of actions is  210\n",
      "282.7696775618408\n",
      "length of actions is  159\n",
      "281.68847023468356\n",
      "length of actions is  214\n",
      "Your final reward is : 208.25\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1217])\n",
      "257.88320363422633\n",
      "length of actions is  192\n",
      "238.0110102059756\n",
      "length of actions is  374\n",
      "234.97547356012694\n",
      "length of actions is  282\n",
      "287.0130807288094\n",
      "length of actions is  243\n",
      "285.8418547482708\n",
      "length of actions is  228\n",
      "Your final reward is : 260.74\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1510])\n",
      "146.46133779466143\n",
      "length of actions is  1000\n",
      "72.19998927556097\n",
      "length of actions is  121\n",
      "284.94351088900044\n",
      "length of actions is  210\n",
      "175.34058992850473\n",
      "length of actions is  1000\n",
      "271.3503680344619\n",
      "length of actions is  182\n",
      "Your final reward is : 190.06\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2083])\n",
      "135.39848861277713\n",
      "length of actions is  1000\n",
      "67.35504637892814\n",
      "length of actions is  123\n",
      "9.002281481114636\n",
      "length of actions is  142\n",
      "62.95506732644537\n",
      "length of actions is  126\n",
      "241.508083406303\n",
      "length of actions is  467\n",
      "Your final reward is : 103.24\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1963])\n",
      "158.70975043763173\n",
      "length of actions is  1000\n",
      "52.113366233436636\n",
      "length of actions is  120\n",
      "265.58169811894976\n",
      "length of actions is  264\n",
      "175.34284768648564\n",
      "length of actions is  1000\n",
      "167.0288013183767\n",
      "length of actions is  1000\n",
      "Your final reward is : 163.76\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2091])\n",
      "161.3116555312269\n",
      "length of actions is  1000\n",
      "63.375574338821394\n",
      "length of actions is  122\n",
      "147.67273362459065\n",
      "length of actions is  1000\n",
      "62.74212114948267\n",
      "length of actions is  138\n",
      "164.57236573797712\n",
      "length of actions is  1000\n",
      "Your final reward is : 119.93\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1964])\n",
      "163.40756662336315\n",
      "length of actions is  1000\n",
      "63.30085481840774\n",
      "length of actions is  126\n",
      "241.16020014263356\n",
      "length of actions is  440\n",
      "44.44560294937378\n",
      "length of actions is  114\n",
      "174.9163863760367\n",
      "length of actions is  1000\n",
      "Your final reward is : 137.45\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2345])\n",
      "160.45691824767266\n",
      "length of actions is  1000\n",
      "60.10690056835935\n",
      "length of actions is  123\n",
      "20.1138223129405\n",
      "length of actions is  145\n",
      "58.65350610017211\n",
      "length of actions is  126\n",
      "247.04176703042432\n",
      "length of actions is  176\n",
      "Your final reward is : 109.27\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2066])\n",
      "164.21206369331713\n",
      "length of actions is  1000\n",
      "59.71519418596253\n",
      "length of actions is  121\n",
      "284.0871617733884\n",
      "length of actions is  211\n",
      "39.491181083736876\n",
      "length of actions is  144\n",
      "82.00590455545577\n",
      "length of actions is  125\n",
      "Your final reward is : 125.90\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1686])\n",
      "159.69510683728765\n",
      "length of actions is  1000\n",
      "52.743795829028585\n",
      "length of actions is  122\n",
      "262.5483747648693\n",
      "length of actions is  192\n",
      "54.936525775215415\n",
      "length of actions is  132\n",
      "41.15727612791014\n",
      "length of actions is  131\n",
      "Your final reward is : 114.22\n",
      "torch.from_numpy(rewards) looks like  torch.Size([988])\n",
      "25.585957849228862\n",
      "length of actions is  133\n",
      "261.49514233376635\n",
      "length of actions is  215\n",
      "35.72072876627189\n",
      "length of actions is  125\n",
      "281.5445175791742\n",
      "length of actions is  162\n",
      "22.960968722269982\n",
      "length of actions is  144\n",
      "Your final reward is : 125.46\n",
      "torch.from_numpy(rewards) looks like  torch.Size([890])\n",
      "51.02952980727903\n",
      "length of actions is  135\n",
      "247.88230404330943\n",
      "length of actions is  333\n",
      "246.4698205571978\n",
      "length of actions is  379\n",
      "74.74745722504366\n",
      "length of actions is  140\n",
      "50.735759359988634\n",
      "length of actions is  142\n",
      "Your final reward is : 134.17\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1184])\n",
      "27.97803890253931\n",
      "length of actions is  124\n",
      "224.84835198221162\n",
      "length of actions is  430\n",
      "39.91932328891838\n",
      "length of actions is  142\n",
      "235.40056682491027\n",
      "length of actions is  354\n",
      "221.24885098094106\n",
      "length of actions is  321\n",
      "Your final reward is : 149.88\n",
      "torch.from_numpy(rewards) looks like  torch.Size([733])\n",
      "263.0357188090038\n",
      "length of actions is  625\n",
      "290.537436984111\n",
      "length of actions is  250\n",
      "183.49898209451595\n",
      "length of actions is  1000\n",
      "9.83635102085907\n",
      "length of actions is  132\n",
      "259.530069019385\n",
      "length of actions is  280\n",
      "Your final reward is : 201.29\n",
      "torch.from_numpy(rewards) looks like  torch.Size([949])\n",
      "267.52868984272214\n",
      "length of actions is  469\n",
      "224.6339309541013\n",
      "length of actions is  471\n",
      "293.03069732796644\n",
      "length of actions is  483\n",
      "240.34038467066216\n",
      "length of actions is  423\n",
      "38.98656443992732\n",
      "length of actions is  131\n",
      "Your final reward is : 212.90\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1417])\n",
      "264.2628265500914\n",
      "length of actions is  191\n",
      "67.5220176876496\n",
      "length of actions is  145\n",
      "284.00012083358234\n",
      "length of actions is  282\n",
      "228.78624288379933\n",
      "length of actions is  392\n",
      "263.23043124479597\n",
      "length of actions is  169\n",
      "Your final reward is : 221.56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPISODE_PER_BATCH = 5  # 每蒐集 5 個 episodes 更新一次 agent\n",
    "NUM_BATCH = 600        # 總共更新 400 次\n",
    "BATCH_SIZE = 32\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "\n",
    "best_score = 0\n",
    "best_batch = 0\n",
    "\n",
    "# 訓練前，先確保 network 處在 training 模式\n",
    "agent.main_q_network.train()\n",
    "agent.target_q_network.train()\n",
    "steps_done = 0\n",
    "\n",
    "avg_total_rewards, avg_final_rewards = [], []\n",
    "\n",
    "prg_bar = tqdm(range(NUM_BATCH))\n",
    "for batch in prg_bar:\n",
    "\n",
    "    rewards = []\n",
    "    total_rewards, final_rewards = [], []\n",
    "\n",
    "    # 蒐集訓練資料\n",
    "    for episode in range(EPISODE_PER_BATCH):\n",
    "        \n",
    "        observation = env.reset() # 環境的初始化\n",
    "        state = observation  # 將觀測結果直接當成狀態s使用\n",
    "        state = torch.from_numpy(state).type(\n",
    "                torch.FloatTensor)  # 將NumPy變數轉換成PyTorch的張量\n",
    "        state = torch.unsqueeze(state, 0)  # 將size 4轉換成size 1x4\n",
    "        total_reward, total_step = 0, 0\n",
    "\n",
    "        while True:\n",
    "\n",
    "            action = agent.get_action(state, batch)  # 求出動作\n",
    "            # 執行動作a_t後，算出s_{t+1}與done旗標\n",
    "            # 根據action指定.item()、再取得內容\n",
    "            observation_next, reward, done, _ = env.step(action.item())  # 不會用到info，所以設定為_\n",
    "\n",
    "            total_reward += reward\n",
    "            total_step += 1\n",
    "            rewards.append(reward) #改這裡\n",
    "            # ! 重要 ！\n",
    "            # 現在的reward 的implementation 為每個時刻的瞬時reward, 給定action_list : a1, a2, a3 ......\n",
    "            #                                                       reward :     r1, r2 ,r3 ......\n",
    "            # medium：將reward調整成accumulative decaying reward, 給定action_list : a1,                         a2,                           a3 ......\n",
    "            #                                                       reward :     r1+0.99*r2+0.99^2*r3+......, r2+0.99*r3+0.99^2*r4+...... ,r3+0.99*r4+0.99^2*r5+ ......\n",
    "            # boss : implement DQN\n",
    "            if done:\n",
    "                state_next = None  # 沒有下個狀態，所以存入None\n",
    "\n",
    "            else:\n",
    "                state_next = observation_next  # 直接將觀測結果當成狀態使用\n",
    "                state_next = torch.from_numpy(state_next).type(\n",
    "                        torch.FloatTensor)  # 將numpy變數轉換成PyTorch的張量\n",
    "                state_next = torch.unsqueeze(state_next, 0)  # 將size 4轉換成size 1x4\n",
    "                \n",
    "            # 將學習經驗存入記憶體\n",
    "            agent.memorize(state, action, state_next, torch.FloatTensor([reward]))\n",
    "            \n",
    "            # 以Experience Replay更新Q函數\n",
    "            agent.update_q_function()\n",
    "            \n",
    "            # 觀測狀態的更新\n",
    "            state = state_next\n",
    "            \n",
    "            # 結束時的處理\n",
    "            if done:\n",
    "                final_rewards.append(reward)\n",
    "                total_rewards.append(total_reward)\n",
    "                break\n",
    "                \n",
    "\n",
    "    #print(f\"rewards looks like \", np.shape(rewards))      \n",
    "    # 紀錄訓練過程\n",
    "    avg_total_reward = sum(total_rewards) / len(total_rewards)\n",
    "    avg_final_reward = sum(final_rewards) / len(final_rewards)\n",
    "    avg_total_rewards.append(avg_total_reward)\n",
    "    avg_final_rewards.append(avg_final_reward)\n",
    "    prg_bar.set_description(f\"Total: {avg_total_reward: 4.1f}, Final: {avg_final_reward: 4.1f}\")\n",
    "\n",
    "    # 更新網路\n",
    "    # rewards = np.concatenate(rewards, axis=0)\n",
    "    #rewards = (rewards - np.mean(rewards)) / (np.std(rewards) + 1e-9)  # 將 reward 正規標準化\n",
    "    agent.update_target_q_function()\n",
    "    print(\"torch.from_numpy(rewards) looks like \", torch.from_numpy(np.array(rewards)).size())\n",
    "\n",
    "\n",
    "    ### testing\n",
    "\n",
    "    fix(env, seed)\n",
    "    agent.main_q_network.eval()  # 測試前先將 network 切換為 evaluation 模式\n",
    "    NUM_OF_TEST = 5 # Do not revise it !!!!!\n",
    "    test_total_reward = []\n",
    "    action_list = []\n",
    "    for i in range(NUM_OF_TEST):\n",
    "        actions = []\n",
    "        state = env.reset()\n",
    "\n",
    "        #img = plt.imshow(env.render(mode='rgb_array'))\n",
    "\n",
    "        total_reward = 0\n",
    "\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = agent.get_action(state, episode=i, test=True)\n",
    "            actions.append(action)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "\n",
    "            total_reward += reward\n",
    "\n",
    "            #img.set_data(env.render(mode='rgb_array'))\n",
    "            #display.display(plt.gcf())\n",
    "            #display.clear_output(wait=True)\n",
    "        print(total_reward)\n",
    "        test_total_reward.append(total_reward)\n",
    "\n",
    "        action_list.append(actions) #儲存你測試的結果\n",
    "        print(\"length of actions is \", len(actions))\n",
    "    print(f\"Your final reward is : %.2f\"%np.mean(test_total_reward))\n",
    "    if np.mean(test_total_reward) > 250:\n",
    "        distribution = {}\n",
    "        for actions in action_list:\n",
    "            for action in actions:\n",
    "                if action not in distribution.keys():\n",
    "                    distribution[action] = 1\n",
    "                else:\n",
    "                    distribution[action] += 1\n",
    "        PATH = \"Action_List_test\" + str(batch) + \".npy\" # 可以改成你想取的名字或路徑\n",
    "        np.save(PATH ,np.array(action_list)) \n",
    "        if np.mean(test_total_reward) > best_score:\n",
    "            best_score = np.mean(test_total_reward)\n",
    "            best_batch = batch\n",
    "            print('Improve to score %.2f at batch %d'% (best_score, best_batch ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "258a77f05cf14442ad6cb4a88ba3a986"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards looks like  (410,)\n",
      "log_probs looks like  (410,)\n",
      "logs prob looks like  torch.Size([410])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([410])\n",
      "rewards looks like  (389,)\n",
      "log_probs looks like  (389,)\n",
      "logs prob looks like  torch.Size([389])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([389])\n",
      "rewards looks like  (445,)\n",
      "log_probs looks like  (445,)\n",
      "logs prob looks like  torch.Size([445])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([445])\n",
      "rewards looks like  (547,)\n",
      "log_probs looks like  (547,)\n",
      "logs prob looks like  torch.Size([547])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([547])\n",
      "rewards looks like  (461,)\n",
      "log_probs looks like  (461,)\n",
      "logs prob looks like  torch.Size([461])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([461])\n",
      "rewards looks like  (475,)\n",
      "log_probs looks like  (475,)\n",
      "logs prob looks like  torch.Size([475])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([475])\n",
      "rewards looks like  (564,)\n",
      "log_probs looks like  (564,)\n",
      "logs prob looks like  torch.Size([564])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([564])\n",
      "rewards looks like  (465,)\n",
      "log_probs looks like  (465,)\n",
      "logs prob looks like  torch.Size([465])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([465])\n",
      "rewards looks like  (503,)\n",
      "log_probs looks like  (503,)\n",
      "logs prob looks like  torch.Size([503])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([503])\n",
      "rewards looks like  (494,)\n",
      "log_probs looks like  (494,)\n",
      "logs prob looks like  torch.Size([494])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([494])\n",
      "rewards looks like  (518,)\n",
      "log_probs looks like  (518,)\n",
      "logs prob looks like  torch.Size([518])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([518])\n",
      "rewards looks like  (452,)\n",
      "log_probs looks like  (452,)\n",
      "logs prob looks like  torch.Size([452])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([452])\n",
      "rewards looks like  (481,)\n",
      "log_probs looks like  (481,)\n",
      "logs prob looks like  torch.Size([481])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([481])\n",
      "rewards looks like  (447,)\n",
      "log_probs looks like  (447,)\n",
      "logs prob looks like  torch.Size([447])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([447])\n",
      "rewards looks like  (588,)\n",
      "log_probs looks like  (588,)\n",
      "logs prob looks like  torch.Size([588])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([588])\n",
      "rewards looks like  (646,)\n",
      "log_probs looks like  (646,)\n",
      "logs prob looks like  torch.Size([646])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([646])\n",
      "rewards looks like  (609,)\n",
      "log_probs looks like  (609,)\n",
      "logs prob looks like  torch.Size([609])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([609])\n",
      "rewards looks like  (528,)\n",
      "log_probs looks like  (528,)\n",
      "logs prob looks like  torch.Size([528])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([528])\n",
      "rewards looks like  (508,)\n",
      "log_probs looks like  (508,)\n",
      "logs prob looks like  torch.Size([508])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([508])\n",
      "rewards looks like  (525,)\n",
      "log_probs looks like  (525,)\n",
      "logs prob looks like  torch.Size([525])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([525])\n",
      "rewards looks like  (620,)\n",
      "log_probs looks like  (620,)\n",
      "logs prob looks like  torch.Size([620])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([620])\n",
      "rewards looks like  (567,)\n",
      "log_probs looks like  (567,)\n",
      "logs prob looks like  torch.Size([567])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([567])\n",
      "rewards looks like  (569,)\n",
      "log_probs looks like  (569,)\n",
      "logs prob looks like  torch.Size([569])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([569])\n",
      "rewards looks like  (747,)\n",
      "log_probs looks like  (747,)\n",
      "logs prob looks like  torch.Size([747])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([747])\n",
      "rewards looks like  (505,)\n",
      "log_probs looks like  (505,)\n",
      "logs prob looks like  torch.Size([505])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([505])\n",
      "rewards looks like  (601,)\n",
      "log_probs looks like  (601,)\n",
      "logs prob looks like  torch.Size([601])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([601])\n",
      "rewards looks like  (514,)\n",
      "log_probs looks like  (514,)\n",
      "logs prob looks like  torch.Size([514])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([514])\n",
      "rewards looks like  (678,)\n",
      "log_probs looks like  (678,)\n",
      "logs prob looks like  torch.Size([678])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([678])\n",
      "rewards looks like  (464,)\n",
      "log_probs looks like  (464,)\n",
      "logs prob looks like  torch.Size([464])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([464])\n",
      "rewards looks like  (582,)\n",
      "log_probs looks like  (582,)\n",
      "logs prob looks like  torch.Size([582])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([582])\n",
      "rewards looks like  (1277,)\n",
      "log_probs looks like  (1277,)\n",
      "logs prob looks like  torch.Size([1277])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1277])\n",
      "rewards looks like  (536,)\n",
      "log_probs looks like  (536,)\n",
      "logs prob looks like  torch.Size([536])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([536])\n",
      "rewards looks like  (585,)\n",
      "log_probs looks like  (585,)\n",
      "logs prob looks like  torch.Size([585])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([585])\n",
      "rewards looks like  (595,)\n",
      "log_probs looks like  (595,)\n",
      "logs prob looks like  torch.Size([595])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([595])\n",
      "rewards looks like  (518,)\n",
      "log_probs looks like  (518,)\n",
      "logs prob looks like  torch.Size([518])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([518])\n",
      "rewards looks like  (585,)\n",
      "log_probs looks like  (585,)\n",
      "logs prob looks like  torch.Size([585])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([585])\n",
      "rewards looks like  (1471,)\n",
      "log_probs looks like  (1471,)\n",
      "logs prob looks like  torch.Size([1471])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1471])\n",
      "rewards looks like  (518,)\n",
      "log_probs looks like  (518,)\n",
      "logs prob looks like  torch.Size([518])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([518])\n",
      "rewards looks like  (614,)\n",
      "log_probs looks like  (614,)\n",
      "logs prob looks like  torch.Size([614])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([614])\n",
      "rewards looks like  (574,)\n",
      "log_probs looks like  (574,)\n",
      "logs prob looks like  torch.Size([574])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([574])\n",
      "rewards looks like  (694,)\n",
      "log_probs looks like  (694,)\n",
      "logs prob looks like  torch.Size([694])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([694])\n",
      "rewards looks like  (683,)\n",
      "log_probs looks like  (683,)\n",
      "logs prob looks like  torch.Size([683])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([683])\n",
      "rewards looks like  (711,)\n",
      "log_probs looks like  (711,)\n",
      "logs prob looks like  torch.Size([711])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([711])\n",
      "rewards looks like  (686,)\n",
      "log_probs looks like  (686,)\n",
      "logs prob looks like  torch.Size([686])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([686])\n",
      "rewards looks like  (619,)\n",
      "log_probs looks like  (619,)\n",
      "logs prob looks like  torch.Size([619])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([619])\n",
      "rewards looks like  (632,)\n",
      "log_probs looks like  (632,)\n",
      "logs prob looks like  torch.Size([632])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([632])\n",
      "rewards looks like  (651,)\n",
      "log_probs looks like  (651,)\n",
      "logs prob looks like  torch.Size([651])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([651])\n",
      "rewards looks like  (542,)\n",
      "log_probs looks like  (542,)\n",
      "logs prob looks like  torch.Size([542])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([542])\n",
      "rewards looks like  (540,)\n",
      "log_probs looks like  (540,)\n",
      "logs prob looks like  torch.Size([540])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([540])\n",
      "rewards looks like  (724,)\n",
      "log_probs looks like  (724,)\n",
      "logs prob looks like  torch.Size([724])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([724])\n",
      "rewards looks like  (692,)\n",
      "log_probs looks like  (692,)\n",
      "logs prob looks like  torch.Size([692])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([692])\n",
      "rewards looks like  (690,)\n",
      "log_probs looks like  (690,)\n",
      "logs prob looks like  torch.Size([690])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([690])\n",
      "rewards looks like  (499,)\n",
      "log_probs looks like  (499,)\n",
      "logs prob looks like  torch.Size([499])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([499])\n",
      "rewards looks like  (1016,)\n",
      "log_probs looks like  (1016,)\n",
      "logs prob looks like  torch.Size([1016])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1016])\n",
      "rewards looks like  (569,)\n",
      "log_probs looks like  (569,)\n",
      "logs prob looks like  torch.Size([569])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([569])\n",
      "rewards looks like  (602,)\n",
      "log_probs looks like  (602,)\n",
      "logs prob looks like  torch.Size([602])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([602])\n",
      "rewards looks like  (520,)\n",
      "log_probs looks like  (520,)\n",
      "logs prob looks like  torch.Size([520])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([520])\n",
      "rewards looks like  (603,)\n",
      "log_probs looks like  (603,)\n",
      "logs prob looks like  torch.Size([603])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([603])\n",
      "rewards looks like  (772,)\n",
      "log_probs looks like  (772,)\n",
      "logs prob looks like  torch.Size([772])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([772])\n",
      "rewards looks like  (617,)\n",
      "log_probs looks like  (617,)\n",
      "logs prob looks like  torch.Size([617])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([617])\n",
      "rewards looks like  (717,)\n",
      "log_probs looks like  (717,)\n",
      "logs prob looks like  torch.Size([717])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([717])\n",
      "rewards looks like  (528,)\n",
      "log_probs looks like  (528,)\n",
      "logs prob looks like  torch.Size([528])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([528])\n",
      "rewards looks like  (482,)\n",
      "log_probs looks like  (482,)\n",
      "logs prob looks like  torch.Size([482])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([482])\n",
      "rewards looks like  (641,)\n",
      "log_probs looks like  (641,)\n",
      "logs prob looks like  torch.Size([641])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([641])\n",
      "rewards looks like  (639,)\n",
      "log_probs looks like  (639,)\n",
      "logs prob looks like  torch.Size([639])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([639])\n",
      "rewards looks like  (753,)\n",
      "log_probs looks like  (753,)\n",
      "logs prob looks like  torch.Size([753])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([753])\n",
      "rewards looks like  (621,)\n",
      "log_probs looks like  (621,)\n",
      "logs prob looks like  torch.Size([621])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([621])\n",
      "rewards looks like  (817,)\n",
      "log_probs looks like  (817,)\n",
      "logs prob looks like  torch.Size([817])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([817])\n",
      "rewards looks like  (724,)\n",
      "log_probs looks like  (724,)\n",
      "logs prob looks like  torch.Size([724])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([724])\n",
      "rewards looks like  (689,)\n",
      "log_probs looks like  (689,)\n",
      "logs prob looks like  torch.Size([689])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([689])\n",
      "rewards looks like  (704,)\n",
      "log_probs looks like  (704,)\n",
      "logs prob looks like  torch.Size([704])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([704])\n",
      "rewards looks like  (759,)\n",
      "log_probs looks like  (759,)\n",
      "logs prob looks like  torch.Size([759])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([759])\n",
      "rewards looks like  (515,)\n",
      "log_probs looks like  (515,)\n",
      "logs prob looks like  torch.Size([515])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([515])\n",
      "rewards looks like  (754,)\n",
      "log_probs looks like  (754,)\n",
      "logs prob looks like  torch.Size([754])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([754])\n",
      "rewards looks like  (719,)\n",
      "log_probs looks like  (719,)\n",
      "logs prob looks like  torch.Size([719])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([719])\n",
      "rewards looks like  (572,)\n",
      "log_probs looks like  (572,)\n",
      "logs prob looks like  torch.Size([572])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([572])\n",
      "rewards looks like  (729,)\n",
      "log_probs looks like  (729,)\n",
      "logs prob looks like  torch.Size([729])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([729])\n",
      "rewards looks like  (746,)\n",
      "log_probs looks like  (746,)\n",
      "logs prob looks like  torch.Size([746])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([746])\n",
      "rewards looks like  (675,)\n",
      "log_probs looks like  (675,)\n",
      "logs prob looks like  torch.Size([675])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([675])\n",
      "rewards looks like  (595,)\n",
      "log_probs looks like  (595,)\n",
      "logs prob looks like  torch.Size([595])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([595])\n",
      "rewards looks like  (715,)\n",
      "log_probs looks like  (715,)\n",
      "logs prob looks like  torch.Size([715])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([715])\n",
      "rewards looks like  (761,)\n",
      "log_probs looks like  (761,)\n",
      "logs prob looks like  torch.Size([761])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([761])\n",
      "rewards looks like  (878,)\n",
      "log_probs looks like  (878,)\n",
      "logs prob looks like  torch.Size([878])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([878])\n",
      "rewards looks like  (898,)\n",
      "log_probs looks like  (898,)\n",
      "logs prob looks like  torch.Size([898])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([898])\n",
      "rewards looks like  (1429,)\n",
      "log_probs looks like  (1429,)\n",
      "logs prob looks like  torch.Size([1429])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1429])\n",
      "rewards looks like  (885,)\n",
      "log_probs looks like  (885,)\n",
      "logs prob looks like  torch.Size([885])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([885])\n",
      "rewards looks like  (729,)\n",
      "log_probs looks like  (729,)\n",
      "logs prob looks like  torch.Size([729])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([729])\n",
      "rewards looks like  (963,)\n",
      "log_probs looks like  (963,)\n",
      "logs prob looks like  torch.Size([963])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([963])\n",
      "rewards looks like  (1525,)\n",
      "log_probs looks like  (1525,)\n",
      "logs prob looks like  torch.Size([1525])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1525])\n",
      "rewards looks like  (682,)\n",
      "log_probs looks like  (682,)\n",
      "logs prob looks like  torch.Size([682])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([682])\n",
      "rewards looks like  (1067,)\n",
      "log_probs looks like  (1067,)\n",
      "logs prob looks like  torch.Size([1067])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1067])\n",
      "rewards looks like  (1113,)\n",
      "log_probs looks like  (1113,)\n",
      "logs prob looks like  torch.Size([1113])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1113])\n",
      "rewards looks like  (979,)\n",
      "log_probs looks like  (979,)\n",
      "logs prob looks like  torch.Size([979])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([979])\n",
      "rewards looks like  (904,)\n",
      "log_probs looks like  (904,)\n",
      "logs prob looks like  torch.Size([904])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([904])\n",
      "rewards looks like  (831,)\n",
      "log_probs looks like  (831,)\n",
      "logs prob looks like  torch.Size([831])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([831])\n",
      "rewards looks like  (920,)\n",
      "log_probs looks like  (920,)\n",
      "logs prob looks like  torch.Size([920])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([920])\n",
      "rewards looks like  (895,)\n",
      "log_probs looks like  (895,)\n",
      "logs prob looks like  torch.Size([895])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([895])\n",
      "rewards looks like  (851,)\n",
      "log_probs looks like  (851,)\n",
      "logs prob looks like  torch.Size([851])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([851])\n",
      "rewards looks like  (793,)\n",
      "log_probs looks like  (793,)\n",
      "logs prob looks like  torch.Size([793])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([793])\n",
      "rewards looks like  (1140,)\n",
      "log_probs looks like  (1140,)\n",
      "logs prob looks like  torch.Size([1140])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1140])\n",
      "rewards looks like  (979,)\n",
      "log_probs looks like  (979,)\n",
      "logs prob looks like  torch.Size([979])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([979])\n",
      "rewards looks like  (902,)\n",
      "log_probs looks like  (902,)\n",
      "logs prob looks like  torch.Size([902])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([902])\n",
      "rewards looks like  (808,)\n",
      "log_probs looks like  (808,)\n",
      "logs prob looks like  torch.Size([808])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([808])\n",
      "rewards looks like  (754,)\n",
      "log_probs looks like  (754,)\n",
      "logs prob looks like  torch.Size([754])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([754])\n",
      "rewards looks like  (1391,)\n",
      "log_probs looks like  (1391,)\n",
      "logs prob looks like  torch.Size([1391])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1391])\n",
      "rewards looks like  (875,)\n",
      "log_probs looks like  (875,)\n",
      "logs prob looks like  torch.Size([875])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([875])\n",
      "rewards looks like  (871,)\n",
      "log_probs looks like  (871,)\n",
      "logs prob looks like  torch.Size([871])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([871])\n",
      "rewards looks like  (1138,)\n",
      "log_probs looks like  (1138,)\n",
      "logs prob looks like  torch.Size([1138])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1138])\n",
      "rewards looks like  (1683,)\n",
      "log_probs looks like  (1683,)\n",
      "logs prob looks like  torch.Size([1683])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1683])\n",
      "rewards looks like  (1150,)\n",
      "log_probs looks like  (1150,)\n",
      "logs prob looks like  torch.Size([1150])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1150])\n",
      "rewards looks like  (1605,)\n",
      "log_probs looks like  (1605,)\n",
      "logs prob looks like  torch.Size([1605])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1605])\n",
      "rewards looks like  (1375,)\n",
      "log_probs looks like  (1375,)\n",
      "logs prob looks like  torch.Size([1375])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1375])\n",
      "rewards looks like  (730,)\n",
      "log_probs looks like  (730,)\n",
      "logs prob looks like  torch.Size([730])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([730])\n",
      "rewards looks like  (1102,)\n",
      "log_probs looks like  (1102,)\n",
      "logs prob looks like  torch.Size([1102])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1102])\n",
      "rewards looks like  (1573,)\n",
      "log_probs looks like  (1573,)\n",
      "logs prob looks like  torch.Size([1573])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1573])\n",
      "rewards looks like  (1609,)\n",
      "log_probs looks like  (1609,)\n",
      "logs prob looks like  torch.Size([1609])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1609])\n",
      "rewards looks like  (921,)\n",
      "log_probs looks like  (921,)\n",
      "logs prob looks like  torch.Size([921])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([921])\n",
      "rewards looks like  (957,)\n",
      "log_probs looks like  (957,)\n",
      "logs prob looks like  torch.Size([957])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([957])\n",
      "rewards looks like  (1324,)\n",
      "log_probs looks like  (1324,)\n",
      "logs prob looks like  torch.Size([1324])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1324])\n",
      "rewards looks like  (820,)\n",
      "log_probs looks like  (820,)\n",
      "logs prob looks like  torch.Size([820])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([820])\n",
      "rewards looks like  (865,)\n",
      "log_probs looks like  (865,)\n",
      "logs prob looks like  torch.Size([865])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([865])\n",
      "rewards looks like  (1843,)\n",
      "log_probs looks like  (1843,)\n",
      "logs prob looks like  torch.Size([1843])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1843])\n",
      "rewards looks like  (1880,)\n",
      "log_probs looks like  (1880,)\n",
      "logs prob looks like  torch.Size([1880])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1880])\n",
      "rewards looks like  (2101,)\n",
      "log_probs looks like  (2101,)\n",
      "logs prob looks like  torch.Size([2101])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2101])\n",
      "rewards looks like  (881,)\n",
      "log_probs looks like  (881,)\n",
      "logs prob looks like  torch.Size([881])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([881])\n",
      "rewards looks like  (937,)\n",
      "log_probs looks like  (937,)\n",
      "logs prob looks like  torch.Size([937])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([937])\n",
      "rewards looks like  (1008,)\n",
      "log_probs looks like  (1008,)\n",
      "logs prob looks like  torch.Size([1008])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1008])\n",
      "rewards looks like  (844,)\n",
      "log_probs looks like  (844,)\n",
      "logs prob looks like  torch.Size([844])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([844])\n",
      "rewards looks like  (956,)\n",
      "log_probs looks like  (956,)\n",
      "logs prob looks like  torch.Size([956])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([956])\n",
      "rewards looks like  (1478,)\n",
      "log_probs looks like  (1478,)\n",
      "logs prob looks like  torch.Size([1478])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1478])\n",
      "rewards looks like  (2310,)\n",
      "log_probs looks like  (2310,)\n",
      "logs prob looks like  torch.Size([2310])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2310])\n",
      "rewards looks like  (3343,)\n",
      "log_probs looks like  (3343,)\n",
      "logs prob looks like  torch.Size([3343])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3343])\n",
      "rewards looks like  (1568,)\n",
      "log_probs looks like  (1568,)\n",
      "logs prob looks like  torch.Size([1568])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1568])\n",
      "rewards looks like  (1078,)\n",
      "log_probs looks like  (1078,)\n",
      "logs prob looks like  torch.Size([1078])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1078])\n",
      "rewards looks like  (1514,)\n",
      "log_probs looks like  (1514,)\n",
      "logs prob looks like  torch.Size([1514])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1514])\n",
      "rewards looks like  (591,)\n",
      "log_probs looks like  (591,)\n",
      "logs prob looks like  torch.Size([591])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([591])\n",
      "rewards looks like  (633,)\n",
      "log_probs looks like  (633,)\n",
      "logs prob looks like  torch.Size([633])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([633])\n",
      "rewards looks like  (703,)\n",
      "log_probs looks like  (703,)\n",
      "logs prob looks like  torch.Size([703])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([703])\n",
      "rewards looks like  (1613,)\n",
      "log_probs looks like  (1613,)\n",
      "logs prob looks like  torch.Size([1613])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1613])\n",
      "rewards looks like  (1329,)\n",
      "log_probs looks like  (1329,)\n",
      "logs prob looks like  torch.Size([1329])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1329])\n",
      "rewards looks like  (768,)\n",
      "log_probs looks like  (768,)\n",
      "logs prob looks like  torch.Size([768])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([768])\n",
      "rewards looks like  (839,)\n",
      "log_probs looks like  (839,)\n",
      "logs prob looks like  torch.Size([839])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([839])\n",
      "rewards looks like  (1782,)\n",
      "log_probs looks like  (1782,)\n",
      "logs prob looks like  torch.Size([1782])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1782])\n",
      "rewards looks like  (1972,)\n",
      "log_probs looks like  (1972,)\n",
      "logs prob looks like  torch.Size([1972])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1972])\n",
      "rewards looks like  (717,)\n",
      "log_probs looks like  (717,)\n",
      "logs prob looks like  torch.Size([717])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([717])\n",
      "rewards looks like  (1188,)\n",
      "log_probs looks like  (1188,)\n",
      "logs prob looks like  torch.Size([1188])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1188])\n",
      "rewards looks like  (1699,)\n",
      "log_probs looks like  (1699,)\n",
      "logs prob looks like  torch.Size([1699])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1699])\n",
      "rewards looks like  (466,)\n",
      "log_probs looks like  (466,)\n",
      "logs prob looks like  torch.Size([466])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([466])\n",
      "rewards looks like  (566,)\n",
      "log_probs looks like  (566,)\n",
      "logs prob looks like  torch.Size([566])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([566])\n",
      "rewards looks like  (517,)\n",
      "log_probs looks like  (517,)\n",
      "logs prob looks like  torch.Size([517])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([517])\n",
      "rewards looks like  (642,)\n",
      "log_probs looks like  (642,)\n",
      "logs prob looks like  torch.Size([642])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([642])\n",
      "rewards looks like  (876,)\n",
      "log_probs looks like  (876,)\n",
      "logs prob looks like  torch.Size([876])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([876])\n",
      "rewards looks like  (1732,)\n",
      "log_probs looks like  (1732,)\n",
      "logs prob looks like  torch.Size([1732])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1732])\n",
      "rewards looks like  (1031,)\n",
      "log_probs looks like  (1031,)\n",
      "logs prob looks like  torch.Size([1031])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1031])\n",
      "rewards looks like  (1609,)\n",
      "log_probs looks like  (1609,)\n",
      "logs prob looks like  torch.Size([1609])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1609])\n",
      "rewards looks like  (2470,)\n",
      "log_probs looks like  (2470,)\n",
      "logs prob looks like  torch.Size([2470])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2470])\n",
      "rewards looks like  (1236,)\n",
      "log_probs looks like  (1236,)\n",
      "logs prob looks like  torch.Size([1236])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1236])\n",
      "rewards looks like  (2238,)\n",
      "log_probs looks like  (2238,)\n",
      "logs prob looks like  torch.Size([2238])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2238])\n",
      "rewards looks like  (1348,)\n",
      "log_probs looks like  (1348,)\n",
      "logs prob looks like  torch.Size([1348])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1348])\n",
      "rewards looks like  (700,)\n",
      "log_probs looks like  (700,)\n",
      "logs prob looks like  torch.Size([700])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([700])\n",
      "rewards looks like  (2139,)\n",
      "log_probs looks like  (2139,)\n",
      "logs prob looks like  torch.Size([2139])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2139])\n",
      "rewards looks like  (1872,)\n",
      "log_probs looks like  (1872,)\n",
      "logs prob looks like  torch.Size([1872])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1872])\n",
      "rewards looks like  (515,)\n",
      "log_probs looks like  (515,)\n",
      "logs prob looks like  torch.Size([515])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([515])\n",
      "rewards looks like  (468,)\n",
      "log_probs looks like  (468,)\n",
      "logs prob looks like  torch.Size([468])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([468])\n",
      "rewards looks like  (2282,)\n",
      "log_probs looks like  (2282,)\n",
      "logs prob looks like  torch.Size([2282])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2282])\n",
      "rewards looks like  (726,)\n",
      "log_probs looks like  (726,)\n",
      "logs prob looks like  torch.Size([726])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([726])\n",
      "rewards looks like  (4101,)\n",
      "log_probs looks like  (4101,)\n",
      "logs prob looks like  torch.Size([4101])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4101])\n",
      "rewards looks like  (710,)\n",
      "log_probs looks like  (710,)\n",
      "logs prob looks like  torch.Size([710])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([710])\n",
      "rewards looks like  (1096,)\n",
      "log_probs looks like  (1096,)\n",
      "logs prob looks like  torch.Size([1096])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1096])\n",
      "rewards looks like  (1737,)\n",
      "log_probs looks like  (1737,)\n",
      "logs prob looks like  torch.Size([1737])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1737])\n",
      "rewards looks like  (2198,)\n",
      "log_probs looks like  (2198,)\n",
      "logs prob looks like  torch.Size([2198])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2198])\n",
      "rewards looks like  (716,)\n",
      "log_probs looks like  (716,)\n",
      "logs prob looks like  torch.Size([716])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([716])\n",
      "rewards looks like  (1635,)\n",
      "log_probs looks like  (1635,)\n",
      "logs prob looks like  torch.Size([1635])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1635])\n",
      "rewards looks like  (2034,)\n",
      "log_probs looks like  (2034,)\n",
      "logs prob looks like  torch.Size([2034])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2034])\n",
      "rewards looks like  (962,)\n",
      "log_probs looks like  (962,)\n",
      "logs prob looks like  torch.Size([962])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([962])\n",
      "rewards looks like  (1607,)\n",
      "log_probs looks like  (1607,)\n",
      "logs prob looks like  torch.Size([1607])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1607])\n",
      "rewards looks like  (1169,)\n",
      "log_probs looks like  (1169,)\n",
      "logs prob looks like  torch.Size([1169])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1169])\n",
      "rewards looks like  (2425,)\n",
      "log_probs looks like  (2425,)\n",
      "logs prob looks like  torch.Size([2425])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2425])\n",
      "rewards looks like  (1461,)\n",
      "log_probs looks like  (1461,)\n",
      "logs prob looks like  torch.Size([1461])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1461])\n",
      "rewards looks like  (888,)\n",
      "log_probs looks like  (888,)\n",
      "logs prob looks like  torch.Size([888])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([888])\n",
      "rewards looks like  (1671,)\n",
      "log_probs looks like  (1671,)\n",
      "logs prob looks like  torch.Size([1671])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1671])\n",
      "rewards looks like  (1118,)\n",
      "log_probs looks like  (1118,)\n",
      "logs prob looks like  torch.Size([1118])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1118])\n",
      "rewards looks like  (1976,)\n",
      "log_probs looks like  (1976,)\n",
      "logs prob looks like  torch.Size([1976])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1976])\n",
      "rewards looks like  (1757,)\n",
      "log_probs looks like  (1757,)\n",
      "logs prob looks like  torch.Size([1757])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1757])\n",
      "rewards looks like  (1492,)\n",
      "log_probs looks like  (1492,)\n",
      "logs prob looks like  torch.Size([1492])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1492])\n",
      "rewards looks like  (997,)\n",
      "log_probs looks like  (997,)\n",
      "logs prob looks like  torch.Size([997])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([997])\n",
      "rewards looks like  (1226,)\n",
      "log_probs looks like  (1226,)\n",
      "logs prob looks like  torch.Size([1226])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1226])\n",
      "rewards looks like  (2003,)\n",
      "log_probs looks like  (2003,)\n",
      "logs prob looks like  torch.Size([2003])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2003])\n",
      "rewards looks like  (2593,)\n",
      "log_probs looks like  (2593,)\n",
      "logs prob looks like  torch.Size([2593])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2593])\n",
      "rewards looks like  (1816,)\n",
      "log_probs looks like  (1816,)\n",
      "logs prob looks like  torch.Size([1816])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1816])\n",
      "rewards looks like  (1543,)\n",
      "log_probs looks like  (1543,)\n",
      "logs prob looks like  torch.Size([1543])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1543])\n",
      "rewards looks like  (738,)\n",
      "log_probs looks like  (738,)\n",
      "logs prob looks like  torch.Size([738])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([738])\n",
      "rewards looks like  (1786,)\n",
      "log_probs looks like  (1786,)\n",
      "logs prob looks like  torch.Size([1786])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1786])\n",
      "rewards looks like  (1098,)\n",
      "log_probs looks like  (1098,)\n",
      "logs prob looks like  torch.Size([1098])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1098])\n",
      "rewards looks like  (998,)\n",
      "log_probs looks like  (998,)\n",
      "logs prob looks like  torch.Size([998])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([998])\n",
      "rewards looks like  (1357,)\n",
      "log_probs looks like  (1357,)\n",
      "logs prob looks like  torch.Size([1357])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1357])\n",
      "rewards looks like  (2209,)\n",
      "log_probs looks like  (2209,)\n",
      "logs prob looks like  torch.Size([2209])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2209])\n",
      "rewards looks like  (1251,)\n",
      "log_probs looks like  (1251,)\n",
      "logs prob looks like  torch.Size([1251])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1251])\n",
      "rewards looks like  (2694,)\n",
      "log_probs looks like  (2694,)\n",
      "logs prob looks like  torch.Size([2694])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2694])\n",
      "rewards looks like  (1844,)\n",
      "log_probs looks like  (1844,)\n",
      "logs prob looks like  torch.Size([1844])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1844])\n",
      "rewards looks like  (1798,)\n",
      "log_probs looks like  (1798,)\n",
      "logs prob looks like  torch.Size([1798])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1798])\n",
      "rewards looks like  (1514,)\n",
      "log_probs looks like  (1514,)\n",
      "logs prob looks like  torch.Size([1514])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1514])\n",
      "rewards looks like  (823,)\n",
      "log_probs looks like  (823,)\n",
      "logs prob looks like  torch.Size([823])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([823])\n",
      "rewards looks like  (1720,)\n",
      "log_probs looks like  (1720,)\n",
      "logs prob looks like  torch.Size([1720])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1720])\n",
      "rewards looks like  (1152,)\n",
      "log_probs looks like  (1152,)\n",
      "logs prob looks like  torch.Size([1152])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1152])\n",
      "rewards looks like  (2051,)\n",
      "log_probs looks like  (2051,)\n",
      "logs prob looks like  torch.Size([2051])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2051])\n",
      "rewards looks like  (1264,)\n",
      "log_probs looks like  (1264,)\n",
      "logs prob looks like  torch.Size([1264])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1264])\n",
      "rewards looks like  (930,)\n",
      "log_probs looks like  (930,)\n",
      "logs prob looks like  torch.Size([930])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([930])\n",
      "rewards looks like  (1132,)\n",
      "log_probs looks like  (1132,)\n",
      "logs prob looks like  torch.Size([1132])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1132])\n",
      "rewards looks like  (2101,)\n",
      "log_probs looks like  (2101,)\n",
      "logs prob looks like  torch.Size([2101])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2101])\n",
      "rewards looks like  (1268,)\n",
      "log_probs looks like  (1268,)\n",
      "logs prob looks like  torch.Size([1268])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1268])\n",
      "rewards looks like  (1587,)\n",
      "log_probs looks like  (1587,)\n",
      "logs prob looks like  torch.Size([1587])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1587])\n",
      "rewards looks like  (3305,)\n",
      "log_probs looks like  (3305,)\n",
      "logs prob looks like  torch.Size([3305])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3305])\n",
      "rewards looks like  (1121,)\n",
      "log_probs looks like  (1121,)\n",
      "logs prob looks like  torch.Size([1121])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1121])\n",
      "rewards looks like  (1399,)\n",
      "log_probs looks like  (1399,)\n",
      "logs prob looks like  torch.Size([1399])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1399])\n",
      "rewards looks like  (2019,)\n",
      "log_probs looks like  (2019,)\n",
      "logs prob looks like  torch.Size([2019])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2019])\n",
      "rewards looks like  (1143,)\n",
      "log_probs looks like  (1143,)\n",
      "logs prob looks like  torch.Size([1143])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1143])\n",
      "rewards looks like  (1129,)\n",
      "log_probs looks like  (1129,)\n",
      "logs prob looks like  torch.Size([1129])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1129])\n",
      "rewards looks like  (1824,)\n",
      "log_probs looks like  (1824,)\n",
      "logs prob looks like  torch.Size([1824])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1824])\n",
      "rewards looks like  (976,)\n",
      "log_probs looks like  (976,)\n",
      "logs prob looks like  torch.Size([976])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([976])\n",
      "rewards looks like  (1080,)\n",
      "log_probs looks like  (1080,)\n",
      "logs prob looks like  torch.Size([1080])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1080])\n",
      "rewards looks like  (1027,)\n",
      "log_probs looks like  (1027,)\n",
      "logs prob looks like  torch.Size([1027])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1027])\n",
      "rewards looks like  (1061,)\n",
      "log_probs looks like  (1061,)\n",
      "logs prob looks like  torch.Size([1061])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1061])\n",
      "rewards looks like  (1010,)\n",
      "log_probs looks like  (1010,)\n",
      "logs prob looks like  torch.Size([1010])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1010])\n",
      "rewards looks like  (2886,)\n",
      "log_probs looks like  (2886,)\n",
      "logs prob looks like  torch.Size([2886])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2886])\n",
      "rewards looks like  (995,)\n",
      "log_probs looks like  (995,)\n",
      "logs prob looks like  torch.Size([995])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([995])\n",
      "rewards looks like  (1963,)\n",
      "log_probs looks like  (1963,)\n",
      "logs prob looks like  torch.Size([1963])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1963])\n",
      "rewards looks like  (1688,)\n",
      "log_probs looks like  (1688,)\n",
      "logs prob looks like  torch.Size([1688])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1688])\n",
      "rewards looks like  (1148,)\n",
      "log_probs looks like  (1148,)\n",
      "logs prob looks like  torch.Size([1148])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1148])\n",
      "rewards looks like  (1687,)\n",
      "log_probs looks like  (1687,)\n",
      "logs prob looks like  torch.Size([1687])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1687])\n",
      "rewards looks like  (893,)\n",
      "log_probs looks like  (893,)\n",
      "logs prob looks like  torch.Size([893])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([893])\n",
      "rewards looks like  (2379,)\n",
      "log_probs looks like  (2379,)\n",
      "logs prob looks like  torch.Size([2379])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2379])\n",
      "rewards looks like  (1141,)\n",
      "log_probs looks like  (1141,)\n",
      "logs prob looks like  torch.Size([1141])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1141])\n",
      "rewards looks like  (1428,)\n",
      "log_probs looks like  (1428,)\n",
      "logs prob looks like  torch.Size([1428])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1428])\n",
      "rewards looks like  (1823,)\n",
      "log_probs looks like  (1823,)\n",
      "logs prob looks like  torch.Size([1823])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1823])\n",
      "rewards looks like  (1777,)\n",
      "log_probs looks like  (1777,)\n",
      "logs prob looks like  torch.Size([1777])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1777])\n",
      "rewards looks like  (1369,)\n",
      "log_probs looks like  (1369,)\n",
      "logs prob looks like  torch.Size([1369])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1369])\n",
      "rewards looks like  (1231,)\n",
      "log_probs looks like  (1231,)\n",
      "logs prob looks like  torch.Size([1231])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1231])\n",
      "rewards looks like  (1228,)\n",
      "log_probs looks like  (1228,)\n",
      "logs prob looks like  torch.Size([1228])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1228])\n",
      "rewards looks like  (1708,)\n",
      "log_probs looks like  (1708,)\n",
      "logs prob looks like  torch.Size([1708])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1708])\n",
      "rewards looks like  (1418,)\n",
      "log_probs looks like  (1418,)\n",
      "logs prob looks like  torch.Size([1418])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1418])\n",
      "rewards looks like  (1779,)\n",
      "log_probs looks like  (1779,)\n",
      "logs prob looks like  torch.Size([1779])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1779])\n",
      "rewards looks like  (2162,)\n",
      "log_probs looks like  (2162,)\n",
      "logs prob looks like  torch.Size([2162])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2162])\n",
      "rewards looks like  (1357,)\n",
      "log_probs looks like  (1357,)\n",
      "logs prob looks like  torch.Size([1357])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1357])\n",
      "rewards looks like  (1541,)\n",
      "log_probs looks like  (1541,)\n",
      "logs prob looks like  torch.Size([1541])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1541])\n",
      "rewards looks like  (1405,)\n",
      "log_probs looks like  (1405,)\n",
      "logs prob looks like  torch.Size([1405])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1405])\n",
      "rewards looks like  (1676,)\n",
      "log_probs looks like  (1676,)\n",
      "logs prob looks like  torch.Size([1676])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1676])\n",
      "rewards looks like  (1255,)\n",
      "log_probs looks like  (1255,)\n",
      "logs prob looks like  torch.Size([1255])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1255])\n",
      "rewards looks like  (1302,)\n",
      "log_probs looks like  (1302,)\n",
      "logs prob looks like  torch.Size([1302])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1302])\n",
      "rewards looks like  (2618,)\n",
      "log_probs looks like  (2618,)\n",
      "logs prob looks like  torch.Size([2618])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2618])\n",
      "rewards looks like  (1608,)\n",
      "log_probs looks like  (1608,)\n",
      "logs prob looks like  torch.Size([1608])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1608])\n",
      "rewards looks like  (2788,)\n",
      "log_probs looks like  (2788,)\n",
      "logs prob looks like  torch.Size([2788])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2788])\n",
      "rewards looks like  (2001,)\n",
      "log_probs looks like  (2001,)\n",
      "logs prob looks like  torch.Size([2001])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2001])\n",
      "rewards looks like  (2384,)\n",
      "log_probs looks like  (2384,)\n",
      "logs prob looks like  torch.Size([2384])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2384])\n",
      "rewards looks like  (2644,)\n",
      "log_probs looks like  (2644,)\n",
      "logs prob looks like  torch.Size([2644])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2644])\n",
      "rewards looks like  (1024,)\n",
      "log_probs looks like  (1024,)\n",
      "logs prob looks like  torch.Size([1024])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1024])\n",
      "rewards looks like  (1657,)\n",
      "log_probs looks like  (1657,)\n",
      "logs prob looks like  torch.Size([1657])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1657])\n",
      "rewards looks like  (2248,)\n",
      "log_probs looks like  (2248,)\n",
      "logs prob looks like  torch.Size([2248])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2248])\n",
      "rewards looks like  (1317,)\n",
      "log_probs looks like  (1317,)\n",
      "logs prob looks like  torch.Size([1317])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1317])\n",
      "rewards looks like  (1825,)\n",
      "log_probs looks like  (1825,)\n",
      "logs prob looks like  torch.Size([1825])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1825])\n",
      "rewards looks like  (2635,)\n",
      "log_probs looks like  (2635,)\n",
      "logs prob looks like  torch.Size([2635])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2635])\n",
      "rewards looks like  (1173,)\n",
      "log_probs looks like  (1173,)\n",
      "logs prob looks like  torch.Size([1173])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1173])\n",
      "rewards looks like  (1083,)\n",
      "log_probs looks like  (1083,)\n",
      "logs prob looks like  torch.Size([1083])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1083])\n",
      "rewards looks like  (1853,)\n",
      "log_probs looks like  (1853,)\n",
      "logs prob looks like  torch.Size([1853])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1853])\n",
      "rewards looks like  (1822,)\n",
      "log_probs looks like  (1822,)\n",
      "logs prob looks like  torch.Size([1822])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1822])\n",
      "rewards looks like  (1316,)\n",
      "log_probs looks like  (1316,)\n",
      "logs prob looks like  torch.Size([1316])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1316])\n",
      "rewards looks like  (1752,)\n",
      "log_probs looks like  (1752,)\n",
      "logs prob looks like  torch.Size([1752])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1752])\n",
      "rewards looks like  (2684,)\n",
      "log_probs looks like  (2684,)\n",
      "logs prob looks like  torch.Size([2684])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2684])\n",
      "rewards looks like  (1415,)\n",
      "log_probs looks like  (1415,)\n",
      "logs prob looks like  torch.Size([1415])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1415])\n",
      "rewards looks like  (1846,)\n",
      "log_probs looks like  (1846,)\n",
      "logs prob looks like  torch.Size([1846])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1846])\n",
      "rewards looks like  (1948,)\n",
      "log_probs looks like  (1948,)\n",
      "logs prob looks like  torch.Size([1948])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1948])\n",
      "rewards looks like  (1242,)\n",
      "log_probs looks like  (1242,)\n",
      "logs prob looks like  torch.Size([1242])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1242])\n",
      "rewards looks like  (1595,)\n",
      "log_probs looks like  (1595,)\n",
      "logs prob looks like  torch.Size([1595])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1595])\n",
      "rewards looks like  (1287,)\n",
      "log_probs looks like  (1287,)\n",
      "logs prob looks like  torch.Size([1287])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1287])\n",
      "rewards looks like  (1918,)\n",
      "log_probs looks like  (1918,)\n",
      "logs prob looks like  torch.Size([1918])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1918])\n",
      "rewards looks like  (941,)\n",
      "log_probs looks like  (941,)\n",
      "logs prob looks like  torch.Size([941])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([941])\n",
      "rewards looks like  (1939,)\n",
      "log_probs looks like  (1939,)\n",
      "logs prob looks like  torch.Size([1939])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1939])\n",
      "rewards looks like  (1187,)\n",
      "log_probs looks like  (1187,)\n",
      "logs prob looks like  torch.Size([1187])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1187])\n",
      "rewards looks like  (1156,)\n",
      "log_probs looks like  (1156,)\n",
      "logs prob looks like  torch.Size([1156])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1156])\n",
      "rewards looks like  (1750,)\n",
      "log_probs looks like  (1750,)\n",
      "logs prob looks like  torch.Size([1750])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1750])\n",
      "rewards looks like  (1357,)\n",
      "log_probs looks like  (1357,)\n",
      "logs prob looks like  torch.Size([1357])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1357])\n",
      "rewards looks like  (1651,)\n",
      "log_probs looks like  (1651,)\n",
      "logs prob looks like  torch.Size([1651])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1651])\n",
      "rewards looks like  (1218,)\n",
      "log_probs looks like  (1218,)\n",
      "logs prob looks like  torch.Size([1218])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1218])\n",
      "rewards looks like  (1258,)\n",
      "log_probs looks like  (1258,)\n",
      "logs prob looks like  torch.Size([1258])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1258])\n",
      "rewards looks like  (2023,)\n",
      "log_probs looks like  (2023,)\n",
      "logs prob looks like  torch.Size([2023])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2023])\n",
      "rewards looks like  (1746,)\n",
      "log_probs looks like  (1746,)\n",
      "logs prob looks like  torch.Size([1746])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1746])\n",
      "rewards looks like  (1670,)\n",
      "log_probs looks like  (1670,)\n",
      "logs prob looks like  torch.Size([1670])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1670])\n",
      "rewards looks like  (1106,)\n",
      "log_probs looks like  (1106,)\n",
      "logs prob looks like  torch.Size([1106])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1106])\n",
      "rewards looks like  (1485,)\n",
      "log_probs looks like  (1485,)\n",
      "logs prob looks like  torch.Size([1485])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1485])\n",
      "rewards looks like  (1322,)\n",
      "log_probs looks like  (1322,)\n",
      "logs prob looks like  torch.Size([1322])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1322])\n",
      "rewards looks like  (1510,)\n",
      "log_probs looks like  (1510,)\n",
      "logs prob looks like  torch.Size([1510])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1510])\n",
      "rewards looks like  (1615,)\n",
      "log_probs looks like  (1615,)\n",
      "logs prob looks like  torch.Size([1615])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1615])\n",
      "rewards looks like  (1186,)\n",
      "log_probs looks like  (1186,)\n",
      "logs prob looks like  torch.Size([1186])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1186])\n",
      "rewards looks like  (2079,)\n",
      "log_probs looks like  (2079,)\n",
      "logs prob looks like  torch.Size([2079])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2079])\n",
      "rewards looks like  (986,)\n",
      "log_probs looks like  (986,)\n",
      "logs prob looks like  torch.Size([986])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([986])\n",
      "rewards looks like  (1235,)\n",
      "log_probs looks like  (1235,)\n",
      "logs prob looks like  torch.Size([1235])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1235])\n",
      "rewards looks like  (1434,)\n",
      "log_probs looks like  (1434,)\n",
      "logs prob looks like  torch.Size([1434])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1434])\n",
      "rewards looks like  (1757,)\n",
      "log_probs looks like  (1757,)\n",
      "logs prob looks like  torch.Size([1757])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1757])\n",
      "rewards looks like  (1455,)\n",
      "log_probs looks like  (1455,)\n",
      "logs prob looks like  torch.Size([1455])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1455])\n",
      "rewards looks like  (1083,)\n",
      "log_probs looks like  (1083,)\n",
      "logs prob looks like  torch.Size([1083])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1083])\n",
      "rewards looks like  (1217,)\n",
      "log_probs looks like  (1217,)\n",
      "logs prob looks like  torch.Size([1217])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1217])\n",
      "rewards looks like  (1409,)\n",
      "log_probs looks like  (1409,)\n",
      "logs prob looks like  torch.Size([1409])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1409])\n",
      "rewards looks like  (1228,)\n",
      "log_probs looks like  (1228,)\n",
      "logs prob looks like  torch.Size([1228])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1228])\n",
      "rewards looks like  (2791,)\n",
      "log_probs looks like  (2791,)\n",
      "logs prob looks like  torch.Size([2791])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2791])\n",
      "rewards looks like  (1449,)\n",
      "log_probs looks like  (1449,)\n",
      "logs prob looks like  torch.Size([1449])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1449])\n",
      "rewards looks like  (1759,)\n",
      "log_probs looks like  (1759,)\n",
      "logs prob looks like  torch.Size([1759])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1759])\n",
      "rewards looks like  (2377,)\n",
      "log_probs looks like  (2377,)\n",
      "logs prob looks like  torch.Size([2377])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2377])\n",
      "rewards looks like  (2049,)\n",
      "log_probs looks like  (2049,)\n",
      "logs prob looks like  torch.Size([2049])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2049])\n",
      "rewards looks like  (1308,)\n",
      "log_probs looks like  (1308,)\n",
      "logs prob looks like  torch.Size([1308])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1308])\n",
      "rewards looks like  (1803,)\n",
      "log_probs looks like  (1803,)\n",
      "logs prob looks like  torch.Size([1803])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1803])\n",
      "rewards looks like  (881,)\n",
      "log_probs looks like  (881,)\n",
      "logs prob looks like  torch.Size([881])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([881])\n",
      "rewards looks like  (1090,)\n",
      "log_probs looks like  (1090,)\n",
      "logs prob looks like  torch.Size([1090])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1090])\n",
      "rewards looks like  (1792,)\n",
      "log_probs looks like  (1792,)\n",
      "logs prob looks like  torch.Size([1792])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1792])\n",
      "rewards looks like  (974,)\n",
      "log_probs looks like  (974,)\n",
      "logs prob looks like  torch.Size([974])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([974])\n",
      "rewards looks like  (1082,)\n",
      "log_probs looks like  (1082,)\n",
      "logs prob looks like  torch.Size([1082])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1082])\n",
      "rewards looks like  (1539,)\n",
      "log_probs looks like  (1539,)\n",
      "logs prob looks like  torch.Size([1539])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1539])\n",
      "rewards looks like  (2071,)\n",
      "log_probs looks like  (2071,)\n",
      "logs prob looks like  torch.Size([2071])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2071])\n",
      "rewards looks like  (1482,)\n",
      "log_probs looks like  (1482,)\n",
      "logs prob looks like  torch.Size([1482])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1482])\n",
      "rewards looks like  (1483,)\n",
      "log_probs looks like  (1483,)\n",
      "logs prob looks like  torch.Size([1483])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1483])\n",
      "rewards looks like  (1734,)\n",
      "log_probs looks like  (1734,)\n",
      "logs prob looks like  torch.Size([1734])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1734])\n",
      "rewards looks like  (1900,)\n",
      "log_probs looks like  (1900,)\n",
      "logs prob looks like  torch.Size([1900])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1900])\n",
      "rewards looks like  (1809,)\n",
      "log_probs looks like  (1809,)\n",
      "logs prob looks like  torch.Size([1809])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1809])\n",
      "rewards looks like  (1313,)\n",
      "log_probs looks like  (1313,)\n",
      "logs prob looks like  torch.Size([1313])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1313])\n",
      "rewards looks like  (1871,)\n",
      "log_probs looks like  (1871,)\n",
      "logs prob looks like  torch.Size([1871])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1871])\n",
      "rewards looks like  (1551,)\n",
      "log_probs looks like  (1551,)\n",
      "logs prob looks like  torch.Size([1551])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1551])\n",
      "rewards looks like  (1315,)\n",
      "log_probs looks like  (1315,)\n",
      "logs prob looks like  torch.Size([1315])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1315])\n",
      "rewards looks like  (1935,)\n",
      "log_probs looks like  (1935,)\n",
      "logs prob looks like  torch.Size([1935])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1935])\n",
      "rewards looks like  (1328,)\n",
      "log_probs looks like  (1328,)\n",
      "logs prob looks like  torch.Size([1328])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1328])\n",
      "rewards looks like  (1916,)\n",
      "log_probs looks like  (1916,)\n",
      "logs prob looks like  torch.Size([1916])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1916])\n",
      "rewards looks like  (2931,)\n",
      "log_probs looks like  (2931,)\n",
      "logs prob looks like  torch.Size([2931])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2931])\n",
      "rewards looks like  (604,)\n",
      "log_probs looks like  (604,)\n",
      "logs prob looks like  torch.Size([604])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([604])\n",
      "rewards looks like  (773,)\n",
      "log_probs looks like  (773,)\n",
      "logs prob looks like  torch.Size([773])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([773])\n",
      "rewards looks like  (1073,)\n",
      "log_probs looks like  (1073,)\n",
      "logs prob looks like  torch.Size([1073])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1073])\n",
      "rewards looks like  (1457,)\n",
      "log_probs looks like  (1457,)\n",
      "logs prob looks like  torch.Size([1457])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1457])\n",
      "rewards looks like  (1259,)\n",
      "log_probs looks like  (1259,)\n",
      "logs prob looks like  torch.Size([1259])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1259])\n",
      "rewards looks like  (1108,)\n",
      "log_probs looks like  (1108,)\n",
      "logs prob looks like  torch.Size([1108])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1108])\n",
      "rewards looks like  (1381,)\n",
      "log_probs looks like  (1381,)\n",
      "logs prob looks like  torch.Size([1381])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1381])\n",
      "rewards looks like  (1090,)\n",
      "log_probs looks like  (1090,)\n",
      "logs prob looks like  torch.Size([1090])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1090])\n",
      "rewards looks like  (1535,)\n",
      "log_probs looks like  (1535,)\n",
      "logs prob looks like  torch.Size([1535])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1535])\n",
      "rewards looks like  (1519,)\n",
      "log_probs looks like  (1519,)\n",
      "logs prob looks like  torch.Size([1519])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1519])\n",
      "rewards looks like  (1041,)\n",
      "log_probs looks like  (1041,)\n",
      "logs prob looks like  torch.Size([1041])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1041])\n",
      "rewards looks like  (1501,)\n",
      "log_probs looks like  (1501,)\n",
      "logs prob looks like  torch.Size([1501])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1501])\n",
      "rewards looks like  (1523,)\n",
      "log_probs looks like  (1523,)\n",
      "logs prob looks like  torch.Size([1523])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1523])\n",
      "rewards looks like  (1222,)\n",
      "log_probs looks like  (1222,)\n",
      "logs prob looks like  torch.Size([1222])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1222])\n",
      "rewards looks like  (1746,)\n",
      "log_probs looks like  (1746,)\n",
      "logs prob looks like  torch.Size([1746])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1746])\n",
      "rewards looks like  (1036,)\n",
      "log_probs looks like  (1036,)\n",
      "logs prob looks like  torch.Size([1036])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1036])\n",
      "rewards looks like  (1323,)\n",
      "log_probs looks like  (1323,)\n",
      "logs prob looks like  torch.Size([1323])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1323])\n",
      "rewards looks like  (1297,)\n",
      "log_probs looks like  (1297,)\n",
      "logs prob looks like  torch.Size([1297])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1297])\n",
      "rewards looks like  (1192,)\n",
      "log_probs looks like  (1192,)\n",
      "logs prob looks like  torch.Size([1192])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1192])\n",
      "rewards looks like  (1381,)\n",
      "log_probs looks like  (1381,)\n",
      "logs prob looks like  torch.Size([1381])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1381])\n",
      "rewards looks like  (1249,)\n",
      "log_probs looks like  (1249,)\n",
      "logs prob looks like  torch.Size([1249])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1249])\n",
      "rewards looks like  (1377,)\n",
      "log_probs looks like  (1377,)\n",
      "logs prob looks like  torch.Size([1377])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1377])\n",
      "rewards looks like  (1120,)\n",
      "log_probs looks like  (1120,)\n",
      "logs prob looks like  torch.Size([1120])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1120])\n",
      "rewards looks like  (1403,)\n",
      "log_probs looks like  (1403,)\n",
      "logs prob looks like  torch.Size([1403])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1403])\n",
      "rewards looks like  (1068,)\n",
      "log_probs looks like  (1068,)\n",
      "logs prob looks like  torch.Size([1068])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1068])\n",
      "rewards looks like  (1445,)\n",
      "log_probs looks like  (1445,)\n",
      "logs prob looks like  torch.Size([1445])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1445])\n",
      "rewards looks like  (1449,)\n",
      "log_probs looks like  (1449,)\n",
      "logs prob looks like  torch.Size([1449])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1449])\n",
      "rewards looks like  (1756,)\n",
      "log_probs looks like  (1756,)\n",
      "logs prob looks like  torch.Size([1756])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1756])\n",
      "rewards looks like  (1531,)\n",
      "log_probs looks like  (1531,)\n",
      "logs prob looks like  torch.Size([1531])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1531])\n",
      "rewards looks like  (1884,)\n",
      "log_probs looks like  (1884,)\n",
      "logs prob looks like  torch.Size([1884])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1884])\n",
      "rewards looks like  (1911,)\n",
      "log_probs looks like  (1911,)\n",
      "logs prob looks like  torch.Size([1911])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1911])\n",
      "rewards looks like  (2147,)\n",
      "log_probs looks like  (2147,)\n",
      "logs prob looks like  torch.Size([2147])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2147])\n",
      "rewards looks like  (1732,)\n",
      "log_probs looks like  (1732,)\n",
      "logs prob looks like  torch.Size([1732])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1732])\n",
      "rewards looks like  (1200,)\n",
      "log_probs looks like  (1200,)\n",
      "logs prob looks like  torch.Size([1200])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1200])\n",
      "rewards looks like  (1884,)\n",
      "log_probs looks like  (1884,)\n",
      "logs prob looks like  torch.Size([1884])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1884])\n",
      "rewards looks like  (1150,)\n",
      "log_probs looks like  (1150,)\n",
      "logs prob looks like  torch.Size([1150])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1150])\n",
      "rewards looks like  (2310,)\n",
      "log_probs looks like  (2310,)\n",
      "logs prob looks like  torch.Size([2310])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2310])\n",
      "rewards looks like  (1632,)\n",
      "log_probs looks like  (1632,)\n",
      "logs prob looks like  torch.Size([1632])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1632])\n",
      "rewards looks like  (1037,)\n",
      "log_probs looks like  (1037,)\n",
      "logs prob looks like  torch.Size([1037])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1037])\n",
      "rewards looks like  (981,)\n",
      "log_probs looks like  (981,)\n",
      "logs prob looks like  torch.Size([981])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([981])\n",
      "rewards looks like  (1169,)\n",
      "log_probs looks like  (1169,)\n",
      "logs prob looks like  torch.Size([1169])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1169])\n",
      "rewards looks like  (1168,)\n",
      "log_probs looks like  (1168,)\n",
      "logs prob looks like  torch.Size([1168])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1168])\n",
      "rewards looks like  (1769,)\n",
      "log_probs looks like  (1769,)\n",
      "logs prob looks like  torch.Size([1769])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1769])\n",
      "rewards looks like  (1360,)\n",
      "log_probs looks like  (1360,)\n",
      "logs prob looks like  torch.Size([1360])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1360])\n",
      "rewards looks like  (1210,)\n",
      "log_probs looks like  (1210,)\n",
      "logs prob looks like  torch.Size([1210])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1210])\n",
      "rewards looks like  (1144,)\n",
      "log_probs looks like  (1144,)\n",
      "logs prob looks like  torch.Size([1144])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1144])\n",
      "rewards looks like  (1456,)\n",
      "log_probs looks like  (1456,)\n",
      "logs prob looks like  torch.Size([1456])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1456])\n",
      "rewards looks like  (1486,)\n",
      "log_probs looks like  (1486,)\n",
      "logs prob looks like  torch.Size([1486])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1486])\n",
      "rewards looks like  (1514,)\n",
      "log_probs looks like  (1514,)\n",
      "logs prob looks like  torch.Size([1514])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1514])\n",
      "rewards looks like  (1932,)\n",
      "log_probs looks like  (1932,)\n",
      "logs prob looks like  torch.Size([1932])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1932])\n",
      "rewards looks like  (1269,)\n",
      "log_probs looks like  (1269,)\n",
      "logs prob looks like  torch.Size([1269])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1269])\n",
      "rewards looks like  (2126,)\n",
      "log_probs looks like  (2126,)\n",
      "logs prob looks like  torch.Size([2126])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2126])\n",
      "rewards looks like  (1249,)\n",
      "log_probs looks like  (1249,)\n",
      "logs prob looks like  torch.Size([1249])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1249])\n",
      "rewards looks like  (1812,)\n",
      "log_probs looks like  (1812,)\n",
      "logs prob looks like  torch.Size([1812])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1812])\n",
      "rewards looks like  (1116,)\n",
      "log_probs looks like  (1116,)\n",
      "logs prob looks like  torch.Size([1116])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1116])\n",
      "rewards looks like  (1467,)\n",
      "log_probs looks like  (1467,)\n",
      "logs prob looks like  torch.Size([1467])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1467])\n",
      "rewards looks like  (1336,)\n",
      "log_probs looks like  (1336,)\n",
      "logs prob looks like  torch.Size([1336])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1336])\n",
      "rewards looks like  (1874,)\n",
      "log_probs looks like  (1874,)\n",
      "logs prob looks like  torch.Size([1874])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1874])\n",
      "rewards looks like  (1141,)\n",
      "log_probs looks like  (1141,)\n",
      "logs prob looks like  torch.Size([1141])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1141])\n",
      "rewards looks like  (2366,)\n",
      "log_probs looks like  (2366,)\n",
      "logs prob looks like  torch.Size([2366])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2366])\n",
      "rewards looks like  (1298,)\n",
      "log_probs looks like  (1298,)\n",
      "logs prob looks like  torch.Size([1298])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1298])\n",
      "rewards looks like  (2647,)\n",
      "log_probs looks like  (2647,)\n",
      "logs prob looks like  torch.Size([2647])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2647])\n",
      "rewards looks like  (1574,)\n",
      "log_probs looks like  (1574,)\n",
      "logs prob looks like  torch.Size([1574])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1574])\n",
      "rewards looks like  (1492,)\n",
      "log_probs looks like  (1492,)\n",
      "logs prob looks like  torch.Size([1492])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1492])\n",
      "rewards looks like  (1483,)\n",
      "log_probs looks like  (1483,)\n",
      "logs prob looks like  torch.Size([1483])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1483])\n",
      "rewards looks like  (1372,)\n",
      "log_probs looks like  (1372,)\n",
      "logs prob looks like  torch.Size([1372])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1372])\n",
      "rewards looks like  (2035,)\n",
      "log_probs looks like  (2035,)\n",
      "logs prob looks like  torch.Size([2035])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2035])\n",
      "rewards looks like  (1144,)\n",
      "log_probs looks like  (1144,)\n",
      "logs prob looks like  torch.Size([1144])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1144])\n",
      "rewards looks like  (1595,)\n",
      "log_probs looks like  (1595,)\n",
      "logs prob looks like  torch.Size([1595])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1595])\n",
      "rewards looks like  (1552,)\n",
      "log_probs looks like  (1552,)\n",
      "logs prob looks like  torch.Size([1552])\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1552])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agent.network.train()\n",
    "EPISODE_BATCH = 5\n",
    "NUM_BATCH = 400\n",
    "\n",
    "avg_final_rewards, avg_total_rewards = [], []\n",
    "prg_bar = tqdm(range(NUM_BATCH))\n",
    "\n",
    "for batch in prg_bar:\n",
    "    \n",
    "    log_probs, rewards = [], []\n",
    "    total_rewards, final_rewards = [], []\n",
    "    \n",
    "    for i in range(EPISODE_BATCH):\n",
    "        total = 0.0\n",
    "        state = env.reset()\n",
    "        while True:\n",
    "            action, log_prob = agent.sample(state)\n",
    "            new_state, reward, done, _ = env.step(action)\n",
    "            state = new_state\n",
    "            total += reward\n",
    "            log_probs.append(log_prob)\n",
    "            rewards.append(reward)\n",
    "            \n",
    "            if done:\n",
    "                total_rewards.append(total)\n",
    "                final_rewards.append(reward)\n",
    "                break\n",
    "    \n",
    "    print(f\"rewards looks like \", np.shape(rewards))  \n",
    "    print(f\"log_probs looks like \", np.shape(log_probs))\n",
    "    \n",
    "    final_reward = np.mean(final_rewards)\n",
    "    total_reward = np.mean(total_rewards)\n",
    "    avg_final_rewards.append(final_reward)\n",
    "    avg_total_rewards.append(total_reward)\n",
    "    prg_bar.set_description(f'Total: {total_reward: 4.1f}, Final: {final_reward: 4.1f}')\n",
    "    rewards = (rewards - np.mean(rewards)) / (np.std(rewards) + 1e-9)\n",
    "    agent.learn(torch.stack(log_probs), torch.FloatTensor(rewards))\n",
    "    \n",
    "    print(\"logs prob looks like \", torch.stack(log_probs).size())\n",
    "    print(\"torch.from_numpy(rewards) looks like \", torch.from_numpy(rewards).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "end = time.time()\n",
    "plt.plot(avg_total_rewards)\n",
    "plt.title('Total Rewards')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_final_rewards)\n",
    "plt.title('Final Rewards')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time is 80123.7777299881 sec\n"
     ]
    }
   ],
   "source": [
    "print(f'total time is {end-start} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-14.033345329940019\n",
      "length of actions is  224\n",
      "-152.33484156642942\n",
      "length of actions is  150\n",
      "-177.21732498274713\n",
      "length of actions is  202\n",
      "-210.51741016568528\n",
      "length of actions is  322\n",
      "-18.538714565001953\n",
      "length of actions is  306\n"
     ]
    }
   ],
   "source": [
    "fix(env, seed)\n",
    "agent.network.eval()\n",
    "NUM_OF_TEST = 5\n",
    "action_list = []\n",
    "test_total_rewards = []\n",
    "\n",
    "for i in range(NUM_OF_TEST):\n",
    "    actions = []\n",
    "    total_reward = 0.0\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = agent.sample(state)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        actions.append(action)\n",
    "        total_reward += reward\n",
    "    \n",
    "    test_total_rewards.append(total_reward)\n",
    "    action_list.append(actions)\n",
    "    print(total_reward)\n",
    "    print(\"length of actions is \", len(actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your reward is : 260.11\n",
      "Your reward is : 256.93\n",
      "Your reward is : 282.63\n",
      "Your reward is : 285.03\n",
      "Your reward is : 314.11\n"
     ]
    }
   ],
   "source": [
    "PATH = \"Action_List_test\" + str(best_batch) + \".npy\"\n",
    "action_list = np.load(PATH,allow_pickle=True) #到時候你上傳的檔案\n",
    "seed = 543 #到時候測試的seed 請不要更改\n",
    "fix(env, seed)\n",
    "\n",
    "#agent.network.eval()  # 測試前先將 network 切換為 evaluation 模式\n",
    "\n",
    "test_total_reward = []\n",
    "for actions in action_list:\n",
    "    state = env.reset()\n",
    "\n",
    "    total_reward = 0\n",
    "\n",
    "    done = False\n",
    "    # while not done:\n",
    "    done_count = 0\n",
    "    for action in actions:\n",
    "        # action, _ = agent1.sample(state)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        done_count += 1\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "    #   img.set_data(env.render(mode='rgb_array'))\n",
    "    #   display.display(plt.gcf())\n",
    "    #   display.clear_output(wait=True)\n",
    "    print(f\"Your reward is : %.2f\"%total_reward)\n",
    "    test_total_reward.append(total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your final reward is : -114.53\n"
     ]
    }
   ],
   "source": [
    "print(f\"Your final reward is : %.2f\"%np.mean(test_total_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action list looks like  [[1, 1, 1, 1, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 3, 3, 3, 2, 2, 3, 3, 2, 3, 2, 2, 3, 3, 3, 3, 2, 3, 2, 2, 3, 3, 3, 3, 3, 2, 3, 2, 2, 3, 3, 3, 2, 2, 3, 2, 2, 3, 2, 3, 3, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 0, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 2, 3, 2, 3, 2, 3, 3, 3, 2, 2, 3, 3, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 3], [1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 3, 3, 3, 3, 2, 3, 3, 2, 3, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 2, 2, 3, 3, 3, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3], [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 0, 2, 0, 2, 0, 2, 2, 3, 3, 2, 2, 3, 3, 2, 0, 0, 2, 2, 0, 2, 0, 2, 0, 2, 3, 2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 2, 2, 2, 0, 1, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 3, 2, 0, 2, 3, 3, 2, 3, 2, 3, 3, 2, 3, 2, 3, 2, 3, 3, 2, 3, 3, 2, 2, 2, 3, 2, 2, 3, 2, 3, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 3, 2, 3, 2, 3, 2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 2, 2, 3, 3, 3, 2, 3, 3, 3, 2, 2, 3, 2, 3, 3, 3, 2, 2, 3, 2, 3, 3, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 2, 0, 0, 2, 2, 0, 0, 3, 2, 2, 2, 0, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 0, 0, 2, 0, 2, 0, 2, 2, 3, 2, 0, 2, 3, 3, 2, 0, 2, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 3, 2, 3, 2, 3, 3, 2, 3, 2, 2, 3, 2, 3, 2, 2, 3, 3, 2, 2, 3, 0, 2, 2, 2, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 2, 2, 2, 3, 3, 3, 3, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 2, 2, 2, 2, 3, 3, 3, 2, 3, 3, 3, 2, 3, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]\n",
      "Action list's shape looks like  (5,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "print(\"Action list looks like \", action_list)\n",
    "print(\"Action list's shape looks like \", np.shape(action_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 268, 2: 595, 3: 288, 0: 53}\n"
     ]
    }
   ],
   "source": [
    "distributions = {}\n",
    "for actions in action_list:\n",
    "    for action in actions:\n",
    "        if action not in distributions.keys():\n",
    "            distributions[action] = 1\n",
    "        else:\n",
    "            distributions[action] += 1  \n",
    "print(distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kate\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "PATH = 'Action_List_test.npy'\n",
    "np.save(PATH, np.array(action_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your reward is : -14.03\n",
      "Your reward is : -152.33\n",
      "Your reward is : -177.22\n",
      "Your reward is : -210.52\n",
      "Your reward is : -18.54\n"
     ]
    }
   ],
   "source": [
    "action_list = np.load(PATH, allow_pickle=True)\n",
    "seed = 543\n",
    "fix(env, seed)\n",
    "agent.network.eval()\n",
    "test_total_reward = []\n",
    "\n",
    "for actions in action_list:\n",
    "    state = env.reset()\n",
    "    total_reward = 0.0\n",
    "    done_count = 0\n",
    "    \n",
    "    for action in actions:\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        total_reward += reward\n",
    "        done_count += 1\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    test_total_reward.append(total_reward)\n",
    "    print(f\"Your reward is : %.2f\"%total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your final reward is : 279.76\n"
     ]
    }
   ],
   "source": [
    "print(f\"Your final reward is : %.2f\"%np.mean(test_total_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
