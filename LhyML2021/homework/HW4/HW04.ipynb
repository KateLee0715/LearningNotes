{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class myDataset(Dataset):\n",
    "    def __init__(self, data_dir, segment_len = 128):\n",
    "        self.data_dir = data_dir\n",
    "        self.segment_len = segment_len\n",
    "        \n",
    "        mapping_path = Path(data_dir) / 'mapping.json'\n",
    "        mapping = json.load(mapping_path.open())\n",
    "        self.speaker2id = mapping['speaker2id']\n",
    "        \n",
    "        meta_path = Path(data_dir) / 'metadata.json'\n",
    "        metadata = json.load(open(meta_path))\n",
    "        speakers = metadata['speakers']\n",
    "        self.speaker_num = len(speakers.keys())\n",
    "        \n",
    "        self.data = []\n",
    "        \n",
    "        for speaker in speakers.keys():\n",
    "            for utterances in speakers[speaker]:\n",
    "                feature_path = utterances['feature_path']\n",
    "                self.data.append([feature_path, self.speaker2id[speaker]])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        feat_path, speaker = self.data[index]\n",
    "        mel = torch.load(os.path.join(self.data_dir, feat_path))\n",
    "        \n",
    "        if len(mel) >= self.segment_len:\n",
    "            start = random.randint(0, len(mel) - self.segment_len + 1)\n",
    "            mel = torch.FloatTensor(mel[start:start+self.segment_len])\n",
    "        else:\n",
    "            mel = torch.FloatTensor(mel)\n",
    "        \n",
    "        speaker = torch.FloatTensor([speaker]).long()\n",
    "        \n",
    "        return mel, speaker\n",
    "    \n",
    "    def get_speaker_number(self):\n",
    "        return self.speaker_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_batch(batch):\n",
    "    mel, speaker = zip(*batch)\n",
    "    mel = pad_sequence(mel, batch_first = True, padding_value = -20)\n",
    "    return mel, torch.FloatTensor(speaker).long()\n",
    "\n",
    "def get_dataloader(data_dir, batch_size, n_workers):\n",
    "    dataset = myDataset(data_dir)\n",
    "    speaker_num = dataset.get_speaker_number()\n",
    "    trainlen = int(0.9 * len(dataset))\n",
    "    length = [trainlen, len(dataset) - trainlen]\n",
    "    trainset, validset = random_split(dataset, length)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        trainset,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = True,\n",
    "        drop_last = True,\n",
    "        num_workers = n_workers,\n",
    "        pin_memory = True,\n",
    "        collate_fn = collate_batch\n",
    "    )\n",
    "    \n",
    "    valid_loader = DataLoader(\n",
    "        validset,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = False,\n",
    "        drop_last = True,\n",
    "        num_workers = n_workers,\n",
    "        pin_memory = True,\n",
    "        collate_fn = collate_batch\n",
    "    )\n",
    "    \n",
    "    return train_loader, valid_loader, speaker_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AMSoftmax(nn.Module):\n",
    "    def __init__(self, in_features, n_classes, s = 30, m = 0.4):\n",
    "        super(AMSoftmax, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, n_classes, bias = False)\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "    \n",
    "    def forward(self, *inputs):\n",
    "        x_vector = F.normalize(inputs[0], p = 2, dim = -1)\n",
    "        self.linear.weight.data = F.normalize(self.linear.weight.data, p = 2, dim = -1)\n",
    "        logits = self.linear(x_vector)\n",
    "        scaled_logits = (logits - self.m) * self.s\n",
    "        return scaled_logits - self._am_logsumexp(logits)\n",
    "    \n",
    "    def _am_logsumexp(self, logits):\n",
    "        max_x = torch.max(logits, dim = -1)[0].unsqueeze(-1)\n",
    "        term1 = (self.s * (logits - (max_x + self.m))).exp()\n",
    "        term2 = (self.s * (logits - max_x)).exp().sum(-1).unsqueeze(-1) - (self.s * (logits - max_x)).exp()\n",
    "        return self.s * max_x + (term2 + term1).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Self_Attentive_Pooling(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(Self_Attentive_Pooling, self).__init__()\n",
    "        self.sap_linear = nn.Linear(dim, dim)\n",
    "        self.attention = nn.Parameter(torch.FloatTensor(dim, 1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        h = torch.tanh(self.sap_linear(x))\n",
    "        w = torch.matmul(h, self.attention).squeeze(dim = 2)\n",
    "        w = F.softmax(w, dim = 1).view(x.size(0), x.size(1), 1)\n",
    "        x = torch.sum(x * w, dim = 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalSoftmax(nn.Module):\n",
    "    def __init__(self, gamma = 2):\n",
    "        super(FocalSoftmax, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self, inputs, target):\n",
    "        logp = self.ce(inputs, target)\n",
    "        p = torch.exp(-logp)\n",
    "        loss = (1 - p) ** self.gamma * logp\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from conformer import ConformerBlock\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, d_model = 512, n_spks = 600, dropout = 0.1):\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        self.prenet = nn.Linear(40, d_model)\n",
    "        # self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "        #     d_model = d_model, dim_feedforward = 256, nhead = 2\n",
    "        # )\n",
    "        self.conformer_block = ConformerBlock(\n",
    "            dim = d_model,\n",
    "            dim_head = 64,\n",
    "            heads = 8,\n",
    "            ff_mult = 4,\n",
    "            conv_expansion_factor = 2,\n",
    "            conv_kernel_size = 31,\n",
    "            attn_dropout = dropout,\n",
    "            ff_dropout = dropout,\n",
    "            conv_dropout = dropout\n",
    "        )\n",
    "        \n",
    "        self.pooling = Self_Attentive_Pooling(d_model)\n",
    "        # self.pred_layer = nn.Sequential(\n",
    "        #     nn.Linear(d_model, d_model),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(d_model, n_spks)\n",
    "        # )\n",
    "        self.pred_layer = AMSoftmax(in_features = d_model, n_classes = n_spks)\n",
    "    \n",
    "    def forward(self, mels):\n",
    "        out = self.prenet(mels)\n",
    "        out = out.permute(1, 0, 2)\n",
    "        out = self.conformer_block(out)\n",
    "        out = out.permute(1, 2, 0)\n",
    "        stats = self.pooling(out)\n",
    "        out = self.pred_layer(stats)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "def get_cosine_schedule_with_warmup(\n",
    "    optimizer: Optimizer,\n",
    "    num_warmup_steps: int,\n",
    "    num_training_steps: int,\n",
    "    num_cycles: float = 0.5,\n",
    "    last_epoch: int = -1\n",
    "):\n",
    "    \n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < num_warmup_steps:\n",
    "            return float(current_step) / float(max(1, num_warmup_steps))\n",
    "        else:\n",
    "            progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "            return max(0.0, 0.5 * (1.0 + math.cos(math.pi * 2.0 * float(num_cycles) * progress)))\n",
    "    \n",
    "    return LambdaLR(optimizer, lr_lambda, last_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def model_fn(batch, model, criterion, device):\n",
    "    mels, labels = batch\n",
    "    mels, labels = mels.to(device), labels.to(device)\n",
    "    outs = model(mels)\n",
    "    \n",
    "    loss = criterion(outs, labels)\n",
    "    preds = outs.argmax(1)\n",
    "    \n",
    "    accuracy = (preds.cpu() == labels.cpu()).float().mean()\n",
    "    \n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def valid(dataloader, model, criterion, device):\n",
    "    model.eval()\n",
    "    pbar = tqdm(total = len(dataloader.dataset), ncols = 0, desc = 'Valid', unit = 'uttr')\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    \n",
    "    for i, batch in enumerate(dataloader):\n",
    "        with torch.no_grad():\n",
    "            loss, accuracy = model_fn(batch, model, criterion, device)\n",
    "        running_loss += loss.item()\n",
    "        running_acc += accuracy.item()\n",
    "        \n",
    "        pbar.update(dataloader.batch_size)\n",
    "        pbar.set_postfix(\n",
    "            loss = f\"{running_loss / (i + 1):.2f}\",\n",
    "            accuracy = f\"{running_acc / (i + 1):.2f}\"\n",
    "        )\n",
    "    \n",
    "    pbar.close()\n",
    "    model.train()\n",
    "    return running_acc / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    config = {\n",
    "        'data_dir': './Dataset',\n",
    "        'model_path': 'model.ckpt',\n",
    "        'batch_size': 32,\n",
    "        'n_workers': 0,\n",
    "        'valid_steps': 2000,\n",
    "        'warmup_steps': 1000,\n",
    "        'save_steps': 10000,\n",
    "        'total_steps': 100000,\n",
    "    }\n",
    "    \n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "def main(data_dir, model_path, batch_size, n_workers, valid_steps, warmup_steps, save_steps, total_steps):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"[Info]: Use {device} now!\")\n",
    "    \n",
    "    pbar = tqdm(total = valid_steps, ncols = 0, desc = 'Train', unit = 'step')\n",
    "    \n",
    "    train_loader, valid_loader, speaker_num = get_dataloader(data_dir, batch_size, n_workers)\n",
    "    train_iterator = iter(train_loader)\n",
    "    print(f\"[Info]: Finish loading data!\",flush = True)\n",
    "    \n",
    "    model = Classifier(n_spks = speaker_num).to(device)\n",
    "    criterion = FocalSoftmax()\n",
    "    optimizer = AdamW(model.parameters(), lr = 1e-3, weight_decay = 1e-4)\n",
    "    scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
    "    print(f\"[Info]: Finish creating model!\",flush = True)\n",
    "    \n",
    "    best_accuracy = 0.0\n",
    "    best_state_dict = None\n",
    "    \n",
    "    model.train()\n",
    "    for step in range(total_steps):\n",
    "        try:\n",
    "            batch = next(train_iterator)\n",
    "        except StopIteration:\n",
    "            train_iterator = iter(train_loader)\n",
    "            batch = next(train_iterator)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss, accuracy = model_fn(batch, model, criterion, device)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        pbar.update()\n",
    "        pbar.set_postfix(\n",
    "            loss = f\"{loss.item():.2f}\",\n",
    "            accuracy = f\"{accuracy.item():.2f}\",\n",
    "            step = step + 1,\n",
    "        )\n",
    "        \n",
    "        if (step + 1) % valid_steps == 0:\n",
    "            pbar.close()\n",
    "            valid_accuracy = valid(valid_loader, model, criterion, device)\n",
    "            \n",
    "            if valid_accuracy > best_accuracy:\n",
    "                best_accuracy = valid_accuracy\n",
    "                best_state_dict = model.state_dict()\n",
    "            \n",
    "            pbar = tqdm(total = valid_steps, ncols = 0, desc = 'Train', unit = 'step')\n",
    "        \n",
    "        if (step + 1) % save_steps == 0 and best_state_dict is not None:\n",
    "            torch.save(best_state_dict, model_path)\n",
    "            pbar.write(f\"Step {step + 1}, best model saved. (accuracy={best_accuracy:.4f})\")\n",
    "    \n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info]: Use cuda now!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0% 0/2000 [00:00<?, ?step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info]: Finish loading data!\n",
      "[Info]: Finish creating model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100% 2000/2000 [02:52<00:00, 11.57step/s, accuracy=0.31, loss=2.52, step=2000]\n",
      "Valid: 100% 6944/6944 [00:09<00:00, 770.04uttr/s, accuracy=0.31, loss=3.01]\n",
      "Train: 100% 2000/2000 [02:50<00:00, 11.76step/s, accuracy=0.38, loss=2.61, step=4000]\n",
      "Valid: 100% 6944/6944 [00:09<00:00, 771.37uttr/s, accuracy=0.45, loss=2.05]\n",
      "Train: 100% 2000/2000 [02:46<00:00, 12.04step/s, accuracy=0.75, loss=0.47, step=6000]\n",
      "Valid: 100% 6944/6944 [00:09<00:00, 768.71uttr/s, accuracy=0.53, loss=1.56]\n",
      "Train: 100% 2000/2000 [02:42<00:00, 12.29step/s, accuracy=0.53, loss=1.14, step=8000]\n",
      "Valid: 100% 6944/6944 [00:08<00:00, 776.81uttr/s, accuracy=0.59, loss=1.28]\n",
      "Train: 100% 2000/2000 [02:42<00:00, 12.29step/s, accuracy=0.72, loss=0.60, step=1e+4]\n",
      "Valid: 100% 6944/6944 [00:08<00:00, 778.85uttr/s, accuracy=0.63, loss=1.03]\n",
      "Train:   0% 2/2000 [00:00<03:20,  9.99step/s, accuracy=0.56, loss=1.42, step=1e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10000, best model saved. (accuracy=0.6300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100% 2000/2000 [02:43<00:00, 12.27step/s, accuracy=0.91, loss=0.09, step=12000]\n",
      "Valid: 100% 6944/6944 [00:08<00:00, 774.09uttr/s, accuracy=0.65, loss=0.94]\n",
      "Train: 100% 2000/2000 [02:44<00:00, 12.15step/s, accuracy=0.69, loss=0.64, step=14000]\n",
      "Valid: 100% 6944/6944 [00:09<00:00, 695.85uttr/s, accuracy=0.66, loss=0.90]\n",
      "Train: 100% 2000/2000 [02:47<00:00, 11.94step/s, accuracy=0.72, loss=0.50, step=16000]\n",
      "Valid: 100% 6944/6944 [00:06<00:00, 1048.88uttr/s, accuracy=0.68, loss=0.77]\n",
      "Train: 100% 2000/2000 [02:42<00:00, 12.28step/s, accuracy=0.81, loss=0.41, step=18000]\n",
      "Valid: 100% 6944/6944 [00:06<00:00, 1061.71uttr/s, accuracy=0.71, loss=0.64]\n",
      "Train: 100% 2000/2000 [02:42<00:00, 12.27step/s, accuracy=0.84, loss=0.09, step=2e+4] \n",
      "Valid: 100% 6944/6944 [00:06<00:00, 1059.02uttr/s, accuracy=0.72, loss=0.59]\n",
      "Train:   0% 2/2000 [00:00<03:39,  9.12step/s, accuracy=0.81, loss=0.27, step=2e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 20000, best model saved. (accuracy=0.7209)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100% 2000/2000 [02:43<00:00, 12.24step/s, accuracy=0.78, loss=0.17, step=22000]\n",
      "Valid: 100% 6944/6944 [00:06<00:00, 1056.37uttr/s, accuracy=0.74, loss=0.54]\n",
      "Train: 100% 2000/2000 [02:43<00:00, 12.24step/s, accuracy=0.81, loss=0.12, step=24000]\n",
      "Valid: 100% 6944/6944 [00:06<00:00, 1057.54uttr/s, accuracy=0.74, loss=0.52]\n",
      "Train: 100% 2000/2000 [02:43<00:00, 12.23step/s, accuracy=0.88, loss=0.13, step=26000]\n",
      "Valid: 100% 6944/6944 [00:06<00:00, 1061.52uttr/s, accuracy=0.75, loss=0.49]\n",
      "Train: 100% 2000/2000 [02:43<00:00, 12.26step/s, accuracy=0.88, loss=0.09, step=28000]\n",
      "Valid: 100% 6944/6944 [00:06<00:00, 1058.91uttr/s, accuracy=0.75, loss=0.49]\n",
      "Train: 100% 2000/2000 [02:43<00:00, 12.21step/s, accuracy=0.91, loss=0.15, step=3e+4] \n",
      "Valid: 100% 6944/6944 [00:06<00:00, 1034.14uttr/s, accuracy=0.77, loss=0.42]\n",
      "Train:   0% 2/2000 [00:00<02:52, 11.56step/s, accuracy=0.81, loss=0.40, step=3e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 30000, best model saved. (accuracy=0.7668)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100% 2000/2000 [02:45<00:00, 12.11step/s, accuracy=0.88, loss=0.11, step=32000]\n",
      "Valid: 100% 6944/6944 [00:06<00:00, 1015.11uttr/s, accuracy=0.78, loss=0.39]\n",
      "Train: 100% 2000/2000 [02:44<00:00, 12.16step/s, accuracy=0.84, loss=0.05, step=34000]\n",
      "Valid: 100% 6944/6944 [00:06<00:00, 1051.63uttr/s, accuracy=0.78, loss=0.37]\n",
      "Train: 100% 2000/2000 [02:44<00:00, 12.19step/s, accuracy=0.84, loss=0.09, step=36000]\n",
      "Valid: 100% 6944/6944 [00:06<00:00, 1052.01uttr/s, accuracy=0.79, loss=0.37]\n",
      "Train: 100% 2000/2000 [02:43<00:00, 12.21step/s, accuracy=0.88, loss=0.07, step=38000]\n",
      "Valid: 100% 6944/6944 [00:06<00:00, 1058.96uttr/s, accuracy=0.80, loss=0.31]\n",
      "Train: 100% 2000/2000 [02:43<00:00, 12.26step/s, accuracy=0.97, loss=0.00, step=4e+4] \n",
      "Valid: 100% 6944/6944 [00:06<00:00, 1056.55uttr/s, accuracy=0.78, loss=0.37]\n",
      "Train:   0% 2/2000 [00:00<03:40,  9.06step/s, accuracy=0.91, loss=0.03, step=4e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 40000, best model saved. (accuracy=0.7980)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100% 2000/2000 [02:44<00:00, 12.19step/s, accuracy=0.97, loss=0.01, step=42000]\n",
      "Valid: 100% 6944/6944 [00:06<00:00, 1051.53uttr/s, accuracy=0.81, loss=0.28]\n",
      "Train: 100% 2000/2000 [02:43<00:00, 12.24step/s, accuracy=0.84, loss=0.05, step=44000]\n",
      "Valid: 100% 6944/6944 [00:06<00:00, 1058.96uttr/s, accuracy=0.81, loss=0.27]\n",
      "Train: 100% 2000/2000 [02:43<00:00, 12.26step/s, accuracy=0.91, loss=0.05, step=46000]\n",
      "Valid: 100% 6944/6944 [00:06<00:00, 1058.17uttr/s, accuracy=0.82, loss=0.25]\n",
      "Train: 100% 2000/2000 [02:42<00:00, 12.28step/s, accuracy=0.91, loss=0.02, step=48000]\n",
      "Valid: 100% 6944/6944 [00:06<00:00, 1058.78uttr/s, accuracy=0.82, loss=0.25]\n",
      "Train: 100% 2000/2000 [02:42<00:00, 12.28step/s, accuracy=0.91, loss=0.02, step=5e+4] \n",
      "Valid: 100% 6944/6944 [00:06<00:00, 1057.63uttr/s, accuracy=0.82, loss=0.24]\n",
      "Train:   0% 2/2000 [00:00<02:59, 11.15step/s, accuracy=0.97, loss=0.01, step=5e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 50000, best model saved. (accuracy=0.8240)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100% 2000/2000 [02:43<00:00, 12.22step/s, accuracy=0.94, loss=0.00, step=52000]\n",
      "Valid: 100% 6944/6944 [00:06<00:00, 1053.97uttr/s, accuracy=0.83, loss=0.22]\n",
      "Train: 100% 2000/2000 [02:43<00:00, 12.22step/s, accuracy=0.91, loss=0.02, step=54000]\n",
      "Valid: 100% 6944/6944 [00:06<00:00, 1058.60uttr/s, accuracy=0.83, loss=0.22]\n",
      "Train: 100% 2000/2000 [02:43<00:00, 12.21step/s, accuracy=0.91, loss=0.04, step=56000]\n",
      "Valid: 100% 6944/6944 [00:06<00:00, 1057.48uttr/s, accuracy=0.84, loss=0.20]\n",
      "Train: 100% 2000/2000 [02:44<00:00, 12.19step/s, accuracy=0.94, loss=0.02, step=58000]\n",
      "Valid: 100% 6944/6944 [00:06<00:00, 1054.65uttr/s, accuracy=0.85, loss=0.18]\n",
      "Train: 100% 2000/2000 [02:43<00:00, 12.20step/s, accuracy=0.97, loss=0.02, step=6e+4] \n",
      "Valid: 100% 6944/6944 [00:06<00:00, 1054.39uttr/s, accuracy=0.85, loss=0.17]\n",
      "Train:   0% 2/2000 [00:00<03:08, 10.60step/s, accuracy=0.97, loss=0.00, step=6e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 60000, best model saved. (accuracy=0.8476)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100% 2000/2000 [02:44<00:00, 12.18step/s, accuracy=0.94, loss=0.01, step=62000]\n",
      "Valid: 100% 6944/6944 [00:06<00:00, 1051.47uttr/s, accuracy=0.85, loss=0.18]\n",
      "Train: 100% 2000/2000 [02:44<00:00, 12.18step/s, accuracy=1.00, loss=0.00, step=64000]\n",
      "Valid: 100% 6944/6944 [00:06<00:00, 1054.00uttr/s, accuracy=0.86, loss=0.15]\n",
      "Train: 100% 2000/2000 [02:42<00:00, 12.34step/s, accuracy=0.94, loss=0.01, step=66000]\n",
      "Valid: 100% 6944/6944 [00:08<00:00, 857.23uttr/s, accuracy=0.86, loss=0.14]\n",
      "Train: 100% 2000/2000 [02:39<00:00, 12.57step/s, accuracy=0.91, loss=0.03, step=68000]\n",
      "Valid: 100% 6944/6944 [00:08<00:00, 794.93uttr/s, accuracy=0.86, loss=0.13]\n",
      "Train: 100% 2000/2000 [02:39<00:00, 12.54step/s, accuracy=1.00, loss=0.00, step=7e+4] \n",
      "Valid: 100% 6944/6944 [00:08<00:00, 782.31uttr/s, accuracy=0.87, loss=0.12]\n",
      "Train:   0% 2/2000 [00:00<03:08, 10.62step/s, accuracy=0.97, loss=0.00, step=7e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 70000, best model saved. (accuracy=0.8692)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100% 2000/2000 [02:39<00:00, 12.51step/s, accuracy=1.00, loss=0.00, step=72000]\n",
      "Valid: 100% 6944/6944 [00:08<00:00, 774.06uttr/s, accuracy=0.87, loss=0.12]\n",
      "Train: 100% 2000/2000 [02:39<00:00, 12.52step/s, accuracy=1.00, loss=0.00, step=74000]\n",
      "Valid: 100% 6944/6944 [00:09<00:00, 765.52uttr/s, accuracy=0.87, loss=0.11]\n",
      "Train: 100% 2000/2000 [02:39<00:00, 12.50step/s, accuracy=0.97, loss=0.00, step=76000]\n",
      "Valid: 100% 6944/6944 [00:09<00:00, 755.57uttr/s, accuracy=0.88, loss=0.10]\n",
      "Train: 100% 2000/2000 [02:39<00:00, 12.51step/s, accuracy=1.00, loss=0.00, step=78000]\n",
      "Valid: 100% 6944/6944 [00:08<00:00, 776.80uttr/s, accuracy=0.88, loss=0.11]\n",
      "Train: 100% 2000/2000 [02:39<00:00, 12.55step/s, accuracy=1.00, loss=0.00, step=8e+4] \n",
      "Valid: 100% 6944/6944 [00:09<00:00, 768.67uttr/s, accuracy=0.88, loss=0.11]\n",
      "Train:   0% 2/2000 [00:00<03:39,  9.11step/s, accuracy=0.97, loss=0.00, step=8e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 80000, best model saved. (accuracy=0.8821)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100% 2000/2000 [02:38<00:00, 12.58step/s, accuracy=1.00, loss=0.00, step=82000]\n",
      "Valid: 100% 6944/6944 [00:08<00:00, 775.07uttr/s, accuracy=0.89, loss=0.10]\n",
      "Train: 100% 2000/2000 [02:38<00:00, 12.62step/s, accuracy=1.00, loss=0.00, step=84000]\n",
      "Valid: 100% 6944/6944 [00:08<00:00, 779.52uttr/s, accuracy=0.89, loss=0.10]\n",
      "Train: 100% 2000/2000 [02:38<00:00, 12.60step/s, accuracy=1.00, loss=0.00, step=86000]\n",
      "Valid: 100% 6944/6944 [00:08<00:00, 776.80uttr/s, accuracy=0.89, loss=0.08]\n",
      "Train: 100% 2000/2000 [02:38<00:00, 12.58step/s, accuracy=1.00, loss=0.00, step=88000]\n",
      "Valid: 100% 6944/6944 [00:08<00:00, 776.80uttr/s, accuracy=0.89, loss=0.09]\n",
      "Train: 100% 2000/2000 [02:38<00:00, 12.59step/s, accuracy=0.97, loss=0.01, step=9e+4] \n",
      "Valid: 100% 6944/6944 [00:08<00:00, 774.06uttr/s, accuracy=0.89, loss=0.09]\n",
      "Train:   0% 2/2000 [00:00<02:52, 11.58step/s, accuracy=1.00, loss=0.00, step=9e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 90000, best model saved. (accuracy=0.8949)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100% 2000/2000 [02:39<00:00, 12.55step/s, accuracy=1.00, loss=0.00, step=92000]\n",
      "Valid: 100% 6944/6944 [00:08<00:00, 772.71uttr/s, accuracy=0.90, loss=0.08]\n",
      "Train: 100% 2000/2000 [02:39<00:00, 12.55step/s, accuracy=0.97, loss=0.00, step=94000]\n",
      "Valid: 100% 6944/6944 [00:08<00:00, 775.41uttr/s, accuracy=0.90, loss=0.08]\n",
      "Train: 100% 2000/2000 [02:39<00:00, 12.55step/s, accuracy=1.00, loss=0.00, step=96000]\n",
      "Valid: 100% 6944/6944 [00:08<00:00, 778.19uttr/s, accuracy=0.89, loss=0.08]\n",
      "Train: 100% 2000/2000 [02:38<00:00, 12.59step/s, accuracy=0.97, loss=0.00, step=98000]\n",
      "Valid: 100% 6944/6944 [00:06<00:00, 1064.30uttr/s, accuracy=0.89, loss=0.08]\n",
      "Train: 100% 2000/2000 [02:38<00:00, 12.62step/s, accuracy=1.00, loss=0.00, step=1e+5] \n",
      "Valid: 100% 6944/6944 [00:06<00:00, 1061.84uttr/s, accuracy=0.90, loss=0.08]\n",
      "Train:   0% 0/2000 [00:00<?, ?step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100000, best model saved. (accuracy=0.8992)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main(**parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        test_path = Path(data_dir) / \"testdata.json\"\n",
    "        testdata = json.load(test_path.open())\n",
    "        self.data_dir = data_dir\n",
    "        self.data = testdata['utterances']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        feat_path = self.data[index]['feature_path']\n",
    "        mel = torch.load(os.path.join(self.data_dir, feat_path))\n",
    "        return feat_path, mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_collate_batch(batch):\n",
    "    feat_paths, mels = zip(*batch)\n",
    "    return feat_paths, torch.stack(mels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_inference_args():\n",
    "    config = {\n",
    "        'data_dir': './Dataset',\n",
    "        'model_path': './model.ckpt',\n",
    "        'output_path': './output.csv',\n",
    "    }\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import csv\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def inference_main(data_dir, model_path, output_path):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"[Info]: Use {device} now!\")\n",
    "    \n",
    "    dataset = InferenceDataset(data_dir)\n",
    "    test_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size = 1,\n",
    "        num_workers = 0,\n",
    "        shuffle = False,\n",
    "        drop_last = False,\n",
    "        collate_fn = inference_collate_batch,\n",
    "    )\n",
    "    \n",
    "    mapping_path = Path(data_dir) / 'mapping.json'\n",
    "    mapping = json.load(mapping_path.open())\n",
    "    \n",
    "    id2speaker = mapping['id2speaker']\n",
    "    speaker_num = len(id2speaker)\n",
    "    \n",
    "    model = Classifier(n_spks = speaker_num).to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    results = [['Id','Category']]\n",
    "    \n",
    "    model.eval()\n",
    "    for feat_paths, mels in test_loader:\n",
    "        mels = mels.to(device)\n",
    "        with torch.no_grad():\n",
    "            outs = model(mels)\n",
    "        preds = outs.argmax(1).cpu().numpy()\n",
    "        \n",
    "        for feat_path, pred in zip(feat_paths, preds):\n",
    "            results.append([feat_path, id2speaker[str(pred)]])\n",
    "        \n",
    "    with open(output_path, 'w', newline = '') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info]: Use cuda now!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    inference_main(**parse_inference_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting conformer\n",
      "  Downloading conformer-0.2.5-py3-none-any.whl (4.1 kB)\n",
      "Requirement already satisfied: torch in d:\\anaconda\\anaconda3\\envs\\pytorch\\lib\\site-packages (from conformer) (1.10.1)\n",
      "Collecting einops\n",
      "  Downloading einops-0.3.2-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: typing_extensions in d:\\anaconda\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch->conformer) (3.10.0.2)\n",
      "Requirement already satisfied: dataclasses in d:\\anaconda\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch->conformer) (0.8)\n",
      "Installing collected packages: einops, conformer\n",
      "Successfully installed conformer-0.2.5 einops-0.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install conformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conformer import ConformerBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
